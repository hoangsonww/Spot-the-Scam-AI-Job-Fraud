{
  "best_metric": 0.08000223338603973,
  "best_model_checkpoint": "/home/snguyen/spot-the-scam-project/artifacts/transformer/checkpoint-1940",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 2910,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010309278350515464,
      "grad_norm": 4.317173480987549,
      "learning_rate": 1.0309278350515464e-06,
      "loss": 0.6838,
      "step": 10
    },
    {
      "epoch": 0.020618556701030927,
      "grad_norm": 3.7843096256256104,
      "learning_rate": 2.061855670103093e-06,
      "loss": 0.6513,
      "step": 20
    },
    {
      "epoch": 0.030927835051546393,
      "grad_norm": 4.014454364776611,
      "learning_rate": 3.092783505154639e-06,
      "loss": 0.6005,
      "step": 30
    },
    {
      "epoch": 0.041237113402061855,
      "grad_norm": 3.813436985015869,
      "learning_rate": 4.123711340206186e-06,
      "loss": 0.5166,
      "step": 40
    },
    {
      "epoch": 0.05154639175257732,
      "grad_norm": 3.2399587631225586,
      "learning_rate": 5.154639175257732e-06,
      "loss": 0.4146,
      "step": 50
    },
    {
      "epoch": 0.061855670103092786,
      "grad_norm": 2.0524892807006836,
      "learning_rate": 6.185567010309278e-06,
      "loss": 0.2646,
      "step": 60
    },
    {
      "epoch": 0.07216494845360824,
      "grad_norm": 1.1096937656402588,
      "learning_rate": 7.216494845360825e-06,
      "loss": 0.211,
      "step": 70
    },
    {
      "epoch": 0.08247422680412371,
      "grad_norm": 1.2972776889801025,
      "learning_rate": 8.247422680412371e-06,
      "loss": 0.2271,
      "step": 80
    },
    {
      "epoch": 0.09278350515463918,
      "grad_norm": 0.9677532911300659,
      "learning_rate": 9.278350515463918e-06,
      "loss": 0.1704,
      "step": 90
    },
    {
      "epoch": 0.10309278350515463,
      "grad_norm": 0.6862984299659729,
      "learning_rate": 1.0309278350515464e-05,
      "loss": 0.1418,
      "step": 100
    },
    {
      "epoch": 0.1134020618556701,
      "grad_norm": 2.193655014038086,
      "learning_rate": 1.134020618556701e-05,
      "loss": 0.2207,
      "step": 110
    },
    {
      "epoch": 0.12371134020618557,
      "grad_norm": 1.1636004447937012,
      "learning_rate": 1.2371134020618556e-05,
      "loss": 0.0881,
      "step": 120
    },
    {
      "epoch": 0.13402061855670103,
      "grad_norm": 0.3661237359046936,
      "learning_rate": 1.3402061855670105e-05,
      "loss": 0.1181,
      "step": 130
    },
    {
      "epoch": 0.14432989690721648,
      "grad_norm": 1.9541175365447998,
      "learning_rate": 1.443298969072165e-05,
      "loss": 0.1557,
      "step": 140
    },
    {
      "epoch": 0.15463917525773196,
      "grad_norm": 1.551915168762207,
      "learning_rate": 1.5463917525773194e-05,
      "loss": 0.1943,
      "step": 150
    },
    {
      "epoch": 0.16494845360824742,
      "grad_norm": 1.1274645328521729,
      "learning_rate": 1.6494845360824743e-05,
      "loss": 0.1791,
      "step": 160
    },
    {
      "epoch": 0.17525773195876287,
      "grad_norm": 1.3621965646743774,
      "learning_rate": 1.752577319587629e-05,
      "loss": 0.176,
      "step": 170
    },
    {
      "epoch": 0.18556701030927836,
      "grad_norm": 0.5910958051681519,
      "learning_rate": 1.8556701030927837e-05,
      "loss": 0.1249,
      "step": 180
    },
    {
      "epoch": 0.1958762886597938,
      "grad_norm": 1.926119089126587,
      "learning_rate": 1.9587628865979382e-05,
      "loss": 0.1509,
      "step": 190
    },
    {
      "epoch": 0.20618556701030927,
      "grad_norm": 3.208749532699585,
      "learning_rate": 2.0618556701030927e-05,
      "loss": 0.199,
      "step": 200
    },
    {
      "epoch": 0.21649484536082475,
      "grad_norm": 0.1765502393245697,
      "learning_rate": 2.1649484536082473e-05,
      "loss": 0.0668,
      "step": 210
    },
    {
      "epoch": 0.2268041237113402,
      "grad_norm": 0.15736441314220428,
      "learning_rate": 2.268041237113402e-05,
      "loss": 0.0665,
      "step": 220
    },
    {
      "epoch": 0.23711340206185566,
      "grad_norm": 1.3699356317520142,
      "learning_rate": 2.3711340206185567e-05,
      "loss": 0.2029,
      "step": 230
    },
    {
      "epoch": 0.24742268041237114,
      "grad_norm": 1.521803379058838,
      "learning_rate": 2.4742268041237112e-05,
      "loss": 0.104,
      "step": 240
    },
    {
      "epoch": 0.25773195876288657,
      "grad_norm": 2.3980531692504883,
      "learning_rate": 2.5773195876288658e-05,
      "loss": 0.3135,
      "step": 250
    },
    {
      "epoch": 0.26804123711340205,
      "grad_norm": 0.8085442781448364,
      "learning_rate": 2.680412371134021e-05,
      "loss": 0.1475,
      "step": 260
    },
    {
      "epoch": 0.27835051546391754,
      "grad_norm": 2.1041088104248047,
      "learning_rate": 2.7835051546391755e-05,
      "loss": 0.2079,
      "step": 270
    },
    {
      "epoch": 0.28865979381443296,
      "grad_norm": 1.9802327156066895,
      "learning_rate": 2.88659793814433e-05,
      "loss": 0.2849,
      "step": 280
    },
    {
      "epoch": 0.29896907216494845,
      "grad_norm": 2.7279770374298096,
      "learning_rate": 2.9896907216494846e-05,
      "loss": 0.1952,
      "step": 290
    },
    {
      "epoch": 0.30927835051546393,
      "grad_norm": 0.7825284600257874,
      "learning_rate": 2.9896907216494846e-05,
      "loss": 0.2699,
      "step": 300
    },
    {
      "epoch": 0.31958762886597936,
      "grad_norm": 0.5694960355758667,
      "learning_rate": 2.9782359679266894e-05,
      "loss": 0.1429,
      "step": 310
    },
    {
      "epoch": 0.32989690721649484,
      "grad_norm": 0.19804762303829193,
      "learning_rate": 2.966781214203895e-05,
      "loss": 0.1397,
      "step": 320
    },
    {
      "epoch": 0.3402061855670103,
      "grad_norm": 0.2788718640804291,
      "learning_rate": 2.9553264604811e-05,
      "loss": 0.191,
      "step": 330
    },
    {
      "epoch": 0.35051546391752575,
      "grad_norm": 1.182224988937378,
      "learning_rate": 2.9438717067583048e-05,
      "loss": 0.1709,
      "step": 340
    },
    {
      "epoch": 0.36082474226804123,
      "grad_norm": 0.3944391906261444,
      "learning_rate": 2.93241695303551e-05,
      "loss": 0.109,
      "step": 350
    },
    {
      "epoch": 0.3711340206185567,
      "grad_norm": 1.25361168384552,
      "learning_rate": 2.9209621993127147e-05,
      "loss": 0.0765,
      "step": 360
    },
    {
      "epoch": 0.38144329896907214,
      "grad_norm": 1.7102159261703491,
      "learning_rate": 2.90950744558992e-05,
      "loss": 0.0899,
      "step": 370
    },
    {
      "epoch": 0.3917525773195876,
      "grad_norm": 3.245516538619995,
      "learning_rate": 2.898052691867125e-05,
      "loss": 0.1681,
      "step": 380
    },
    {
      "epoch": 0.4020618556701031,
      "grad_norm": 1.45280921459198,
      "learning_rate": 2.88659793814433e-05,
      "loss": 0.1652,
      "step": 390
    },
    {
      "epoch": 0.41237113402061853,
      "grad_norm": 2.6472182273864746,
      "learning_rate": 2.875143184421535e-05,
      "loss": 0.0914,
      "step": 400
    },
    {
      "epoch": 0.422680412371134,
      "grad_norm": 0.5660482048988342,
      "learning_rate": 2.86368843069874e-05,
      "loss": 0.1529,
      "step": 410
    },
    {
      "epoch": 0.4329896907216495,
      "grad_norm": 0.3490018844604492,
      "learning_rate": 2.852233676975945e-05,
      "loss": 0.1111,
      "step": 420
    },
    {
      "epoch": 0.44329896907216493,
      "grad_norm": 4.462515830993652,
      "learning_rate": 2.8407789232531502e-05,
      "loss": 0.1256,
      "step": 430
    },
    {
      "epoch": 0.4536082474226804,
      "grad_norm": 0.2722024619579315,
      "learning_rate": 2.8293241695303553e-05,
      "loss": 0.1268,
      "step": 440
    },
    {
      "epoch": 0.4639175257731959,
      "grad_norm": 3.0581185817718506,
      "learning_rate": 2.81786941580756e-05,
      "loss": 0.1872,
      "step": 450
    },
    {
      "epoch": 0.4742268041237113,
      "grad_norm": 0.4485691785812378,
      "learning_rate": 2.8064146620847653e-05,
      "loss": 0.1119,
      "step": 460
    },
    {
      "epoch": 0.4845360824742268,
      "grad_norm": 0.3479576110839844,
      "learning_rate": 2.7949599083619704e-05,
      "loss": 0.0952,
      "step": 470
    },
    {
      "epoch": 0.4948453608247423,
      "grad_norm": 2.625110149383545,
      "learning_rate": 2.7835051546391755e-05,
      "loss": 0.0544,
      "step": 480
    },
    {
      "epoch": 0.5051546391752577,
      "grad_norm": 0.13807691633701324,
      "learning_rate": 2.7720504009163803e-05,
      "loss": 0.0533,
      "step": 490
    },
    {
      "epoch": 0.5154639175257731,
      "grad_norm": 2.3253605365753174,
      "learning_rate": 2.7605956471935854e-05,
      "loss": 0.0719,
      "step": 500
    },
    {
      "epoch": 0.5257731958762887,
      "grad_norm": 0.10762935131788254,
      "learning_rate": 2.7491408934707902e-05,
      "loss": 0.0838,
      "step": 510
    },
    {
      "epoch": 0.5360824742268041,
      "grad_norm": 0.3613987863063812,
      "learning_rate": 2.7376861397479957e-05,
      "loss": 0.1732,
      "step": 520
    },
    {
      "epoch": 0.5463917525773195,
      "grad_norm": 2.2884011268615723,
      "learning_rate": 2.7262313860252005e-05,
      "loss": 0.1647,
      "step": 530
    },
    {
      "epoch": 0.5567010309278351,
      "grad_norm": 1.7993592023849487,
      "learning_rate": 2.7147766323024056e-05,
      "loss": 0.1559,
      "step": 540
    },
    {
      "epoch": 0.5670103092783505,
      "grad_norm": 1.7095249891281128,
      "learning_rate": 2.70446735395189e-05,
      "loss": 0.086,
      "step": 550
    },
    {
      "epoch": 0.5773195876288659,
      "grad_norm": 0.1881275624036789,
      "learning_rate": 2.693012600229095e-05,
      "loss": 0.09,
      "step": 560
    },
    {
      "epoch": 0.5876288659793815,
      "grad_norm": 0.5030262470245361,
      "learning_rate": 2.6815578465063004e-05,
      "loss": 0.0859,
      "step": 570
    },
    {
      "epoch": 0.5979381443298969,
      "grad_norm": 0.2941288650035858,
      "learning_rate": 2.670103092783505e-05,
      "loss": 0.1249,
      "step": 580
    },
    {
      "epoch": 0.6082474226804123,
      "grad_norm": 0.36757808923721313,
      "learning_rate": 2.6586483390607103e-05,
      "loss": 0.1213,
      "step": 590
    },
    {
      "epoch": 0.6185567010309279,
      "grad_norm": 1.9992733001708984,
      "learning_rate": 2.6471935853379154e-05,
      "loss": 0.0731,
      "step": 600
    },
    {
      "epoch": 0.6288659793814433,
      "grad_norm": 2.4748663902282715,
      "learning_rate": 2.6357388316151202e-05,
      "loss": 0.0834,
      "step": 610
    },
    {
      "epoch": 0.6391752577319587,
      "grad_norm": 2.408506155014038,
      "learning_rate": 2.6242840778923257e-05,
      "loss": 0.0945,
      "step": 620
    },
    {
      "epoch": 0.6494845360824743,
      "grad_norm": 0.10369842499494553,
      "learning_rate": 2.6128293241695305e-05,
      "loss": 0.1055,
      "step": 630
    },
    {
      "epoch": 0.6597938144329897,
      "grad_norm": 3.6266393661499023,
      "learning_rate": 2.6013745704467356e-05,
      "loss": 0.1831,
      "step": 640
    },
    {
      "epoch": 0.6701030927835051,
      "grad_norm": 0.7044646143913269,
      "learning_rate": 2.5899198167239404e-05,
      "loss": 0.1231,
      "step": 650
    },
    {
      "epoch": 0.6804123711340206,
      "grad_norm": 0.21254697442054749,
      "learning_rate": 2.5784650630011455e-05,
      "loss": 0.1026,
      "step": 660
    },
    {
      "epoch": 0.6907216494845361,
      "grad_norm": 0.1241818368434906,
      "learning_rate": 2.5670103092783506e-05,
      "loss": 0.07,
      "step": 670
    },
    {
      "epoch": 0.7010309278350515,
      "grad_norm": 2.380262613296509,
      "learning_rate": 2.5555555555555557e-05,
      "loss": 0.1851,
      "step": 680
    },
    {
      "epoch": 0.711340206185567,
      "grad_norm": 0.19160880148410797,
      "learning_rate": 2.5441008018327605e-05,
      "loss": 0.1245,
      "step": 690
    },
    {
      "epoch": 0.7216494845360825,
      "grad_norm": 0.16937170922756195,
      "learning_rate": 2.5326460481099657e-05,
      "loss": 0.0731,
      "step": 700
    },
    {
      "epoch": 0.7319587628865979,
      "grad_norm": 3.7826178073883057,
      "learning_rate": 2.5211912943871708e-05,
      "loss": 0.1335,
      "step": 710
    },
    {
      "epoch": 0.7422680412371134,
      "grad_norm": 1.6277021169662476,
      "learning_rate": 2.5097365406643756e-05,
      "loss": 0.1095,
      "step": 720
    },
    {
      "epoch": 0.7525773195876289,
      "grad_norm": 1.4571443796157837,
      "learning_rate": 2.498281786941581e-05,
      "loss": 0.1416,
      "step": 730
    },
    {
      "epoch": 0.7628865979381443,
      "grad_norm": 0.1162184551358223,
      "learning_rate": 2.4868270332187858e-05,
      "loss": 0.1035,
      "step": 740
    },
    {
      "epoch": 0.7731958762886598,
      "grad_norm": 0.05871587246656418,
      "learning_rate": 2.475372279495991e-05,
      "loss": 0.0235,
      "step": 750
    },
    {
      "epoch": 0.7835051546391752,
      "grad_norm": 0.0951966866850853,
      "learning_rate": 2.4639175257731957e-05,
      "loss": 0.0821,
      "step": 760
    },
    {
      "epoch": 0.7938144329896907,
      "grad_norm": 0.13699640333652496,
      "learning_rate": 2.452462772050401e-05,
      "loss": 0.0907,
      "step": 770
    },
    {
      "epoch": 0.8041237113402062,
      "grad_norm": 1.293277382850647,
      "learning_rate": 2.441008018327606e-05,
      "loss": 0.1042,
      "step": 780
    },
    {
      "epoch": 0.8144329896907216,
      "grad_norm": 3.166578769683838,
      "learning_rate": 2.429553264604811e-05,
      "loss": 0.0678,
      "step": 790
    },
    {
      "epoch": 0.8247422680412371,
      "grad_norm": 0.08600921183824539,
      "learning_rate": 2.418098510882016e-05,
      "loss": 0.1292,
      "step": 800
    },
    {
      "epoch": 0.8350515463917526,
      "grad_norm": 6.330578804016113,
      "learning_rate": 2.406643757159221e-05,
      "loss": 0.1491,
      "step": 810
    },
    {
      "epoch": 0.845360824742268,
      "grad_norm": 3.1759073734283447,
      "learning_rate": 2.395189003436426e-05,
      "loss": 0.1794,
      "step": 820
    },
    {
      "epoch": 0.8556701030927835,
      "grad_norm": 0.2446589320898056,
      "learning_rate": 2.3837342497136313e-05,
      "loss": 0.0911,
      "step": 830
    },
    {
      "epoch": 0.865979381443299,
      "grad_norm": 1.6263593435287476,
      "learning_rate": 2.3722794959908364e-05,
      "loss": 0.1548,
      "step": 840
    },
    {
      "epoch": 0.8762886597938144,
      "grad_norm": 1.4983681440353394,
      "learning_rate": 2.3608247422680412e-05,
      "loss": 0.0655,
      "step": 850
    },
    {
      "epoch": 0.8865979381443299,
      "grad_norm": 1.4722660779953003,
      "learning_rate": 2.3493699885452463e-05,
      "loss": 0.0869,
      "step": 860
    },
    {
      "epoch": 0.8969072164948454,
      "grad_norm": 3.211874485015869,
      "learning_rate": 2.337915234822451e-05,
      "loss": 0.154,
      "step": 870
    },
    {
      "epoch": 0.9072164948453608,
      "grad_norm": 4.197707653045654,
      "learning_rate": 2.3264604810996566e-05,
      "loss": 0.1052,
      "step": 880
    },
    {
      "epoch": 0.9175257731958762,
      "grad_norm": 0.16066524386405945,
      "learning_rate": 2.3150057273768614e-05,
      "loss": 0.094,
      "step": 890
    },
    {
      "epoch": 0.9278350515463918,
      "grad_norm": 1.7180278301239014,
      "learning_rate": 2.3035509736540665e-05,
      "loss": 0.1809,
      "step": 900
    },
    {
      "epoch": 0.9381443298969072,
      "grad_norm": 3.2047743797302246,
      "learning_rate": 2.2920962199312713e-05,
      "loss": 0.168,
      "step": 910
    },
    {
      "epoch": 0.9484536082474226,
      "grad_norm": 1.868985891342163,
      "learning_rate": 2.2806414662084764e-05,
      "loss": 0.1405,
      "step": 920
    },
    {
      "epoch": 0.9587628865979382,
      "grad_norm": 0.24455225467681885,
      "learning_rate": 2.269186712485682e-05,
      "loss": 0.1149,
      "step": 930
    },
    {
      "epoch": 0.9690721649484536,
      "grad_norm": 1.8327713012695312,
      "learning_rate": 2.2577319587628867e-05,
      "loss": 0.0966,
      "step": 940
    },
    {
      "epoch": 0.979381443298969,
      "grad_norm": 0.27689123153686523,
      "learning_rate": 2.2462772050400918e-05,
      "loss": 0.1444,
      "step": 950
    },
    {
      "epoch": 0.9896907216494846,
      "grad_norm": 0.1984609067440033,
      "learning_rate": 2.2348224513172966e-05,
      "loss": 0.0403,
      "step": 960
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.10088545083999634,
      "learning_rate": 2.2233676975945017e-05,
      "loss": 0.0805,
      "step": 970
    },
    {
      "epoch": 1.0,
      "eval_f1": 0.6212765957446809,
      "eval_loss": 0.10410524159669876,
      "eval_precision": 0.8588235294117647,
      "eval_recall": 0.4866666666666667,
      "eval_runtime": 1.6897,
      "eval_samples_per_second": 1966.629,
      "eval_steps_per_second": 123.099,
      "step": 970
    },
    {
      "epoch": 1.0103092783505154,
      "grad_norm": 1.5825376510620117,
      "learning_rate": 2.211912943871707e-05,
      "loss": 0.1132,
      "step": 980
    },
    {
      "epoch": 1.0206185567010309,
      "grad_norm": 0.2509423494338989,
      "learning_rate": 2.200458190148912e-05,
      "loss": 0.0931,
      "step": 990
    },
    {
      "epoch": 1.0309278350515463,
      "grad_norm": 0.4168960154056549,
      "learning_rate": 2.1890034364261168e-05,
      "loss": 0.0659,
      "step": 1000
    },
    {
      "epoch": 1.041237113402062,
      "grad_norm": 0.1522691547870636,
      "learning_rate": 2.177548682703322e-05,
      "loss": 0.0814,
      "step": 1010
    },
    {
      "epoch": 1.0515463917525774,
      "grad_norm": 0.07962822914123535,
      "learning_rate": 2.1660939289805267e-05,
      "loss": 0.0323,
      "step": 1020
    },
    {
      "epoch": 1.0618556701030928,
      "grad_norm": 6.0692949295043945,
      "learning_rate": 2.154639175257732e-05,
      "loss": 0.058,
      "step": 1030
    },
    {
      "epoch": 1.0721649484536082,
      "grad_norm": 0.44531315565109253,
      "learning_rate": 2.1431844215349373e-05,
      "loss": 0.0195,
      "step": 1040
    },
    {
      "epoch": 1.0824742268041236,
      "grad_norm": 0.07671056687831879,
      "learning_rate": 2.131729667812142e-05,
      "loss": 0.0836,
      "step": 1050
    },
    {
      "epoch": 1.0927835051546393,
      "grad_norm": 0.3776167035102844,
      "learning_rate": 2.1202749140893472e-05,
      "loss": 0.0839,
      "step": 1060
    },
    {
      "epoch": 1.1030927835051547,
      "grad_norm": 0.6264195442199707,
      "learning_rate": 2.108820160366552e-05,
      "loss": 0.0114,
      "step": 1070
    },
    {
      "epoch": 1.1134020618556701,
      "grad_norm": 1.631669282913208,
      "learning_rate": 2.0973654066437574e-05,
      "loss": 0.0588,
      "step": 1080
    },
    {
      "epoch": 1.1237113402061856,
      "grad_norm": 0.050690095871686935,
      "learning_rate": 2.0859106529209622e-05,
      "loss": 0.017,
      "step": 1090
    },
    {
      "epoch": 1.134020618556701,
      "grad_norm": 0.05047135055065155,
      "learning_rate": 2.0756013745704467e-05,
      "loss": 0.1172,
      "step": 1100
    },
    {
      "epoch": 1.1443298969072164,
      "grad_norm": 0.07051543891429901,
      "learning_rate": 2.064146620847652e-05,
      "loss": 0.0277,
      "step": 1110
    },
    {
      "epoch": 1.1546391752577319,
      "grad_norm": 0.1723417043685913,
      "learning_rate": 2.0526918671248566e-05,
      "loss": 0.0078,
      "step": 1120
    },
    {
      "epoch": 1.1649484536082475,
      "grad_norm": 0.6613743901252747,
      "learning_rate": 2.041237113402062e-05,
      "loss": 0.0937,
      "step": 1130
    },
    {
      "epoch": 1.175257731958763,
      "grad_norm": 0.27278047800064087,
      "learning_rate": 2.029782359679267e-05,
      "loss": 0.1054,
      "step": 1140
    },
    {
      "epoch": 1.1855670103092784,
      "grad_norm": 0.49154219031333923,
      "learning_rate": 2.018327605956472e-05,
      "loss": 0.0677,
      "step": 1150
    },
    {
      "epoch": 1.1958762886597938,
      "grad_norm": 0.04639893397688866,
      "learning_rate": 2.0068728522336768e-05,
      "loss": 0.1039,
      "step": 1160
    },
    {
      "epoch": 1.2061855670103092,
      "grad_norm": 3.035609006881714,
      "learning_rate": 1.995418098510882e-05,
      "loss": 0.1311,
      "step": 1170
    },
    {
      "epoch": 1.2164948453608249,
      "grad_norm": 0.11584543436765671,
      "learning_rate": 1.983963344788087e-05,
      "loss": 0.0286,
      "step": 1180
    },
    {
      "epoch": 1.2268041237113403,
      "grad_norm": 0.19672565162181854,
      "learning_rate": 1.9725085910652922e-05,
      "loss": 0.0499,
      "step": 1190
    },
    {
      "epoch": 1.2371134020618557,
      "grad_norm": 0.11552894115447998,
      "learning_rate": 1.9610538373424973e-05,
      "loss": 0.0343,
      "step": 1200
    },
    {
      "epoch": 1.2474226804123711,
      "grad_norm": 0.35241463780403137,
      "learning_rate": 1.949599083619702e-05,
      "loss": 0.1056,
      "step": 1210
    },
    {
      "epoch": 1.2577319587628866,
      "grad_norm": 0.16526514291763306,
      "learning_rate": 1.9381443298969072e-05,
      "loss": 0.0285,
      "step": 1220
    },
    {
      "epoch": 1.268041237113402,
      "grad_norm": 5.826353549957275,
      "learning_rate": 1.9266895761741124e-05,
      "loss": 0.055,
      "step": 1230
    },
    {
      "epoch": 1.2783505154639174,
      "grad_norm": 0.49273091554641724,
      "learning_rate": 1.9152348224513175e-05,
      "loss": 0.0085,
      "step": 1240
    },
    {
      "epoch": 1.2886597938144329,
      "grad_norm": 0.026848260313272476,
      "learning_rate": 1.9037800687285223e-05,
      "loss": 0.0332,
      "step": 1250
    },
    {
      "epoch": 1.2989690721649485,
      "grad_norm": 0.31606560945510864,
      "learning_rate": 1.8923253150057274e-05,
      "loss": 0.0735,
      "step": 1260
    },
    {
      "epoch": 1.309278350515464,
      "grad_norm": 0.11708291620016098,
      "learning_rate": 1.8808705612829322e-05,
      "loss": 0.1373,
      "step": 1270
    },
    {
      "epoch": 1.3195876288659794,
      "grad_norm": 5.989693641662598,
      "learning_rate": 1.8694158075601377e-05,
      "loss": 0.1284,
      "step": 1280
    },
    {
      "epoch": 1.3298969072164948,
      "grad_norm": 0.26877957582473755,
      "learning_rate": 1.8579610538373424e-05,
      "loss": 0.025,
      "step": 1290
    },
    {
      "epoch": 1.3402061855670104,
      "grad_norm": 4.572633743286133,
      "learning_rate": 1.8465063001145476e-05,
      "loss": 0.0557,
      "step": 1300
    },
    {
      "epoch": 1.3505154639175259,
      "grad_norm": 0.19360578060150146,
      "learning_rate": 1.8350515463917527e-05,
      "loss": 0.027,
      "step": 1310
    },
    {
      "epoch": 1.3608247422680413,
      "grad_norm": 0.027447201311588287,
      "learning_rate": 1.8235967926689575e-05,
      "loss": 0.0761,
      "step": 1320
    },
    {
      "epoch": 1.3711340206185567,
      "grad_norm": 3.470348358154297,
      "learning_rate": 1.812142038946163e-05,
      "loss": 0.1701,
      "step": 1330
    },
    {
      "epoch": 1.3814432989690721,
      "grad_norm": 0.09934183955192566,
      "learning_rate": 1.8006872852233677e-05,
      "loss": 0.0281,
      "step": 1340
    },
    {
      "epoch": 1.3917525773195876,
      "grad_norm": 11.088688850402832,
      "learning_rate": 1.789232531500573e-05,
      "loss": 0.1144,
      "step": 1350
    },
    {
      "epoch": 1.402061855670103,
      "grad_norm": 2.447697401046753,
      "learning_rate": 1.7777777777777777e-05,
      "loss": 0.0465,
      "step": 1360
    },
    {
      "epoch": 1.4123711340206184,
      "grad_norm": 3.262481451034546,
      "learning_rate": 1.7663230240549828e-05,
      "loss": 0.1549,
      "step": 1370
    },
    {
      "epoch": 1.422680412371134,
      "grad_norm": 11.21426010131836,
      "learning_rate": 1.754868270332188e-05,
      "loss": 0.112,
      "step": 1380
    },
    {
      "epoch": 1.4329896907216495,
      "grad_norm": 2.0972723960876465,
      "learning_rate": 1.743413516609393e-05,
      "loss": 0.073,
      "step": 1390
    },
    {
      "epoch": 1.443298969072165,
      "grad_norm": 9.263619422912598,
      "learning_rate": 1.7319587628865978e-05,
      "loss": 0.1117,
      "step": 1400
    },
    {
      "epoch": 1.4536082474226804,
      "grad_norm": 0.32472851872444153,
      "learning_rate": 1.720504009163803e-05,
      "loss": 0.0293,
      "step": 1410
    },
    {
      "epoch": 1.463917525773196,
      "grad_norm": 11.957159042358398,
      "learning_rate": 1.709049255441008e-05,
      "loss": 0.0928,
      "step": 1420
    },
    {
      "epoch": 1.4742268041237114,
      "grad_norm": 3.5665836334228516,
      "learning_rate": 1.6975945017182132e-05,
      "loss": 0.0588,
      "step": 1430
    },
    {
      "epoch": 1.4845360824742269,
      "grad_norm": 0.20149274170398712,
      "learning_rate": 1.6861397479954183e-05,
      "loss": 0.0976,
      "step": 1440
    },
    {
      "epoch": 1.4948453608247423,
      "grad_norm": 0.08038213104009628,
      "learning_rate": 1.674684994272623e-05,
      "loss": 0.1458,
      "step": 1450
    },
    {
      "epoch": 1.5051546391752577,
      "grad_norm": 4.051845550537109,
      "learning_rate": 1.6632302405498283e-05,
      "loss": 0.0847,
      "step": 1460
    },
    {
      "epoch": 1.5154639175257731,
      "grad_norm": 0.12762843072414398,
      "learning_rate": 1.651775486827033e-05,
      "loss": 0.0406,
      "step": 1470
    },
    {
      "epoch": 1.5257731958762886,
      "grad_norm": 0.1741316169500351,
      "learning_rate": 1.6403207331042385e-05,
      "loss": 0.0253,
      "step": 1480
    },
    {
      "epoch": 1.536082474226804,
      "grad_norm": 0.050555936992168427,
      "learning_rate": 1.6288659793814433e-05,
      "loss": 0.0296,
      "step": 1490
    },
    {
      "epoch": 1.5463917525773194,
      "grad_norm": 0.03147748485207558,
      "learning_rate": 1.6174112256586484e-05,
      "loss": 0.0142,
      "step": 1500
    },
    {
      "epoch": 1.556701030927835,
      "grad_norm": 1.022942066192627,
      "learning_rate": 1.6059564719358532e-05,
      "loss": 0.0608,
      "step": 1510
    },
    {
      "epoch": 1.5670103092783505,
      "grad_norm": 0.06452157348394394,
      "learning_rate": 1.5945017182130583e-05,
      "loss": 0.0464,
      "step": 1520
    },
    {
      "epoch": 1.577319587628866,
      "grad_norm": 0.2197786569595337,
      "learning_rate": 1.5830469644902638e-05,
      "loss": 0.0457,
      "step": 1530
    },
    {
      "epoch": 1.5876288659793816,
      "grad_norm": 8.29436206817627,
      "learning_rate": 1.5715922107674686e-05,
      "loss": 0.1198,
      "step": 1540
    },
    {
      "epoch": 1.597938144329897,
      "grad_norm": 0.12264234572649002,
      "learning_rate": 1.5601374570446737e-05,
      "loss": 0.0337,
      "step": 1550
    },
    {
      "epoch": 1.6082474226804124,
      "grad_norm": 0.029949283227324486,
      "learning_rate": 1.5486827033218785e-05,
      "loss": 0.0605,
      "step": 1560
    },
    {
      "epoch": 1.6185567010309279,
      "grad_norm": 0.16410726308822632,
      "learning_rate": 1.5372279495990836e-05,
      "loss": 0.0338,
      "step": 1570
    },
    {
      "epoch": 1.6288659793814433,
      "grad_norm": 2.2676210403442383,
      "learning_rate": 1.5257731958762886e-05,
      "loss": 0.0355,
      "step": 1580
    },
    {
      "epoch": 1.6391752577319587,
      "grad_norm": 0.18357457220554352,
      "learning_rate": 1.5143184421534937e-05,
      "loss": 0.0543,
      "step": 1590
    },
    {
      "epoch": 1.6494845360824741,
      "grad_norm": 8.963653564453125,
      "learning_rate": 1.5028636884306987e-05,
      "loss": 0.0717,
      "step": 1600
    },
    {
      "epoch": 1.6597938144329896,
      "grad_norm": 0.11624784022569656,
      "learning_rate": 1.4914089347079038e-05,
      "loss": 0.0807,
      "step": 1610
    },
    {
      "epoch": 1.670103092783505,
      "grad_norm": 0.06013496592640877,
      "learning_rate": 1.479954180985109e-05,
      "loss": 0.0354,
      "step": 1620
    },
    {
      "epoch": 1.6804123711340206,
      "grad_norm": 0.17156679928302765,
      "learning_rate": 1.4684994272623139e-05,
      "loss": 0.1149,
      "step": 1630
    },
    {
      "epoch": 1.690721649484536,
      "grad_norm": 0.2744223475456238,
      "learning_rate": 1.4570446735395188e-05,
      "loss": 0.0651,
      "step": 1640
    },
    {
      "epoch": 1.7010309278350515,
      "grad_norm": 0.07620652765035629,
      "learning_rate": 1.445589919816724e-05,
      "loss": 0.0123,
      "step": 1650
    },
    {
      "epoch": 1.7113402061855671,
      "grad_norm": 0.22384363412857056,
      "learning_rate": 1.434135166093929e-05,
      "loss": 0.0293,
      "step": 1660
    },
    {
      "epoch": 1.7216494845360826,
      "grad_norm": 3.401942491531372,
      "learning_rate": 1.422680412371134e-05,
      "loss": 0.0645,
      "step": 1670
    },
    {
      "epoch": 1.731958762886598,
      "grad_norm": 4.862588882446289,
      "learning_rate": 1.411225658648339e-05,
      "loss": 0.0727,
      "step": 1680
    },
    {
      "epoch": 1.7422680412371134,
      "grad_norm": 0.33115583658218384,
      "learning_rate": 1.3997709049255441e-05,
      "loss": 0.0477,
      "step": 1690
    },
    {
      "epoch": 1.7525773195876289,
      "grad_norm": 0.31604743003845215,
      "learning_rate": 1.3883161512027493e-05,
      "loss": 0.0747,
      "step": 1700
    },
    {
      "epoch": 1.7628865979381443,
      "grad_norm": 0.03809346258640289,
      "learning_rate": 1.3768613974799542e-05,
      "loss": 0.1053,
      "step": 1710
    },
    {
      "epoch": 1.7731958762886597,
      "grad_norm": 0.08946692943572998,
      "learning_rate": 1.3654066437571593e-05,
      "loss": 0.0688,
      "step": 1720
    },
    {
      "epoch": 1.7835051546391751,
      "grad_norm": 0.206621453166008,
      "learning_rate": 1.3539518900343643e-05,
      "loss": 0.0188,
      "step": 1730
    },
    {
      "epoch": 1.7938144329896906,
      "grad_norm": 1.1095622777938843,
      "learning_rate": 1.3424971363115693e-05,
      "loss": 0.0091,
      "step": 1740
    },
    {
      "epoch": 1.8041237113402062,
      "grad_norm": 0.09467820078134537,
      "learning_rate": 1.3310423825887744e-05,
      "loss": 0.0383,
      "step": 1750
    },
    {
      "epoch": 1.8144329896907216,
      "grad_norm": 0.19485613703727722,
      "learning_rate": 1.3195876288659793e-05,
      "loss": 0.0129,
      "step": 1760
    },
    {
      "epoch": 1.824742268041237,
      "grad_norm": 0.03243769332766533,
      "learning_rate": 1.3081328751431845e-05,
      "loss": 0.0475,
      "step": 1770
    },
    {
      "epoch": 1.8350515463917527,
      "grad_norm": 0.13236543536186218,
      "learning_rate": 1.2966781214203894e-05,
      "loss": 0.0223,
      "step": 1780
    },
    {
      "epoch": 1.8453608247422681,
      "grad_norm": 0.026740094646811485,
      "learning_rate": 1.2852233676975944e-05,
      "loss": 0.0712,
      "step": 1790
    },
    {
      "epoch": 1.8556701030927836,
      "grad_norm": 0.0959073156118393,
      "learning_rate": 1.2737686139747997e-05,
      "loss": 0.0832,
      "step": 1800
    },
    {
      "epoch": 1.865979381443299,
      "grad_norm": 7.6800007820129395,
      "learning_rate": 1.2623138602520046e-05,
      "loss": 0.0712,
      "step": 1810
    },
    {
      "epoch": 1.8762886597938144,
      "grad_norm": 8.711745262145996,
      "learning_rate": 1.2508591065292098e-05,
      "loss": 0.0814,
      "step": 1820
    },
    {
      "epoch": 1.8865979381443299,
      "grad_norm": 0.5978940725326538,
      "learning_rate": 1.2394043528064147e-05,
      "loss": 0.003,
      "step": 1830
    },
    {
      "epoch": 1.8969072164948453,
      "grad_norm": 0.018499305471777916,
      "learning_rate": 1.2279495990836197e-05,
      "loss": 0.0214,
      "step": 1840
    },
    {
      "epoch": 1.9072164948453607,
      "grad_norm": 0.08009520918130875,
      "learning_rate": 1.2164948453608248e-05,
      "loss": 0.0166,
      "step": 1850
    },
    {
      "epoch": 1.9175257731958761,
      "grad_norm": 0.262083500623703,
      "learning_rate": 1.2050400916380298e-05,
      "loss": 0.1056,
      "step": 1860
    },
    {
      "epoch": 1.9278350515463918,
      "grad_norm": 0.683948814868927,
      "learning_rate": 1.1935853379152349e-05,
      "loss": 0.0591,
      "step": 1870
    },
    {
      "epoch": 1.9381443298969072,
      "grad_norm": 0.02761785313487053,
      "learning_rate": 1.1821305841924399e-05,
      "loss": 0.0467,
      "step": 1880
    },
    {
      "epoch": 1.9484536082474226,
      "grad_norm": 0.05655491724610329,
      "learning_rate": 1.1706758304696448e-05,
      "loss": 0.0509,
      "step": 1890
    },
    {
      "epoch": 1.9587628865979383,
      "grad_norm": 0.0532994344830513,
      "learning_rate": 1.15922107674685e-05,
      "loss": 0.1094,
      "step": 1900
    },
    {
      "epoch": 1.9690721649484537,
      "grad_norm": 0.0637044832110405,
      "learning_rate": 1.1477663230240549e-05,
      "loss": 0.0926,
      "step": 1910
    },
    {
      "epoch": 1.9793814432989691,
      "grad_norm": 0.11572844535112381,
      "learning_rate": 1.1363115693012602e-05,
      "loss": 0.0591,
      "step": 1920
    },
    {
      "epoch": 1.9896907216494846,
      "grad_norm": 7.361093521118164,
      "learning_rate": 1.1248568155784651e-05,
      "loss": 0.0939,
      "step": 1930
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.012472599744796753,
      "learning_rate": 1.1134020618556701e-05,
      "loss": 0.027,
      "step": 1940
    },
    {
      "epoch": 2.0,
      "eval_f1": 0.7509578544061303,
      "eval_loss": 0.08000223338603973,
      "eval_precision": 0.8828828828828829,
      "eval_recall": 0.6533333333333333,
      "eval_runtime": 1.6836,
      "eval_samples_per_second": 1973.792,
      "eval_steps_per_second": 123.548,
      "step": 1940
    },
    {
      "epoch": 2.0103092783505154,
      "grad_norm": 0.04373371601104736,
      "learning_rate": 1.1019473081328752e-05,
      "loss": 0.0016,
      "step": 1950
    },
    {
      "epoch": 2.020618556701031,
      "grad_norm": 0.02940940484404564,
      "learning_rate": 1.0904925544100802e-05,
      "loss": 0.0271,
      "step": 1960
    },
    {
      "epoch": 2.0309278350515463,
      "grad_norm": 0.22533771395683289,
      "learning_rate": 1.0790378006872853e-05,
      "loss": 0.043,
      "step": 1970
    },
    {
      "epoch": 2.0412371134020617,
      "grad_norm": 0.3112419545650482,
      "learning_rate": 1.0675830469644903e-05,
      "loss": 0.0131,
      "step": 1980
    },
    {
      "epoch": 2.051546391752577,
      "grad_norm": 6.360775947570801,
      "learning_rate": 1.0561282932416952e-05,
      "loss": 0.0531,
      "step": 1990
    },
    {
      "epoch": 2.0618556701030926,
      "grad_norm": 3.6381478309631348,
      "learning_rate": 1.0446735395189004e-05,
      "loss": 0.0485,
      "step": 2000
    },
    {
      "epoch": 2.0721649484536084,
      "grad_norm": 0.07350518554449081,
      "learning_rate": 1.0332187857961053e-05,
      "loss": 0.019,
      "step": 2010
    },
    {
      "epoch": 2.082474226804124,
      "grad_norm": 7.305514812469482,
      "learning_rate": 1.0217640320733104e-05,
      "loss": 0.0317,
      "step": 2020
    },
    {
      "epoch": 2.0927835051546393,
      "grad_norm": 0.022926969453692436,
      "learning_rate": 1.0103092783505156e-05,
      "loss": 0.0158,
      "step": 2030
    },
    {
      "epoch": 2.1030927835051547,
      "grad_norm": 0.15228112041950226,
      "learning_rate": 9.988545246277205e-06,
      "loss": 0.0136,
      "step": 2040
    },
    {
      "epoch": 2.11340206185567,
      "grad_norm": 0.04139455407857895,
      "learning_rate": 9.873997709049257e-06,
      "loss": 0.0283,
      "step": 2050
    },
    {
      "epoch": 2.1237113402061856,
      "grad_norm": 17.485000610351562,
      "learning_rate": 9.759450171821306e-06,
      "loss": 0.0566,
      "step": 2060
    },
    {
      "epoch": 2.134020618556701,
      "grad_norm": 0.029681317508220673,
      "learning_rate": 9.644902634593357e-06,
      "loss": 0.0237,
      "step": 2070
    },
    {
      "epoch": 2.1443298969072164,
      "grad_norm": 0.3352223038673401,
      "learning_rate": 9.530355097365407e-06,
      "loss": 0.0023,
      "step": 2080
    },
    {
      "epoch": 2.154639175257732,
      "grad_norm": 0.13560333847999573,
      "learning_rate": 9.415807560137457e-06,
      "loss": 0.0036,
      "step": 2090
    },
    {
      "epoch": 2.1649484536082473,
      "grad_norm": 0.023198924958705902,
      "learning_rate": 9.301260022909508e-06,
      "loss": 0.0436,
      "step": 2100
    },
    {
      "epoch": 2.1752577319587627,
      "grad_norm": 0.04926251247525215,
      "learning_rate": 9.186712485681557e-06,
      "loss": 0.043,
      "step": 2110
    },
    {
      "epoch": 2.1855670103092786,
      "grad_norm": 0.027114320546388626,
      "learning_rate": 9.072164948453609e-06,
      "loss": 0.0319,
      "step": 2120
    },
    {
      "epoch": 2.195876288659794,
      "grad_norm": 0.07645676285028458,
      "learning_rate": 8.957617411225658e-06,
      "loss": 0.0989,
      "step": 2130
    },
    {
      "epoch": 2.2061855670103094,
      "grad_norm": 0.045519378036260605,
      "learning_rate": 8.84306987399771e-06,
      "loss": 0.0027,
      "step": 2140
    },
    {
      "epoch": 2.216494845360825,
      "grad_norm": 3.6571874618530273,
      "learning_rate": 8.72852233676976e-06,
      "loss": 0.0366,
      "step": 2150
    },
    {
      "epoch": 2.2268041237113403,
      "grad_norm": 0.021279428154230118,
      "learning_rate": 8.61397479954181e-06,
      "loss": 0.0054,
      "step": 2160
    },
    {
      "epoch": 2.2371134020618557,
      "grad_norm": 4.965035915374756,
      "learning_rate": 8.499427262313862e-06,
      "loss": 0.0728,
      "step": 2170
    },
    {
      "epoch": 2.247422680412371,
      "grad_norm": 0.04071386903524399,
      "learning_rate": 8.384879725085911e-06,
      "loss": 0.0035,
      "step": 2180
    },
    {
      "epoch": 2.2577319587628866,
      "grad_norm": 0.2861349284648895,
      "learning_rate": 8.27033218785796e-06,
      "loss": 0.0168,
      "step": 2190
    },
    {
      "epoch": 2.268041237113402,
      "grad_norm": 0.08274807780981064,
      "learning_rate": 8.155784650630012e-06,
      "loss": 0.0226,
      "step": 2200
    },
    {
      "epoch": 2.2783505154639174,
      "grad_norm": 0.045776911079883575,
      "learning_rate": 8.041237113402062e-06,
      "loss": 0.0236,
      "step": 2210
    },
    {
      "epoch": 2.288659793814433,
      "grad_norm": 0.018478892743587494,
      "learning_rate": 7.926689576174113e-06,
      "loss": 0.0238,
      "step": 2220
    },
    {
      "epoch": 2.2989690721649483,
      "grad_norm": 2.7552602291107178,
      "learning_rate": 7.812142038946162e-06,
      "loss": 0.0029,
      "step": 2230
    },
    {
      "epoch": 2.3092783505154637,
      "grad_norm": 0.07262483984231949,
      "learning_rate": 7.697594501718212e-06,
      "loss": 0.0789,
      "step": 2240
    },
    {
      "epoch": 2.319587628865979,
      "grad_norm": 0.04016147181391716,
      "learning_rate": 7.583046964490264e-06,
      "loss": 0.019,
      "step": 2250
    },
    {
      "epoch": 2.329896907216495,
      "grad_norm": 0.28085756301879883,
      "learning_rate": 7.468499427262314e-06,
      "loss": 0.015,
      "step": 2260
    },
    {
      "epoch": 2.3402061855670104,
      "grad_norm": 0.03595329448580742,
      "learning_rate": 7.353951890034364e-06,
      "loss": 0.0062,
      "step": 2270
    },
    {
      "epoch": 2.350515463917526,
      "grad_norm": 0.012629996985197067,
      "learning_rate": 7.239404352806415e-06,
      "loss": 0.0261,
      "step": 2280
    },
    {
      "epoch": 2.3608247422680413,
      "grad_norm": 0.013781826943159103,
      "learning_rate": 7.124856815578466e-06,
      "loss": 0.0473,
      "step": 2290
    },
    {
      "epoch": 2.3711340206185567,
      "grad_norm": 0.14271730184555054,
      "learning_rate": 7.010309278350515e-06,
      "loss": 0.0475,
      "step": 2300
    },
    {
      "epoch": 2.381443298969072,
      "grad_norm": 0.03822716325521469,
      "learning_rate": 6.895761741122566e-06,
      "loss": 0.0436,
      "step": 2310
    },
    {
      "epoch": 2.3917525773195876,
      "grad_norm": 0.02220831997692585,
      "learning_rate": 6.781214203894616e-06,
      "loss": 0.0207,
      "step": 2320
    },
    {
      "epoch": 2.402061855670103,
      "grad_norm": 0.08852267265319824,
      "learning_rate": 6.666666666666667e-06,
      "loss": 0.0231,
      "step": 2330
    },
    {
      "epoch": 2.4123711340206184,
      "grad_norm": 0.029937349259853363,
      "learning_rate": 6.552119129438718e-06,
      "loss": 0.0009,
      "step": 2340
    },
    {
      "epoch": 2.422680412371134,
      "grad_norm": 4.011668682098389,
      "learning_rate": 6.4375715922107675e-06,
      "loss": 0.0667,
      "step": 2350
    },
    {
      "epoch": 2.4329896907216497,
      "grad_norm": 2.4068682193756104,
      "learning_rate": 6.323024054982818e-06,
      "loss": 0.048,
      "step": 2360
    },
    {
      "epoch": 2.443298969072165,
      "grad_norm": 0.030706986784934998,
      "learning_rate": 6.208476517754868e-06,
      "loss": 0.0496,
      "step": 2370
    },
    {
      "epoch": 2.4536082474226806,
      "grad_norm": 0.038077812641859055,
      "learning_rate": 6.093928980526919e-06,
      "loss": 0.0373,
      "step": 2380
    },
    {
      "epoch": 2.463917525773196,
      "grad_norm": 7.874398231506348,
      "learning_rate": 5.97938144329897e-06,
      "loss": 0.0757,
      "step": 2390
    },
    {
      "epoch": 2.4742268041237114,
      "grad_norm": 0.25020262598991394,
      "learning_rate": 5.86483390607102e-06,
      "loss": 0.0387,
      "step": 2400
    },
    {
      "epoch": 2.484536082474227,
      "grad_norm": 0.02750178799033165,
      "learning_rate": 5.75028636884307e-06,
      "loss": 0.0032,
      "step": 2410
    },
    {
      "epoch": 2.4948453608247423,
      "grad_norm": 0.1140226349234581,
      "learning_rate": 5.6357388316151204e-06,
      "loss": 0.0104,
      "step": 2420
    },
    {
      "epoch": 2.5051546391752577,
      "grad_norm": 8.699901580810547,
      "learning_rate": 5.521191294387171e-06,
      "loss": 0.0511,
      "step": 2430
    },
    {
      "epoch": 2.515463917525773,
      "grad_norm": 0.02392842248082161,
      "learning_rate": 5.406643757159221e-06,
      "loss": 0.0009,
      "step": 2440
    },
    {
      "epoch": 2.5257731958762886,
      "grad_norm": 1.887519359588623,
      "learning_rate": 5.292096219931272e-06,
      "loss": 0.0617,
      "step": 2450
    },
    {
      "epoch": 2.536082474226804,
      "grad_norm": 12.935230255126953,
      "learning_rate": 5.177548682703322e-06,
      "loss": 0.0422,
      "step": 2460
    },
    {
      "epoch": 2.5463917525773194,
      "grad_norm": 0.04965393245220184,
      "learning_rate": 5.0630011454753726e-06,
      "loss": 0.0152,
      "step": 2470
    },
    {
      "epoch": 2.556701030927835,
      "grad_norm": 0.01342835184186697,
      "learning_rate": 4.948453608247423e-06,
      "loss": 0.0131,
      "step": 2480
    },
    {
      "epoch": 2.5670103092783503,
      "grad_norm": 0.05648103356361389,
      "learning_rate": 4.8339060710194725e-06,
      "loss": 0.0347,
      "step": 2490
    },
    {
      "epoch": 2.5773195876288657,
      "grad_norm": 0.015596347860991955,
      "learning_rate": 4.719358533791523e-06,
      "loss": 0.0188,
      "step": 2500
    },
    {
      "epoch": 2.5876288659793816,
      "grad_norm": 0.3773278594017029,
      "learning_rate": 4.604810996563574e-06,
      "loss": 0.0013,
      "step": 2510
    },
    {
      "epoch": 2.597938144329897,
      "grad_norm": 3.465897798538208,
      "learning_rate": 4.490263459335625e-06,
      "loss": 0.0239,
      "step": 2520
    },
    {
      "epoch": 2.6082474226804124,
      "grad_norm": 0.06416498869657516,
      "learning_rate": 4.375715922107675e-06,
      "loss": 0.0097,
      "step": 2530
    },
    {
      "epoch": 2.618556701030928,
      "grad_norm": 2.0794966220855713,
      "learning_rate": 4.261168384879725e-06,
      "loss": 0.0482,
      "step": 2540
    },
    {
      "epoch": 2.6288659793814433,
      "grad_norm": 0.040504276752471924,
      "learning_rate": 4.146620847651775e-06,
      "loss": 0.0399,
      "step": 2550
    },
    {
      "epoch": 2.6391752577319587,
      "grad_norm": 2.9593887329101562,
      "learning_rate": 4.032073310423826e-06,
      "loss": 0.0742,
      "step": 2560
    },
    {
      "epoch": 2.649484536082474,
      "grad_norm": 0.03548374027013779,
      "learning_rate": 3.917525773195877e-06,
      "loss": 0.0052,
      "step": 2570
    },
    {
      "epoch": 2.6597938144329896,
      "grad_norm": 0.013827776536345482,
      "learning_rate": 3.8029782359679268e-06,
      "loss": 0.0011,
      "step": 2580
    },
    {
      "epoch": 2.670103092783505,
      "grad_norm": 0.056386999785900116,
      "learning_rate": 3.688430698739977e-06,
      "loss": 0.0028,
      "step": 2590
    },
    {
      "epoch": 2.680412371134021,
      "grad_norm": 0.03353402391076088,
      "learning_rate": 3.573883161512027e-06,
      "loss": 0.0316,
      "step": 2600
    },
    {
      "epoch": 2.6907216494845363,
      "grad_norm": 0.34432166814804077,
      "learning_rate": 3.459335624284078e-06,
      "loss": 0.0664,
      "step": 2610
    },
    {
      "epoch": 2.7010309278350517,
      "grad_norm": 0.03327024728059769,
      "learning_rate": 3.3447880870561285e-06,
      "loss": 0.038,
      "step": 2620
    },
    {
      "epoch": 2.711340206185567,
      "grad_norm": 0.033090684562921524,
      "learning_rate": 3.230240549828179e-06,
      "loss": 0.0196,
      "step": 2630
    },
    {
      "epoch": 2.7216494845360826,
      "grad_norm": 0.020472681149840355,
      "learning_rate": 3.1156930126002293e-06,
      "loss": 0.0275,
      "step": 2640
    },
    {
      "epoch": 2.731958762886598,
      "grad_norm": 0.02251368574798107,
      "learning_rate": 3.0011454753722793e-06,
      "loss": 0.0268,
      "step": 2650
    },
    {
      "epoch": 2.7422680412371134,
      "grad_norm": 0.15708185732364655,
      "learning_rate": 2.88659793814433e-06,
      "loss": 0.0013,
      "step": 2660
    },
    {
      "epoch": 2.752577319587629,
      "grad_norm": 0.01716494746506214,
      "learning_rate": 2.7720504009163806e-06,
      "loss": 0.0133,
      "step": 2670
    },
    {
      "epoch": 2.7628865979381443,
      "grad_norm": 0.00948026031255722,
      "learning_rate": 2.6575028636884306e-06,
      "loss": 0.0245,
      "step": 2680
    },
    {
      "epoch": 2.7731958762886597,
      "grad_norm": 0.015581762418150902,
      "learning_rate": 2.5429553264604814e-06,
      "loss": 0.0349,
      "step": 2690
    },
    {
      "epoch": 2.783505154639175,
      "grad_norm": 0.038813721388578415,
      "learning_rate": 2.4284077892325314e-06,
      "loss": 0.0012,
      "step": 2700
    },
    {
      "epoch": 2.7938144329896906,
      "grad_norm": 0.03504427149891853,
      "learning_rate": 2.313860252004582e-06,
      "loss": 0.041,
      "step": 2710
    },
    {
      "epoch": 2.804123711340206,
      "grad_norm": 0.031080882996320724,
      "learning_rate": 2.1993127147766322e-06,
      "loss": 0.0446,
      "step": 2720
    },
    {
      "epoch": 2.8144329896907214,
      "grad_norm": 0.05173027142882347,
      "learning_rate": 2.0847651775486827e-06,
      "loss": 0.0026,
      "step": 2730
    },
    {
      "epoch": 2.824742268041237,
      "grad_norm": 0.04636136442422867,
      "learning_rate": 1.970217640320733e-06,
      "loss": 0.0472,
      "step": 2740
    },
    {
      "epoch": 2.8350515463917527,
      "grad_norm": 0.015198017470538616,
      "learning_rate": 1.8556701030927837e-06,
      "loss": 0.0012,
      "step": 2750
    },
    {
      "epoch": 2.845360824742268,
      "grad_norm": 0.046647634357213974,
      "learning_rate": 1.741122565864834e-06,
      "loss": 0.0188,
      "step": 2760
    },
    {
      "epoch": 2.8556701030927836,
      "grad_norm": 0.024301692843437195,
      "learning_rate": 1.6265750286368844e-06,
      "loss": 0.0016,
      "step": 2770
    },
    {
      "epoch": 2.865979381443299,
      "grad_norm": 0.016709104180336,
      "learning_rate": 1.5120274914089348e-06,
      "loss": 0.0133,
      "step": 2780
    },
    {
      "epoch": 2.8762886597938144,
      "grad_norm": 0.027338460087776184,
      "learning_rate": 1.3974799541809852e-06,
      "loss": 0.0019,
      "step": 2790
    },
    {
      "epoch": 2.88659793814433,
      "grad_norm": 0.3419231176376343,
      "learning_rate": 1.2829324169530354e-06,
      "loss": 0.0026,
      "step": 2800
    },
    {
      "epoch": 2.8969072164948453,
      "grad_norm": 0.0684218779206276,
      "learning_rate": 1.168384879725086e-06,
      "loss": 0.0435,
      "step": 2810
    },
    {
      "epoch": 2.9072164948453607,
      "grad_norm": 0.2091173380613327,
      "learning_rate": 1.0538373424971365e-06,
      "loss": 0.0448,
      "step": 2820
    },
    {
      "epoch": 2.917525773195876,
      "grad_norm": 0.04728148132562637,
      "learning_rate": 9.392898052691867e-07,
      "loss": 0.0381,
      "step": 2830
    },
    {
      "epoch": 2.927835051546392,
      "grad_norm": 0.02549094147980213,
      "learning_rate": 8.247422680412371e-07,
      "loss": 0.003,
      "step": 2840
    },
    {
      "epoch": 2.9381443298969074,
      "grad_norm": 1.3702152967453003,
      "learning_rate": 7.101947308132876e-07,
      "loss": 0.0013,
      "step": 2850
    },
    {
      "epoch": 2.948453608247423,
      "grad_norm": 0.0775376707315445,
      "learning_rate": 5.956471935853379e-07,
      "loss": 0.0034,
      "step": 2860
    },
    {
      "epoch": 2.9587628865979383,
      "grad_norm": 3.670414447784424,
      "learning_rate": 4.810996563573883e-07,
      "loss": 0.0125,
      "step": 2870
    },
    {
      "epoch": 2.9690721649484537,
      "grad_norm": 0.020632313564419746,
      "learning_rate": 3.665521191294387e-07,
      "loss": 0.0644,
      "step": 2880
    },
    {
      "epoch": 2.979381443298969,
      "grad_norm": 0.09777373820543289,
      "learning_rate": 2.5200458190148915e-07,
      "loss": 0.0493,
      "step": 2890
    },
    {
      "epoch": 2.9896907216494846,
      "grad_norm": 0.04038876295089722,
      "learning_rate": 1.3745704467353952e-07,
      "loss": 0.0012,
      "step": 2900
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.021561112254858017,
      "learning_rate": 2.290950744558992e-08,
      "loss": 0.051,
      "step": 2910
    },
    {
      "epoch": 3.0,
      "eval_f1": 0.7851851851851852,
      "eval_loss": 0.0821208655834198,
      "eval_precision": 0.8833333333333333,
      "eval_recall": 0.7066666666666667,
      "eval_runtime": 1.9261,
      "eval_samples_per_second": 1725.272,
      "eval_steps_per_second": 107.992,
      "step": 2910
    }
  ],
  "logging_steps": 10,
  "max_steps": 2910,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 1
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1540529612669952.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
