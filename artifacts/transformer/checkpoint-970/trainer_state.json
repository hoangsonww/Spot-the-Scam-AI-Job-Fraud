{
  "best_metric": 0.10410524159669876,
  "best_model_checkpoint": "/home/snguyen/spot-the-scam-project/artifacts/transformer/checkpoint-970",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 970,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010309278350515464,
      "grad_norm": 4.317173480987549,
      "learning_rate": 1.0309278350515464e-06,
      "loss": 0.6838,
      "step": 10
    },
    {
      "epoch": 0.020618556701030927,
      "grad_norm": 3.7843096256256104,
      "learning_rate": 2.061855670103093e-06,
      "loss": 0.6513,
      "step": 20
    },
    {
      "epoch": 0.030927835051546393,
      "grad_norm": 4.014454364776611,
      "learning_rate": 3.092783505154639e-06,
      "loss": 0.6005,
      "step": 30
    },
    {
      "epoch": 0.041237113402061855,
      "grad_norm": 3.813436985015869,
      "learning_rate": 4.123711340206186e-06,
      "loss": 0.5166,
      "step": 40
    },
    {
      "epoch": 0.05154639175257732,
      "grad_norm": 3.2399587631225586,
      "learning_rate": 5.154639175257732e-06,
      "loss": 0.4146,
      "step": 50
    },
    {
      "epoch": 0.061855670103092786,
      "grad_norm": 2.0524892807006836,
      "learning_rate": 6.185567010309278e-06,
      "loss": 0.2646,
      "step": 60
    },
    {
      "epoch": 0.07216494845360824,
      "grad_norm": 1.1096937656402588,
      "learning_rate": 7.216494845360825e-06,
      "loss": 0.211,
      "step": 70
    },
    {
      "epoch": 0.08247422680412371,
      "grad_norm": 1.2972776889801025,
      "learning_rate": 8.247422680412371e-06,
      "loss": 0.2271,
      "step": 80
    },
    {
      "epoch": 0.09278350515463918,
      "grad_norm": 0.9677532911300659,
      "learning_rate": 9.278350515463918e-06,
      "loss": 0.1704,
      "step": 90
    },
    {
      "epoch": 0.10309278350515463,
      "grad_norm": 0.6862984299659729,
      "learning_rate": 1.0309278350515464e-05,
      "loss": 0.1418,
      "step": 100
    },
    {
      "epoch": 0.1134020618556701,
      "grad_norm": 2.193655014038086,
      "learning_rate": 1.134020618556701e-05,
      "loss": 0.2207,
      "step": 110
    },
    {
      "epoch": 0.12371134020618557,
      "grad_norm": 1.1636004447937012,
      "learning_rate": 1.2371134020618556e-05,
      "loss": 0.0881,
      "step": 120
    },
    {
      "epoch": 0.13402061855670103,
      "grad_norm": 0.3661237359046936,
      "learning_rate": 1.3402061855670105e-05,
      "loss": 0.1181,
      "step": 130
    },
    {
      "epoch": 0.14432989690721648,
      "grad_norm": 1.9541175365447998,
      "learning_rate": 1.443298969072165e-05,
      "loss": 0.1557,
      "step": 140
    },
    {
      "epoch": 0.15463917525773196,
      "grad_norm": 1.551915168762207,
      "learning_rate": 1.5463917525773194e-05,
      "loss": 0.1943,
      "step": 150
    },
    {
      "epoch": 0.16494845360824742,
      "grad_norm": 1.1274645328521729,
      "learning_rate": 1.6494845360824743e-05,
      "loss": 0.1791,
      "step": 160
    },
    {
      "epoch": 0.17525773195876287,
      "grad_norm": 1.3621965646743774,
      "learning_rate": 1.752577319587629e-05,
      "loss": 0.176,
      "step": 170
    },
    {
      "epoch": 0.18556701030927836,
      "grad_norm": 0.5910958051681519,
      "learning_rate": 1.8556701030927837e-05,
      "loss": 0.1249,
      "step": 180
    },
    {
      "epoch": 0.1958762886597938,
      "grad_norm": 1.926119089126587,
      "learning_rate": 1.9587628865979382e-05,
      "loss": 0.1509,
      "step": 190
    },
    {
      "epoch": 0.20618556701030927,
      "grad_norm": 3.208749532699585,
      "learning_rate": 2.0618556701030927e-05,
      "loss": 0.199,
      "step": 200
    },
    {
      "epoch": 0.21649484536082475,
      "grad_norm": 0.1765502393245697,
      "learning_rate": 2.1649484536082473e-05,
      "loss": 0.0668,
      "step": 210
    },
    {
      "epoch": 0.2268041237113402,
      "grad_norm": 0.15736441314220428,
      "learning_rate": 2.268041237113402e-05,
      "loss": 0.0665,
      "step": 220
    },
    {
      "epoch": 0.23711340206185566,
      "grad_norm": 1.3699356317520142,
      "learning_rate": 2.3711340206185567e-05,
      "loss": 0.2029,
      "step": 230
    },
    {
      "epoch": 0.24742268041237114,
      "grad_norm": 1.521803379058838,
      "learning_rate": 2.4742268041237112e-05,
      "loss": 0.104,
      "step": 240
    },
    {
      "epoch": 0.25773195876288657,
      "grad_norm": 2.3980531692504883,
      "learning_rate": 2.5773195876288658e-05,
      "loss": 0.3135,
      "step": 250
    },
    {
      "epoch": 0.26804123711340205,
      "grad_norm": 0.8085442781448364,
      "learning_rate": 2.680412371134021e-05,
      "loss": 0.1475,
      "step": 260
    },
    {
      "epoch": 0.27835051546391754,
      "grad_norm": 2.1041088104248047,
      "learning_rate": 2.7835051546391755e-05,
      "loss": 0.2079,
      "step": 270
    },
    {
      "epoch": 0.28865979381443296,
      "grad_norm": 1.9802327156066895,
      "learning_rate": 2.88659793814433e-05,
      "loss": 0.2849,
      "step": 280
    },
    {
      "epoch": 0.29896907216494845,
      "grad_norm": 2.7279770374298096,
      "learning_rate": 2.9896907216494846e-05,
      "loss": 0.1952,
      "step": 290
    },
    {
      "epoch": 0.30927835051546393,
      "grad_norm": 0.7825284600257874,
      "learning_rate": 2.9896907216494846e-05,
      "loss": 0.2699,
      "step": 300
    },
    {
      "epoch": 0.31958762886597936,
      "grad_norm": 0.5694960355758667,
      "learning_rate": 2.9782359679266894e-05,
      "loss": 0.1429,
      "step": 310
    },
    {
      "epoch": 0.32989690721649484,
      "grad_norm": 0.19804762303829193,
      "learning_rate": 2.966781214203895e-05,
      "loss": 0.1397,
      "step": 320
    },
    {
      "epoch": 0.3402061855670103,
      "grad_norm": 0.2788718640804291,
      "learning_rate": 2.9553264604811e-05,
      "loss": 0.191,
      "step": 330
    },
    {
      "epoch": 0.35051546391752575,
      "grad_norm": 1.182224988937378,
      "learning_rate": 2.9438717067583048e-05,
      "loss": 0.1709,
      "step": 340
    },
    {
      "epoch": 0.36082474226804123,
      "grad_norm": 0.3944391906261444,
      "learning_rate": 2.93241695303551e-05,
      "loss": 0.109,
      "step": 350
    },
    {
      "epoch": 0.3711340206185567,
      "grad_norm": 1.25361168384552,
      "learning_rate": 2.9209621993127147e-05,
      "loss": 0.0765,
      "step": 360
    },
    {
      "epoch": 0.38144329896907214,
      "grad_norm": 1.7102159261703491,
      "learning_rate": 2.90950744558992e-05,
      "loss": 0.0899,
      "step": 370
    },
    {
      "epoch": 0.3917525773195876,
      "grad_norm": 3.245516538619995,
      "learning_rate": 2.898052691867125e-05,
      "loss": 0.1681,
      "step": 380
    },
    {
      "epoch": 0.4020618556701031,
      "grad_norm": 1.45280921459198,
      "learning_rate": 2.88659793814433e-05,
      "loss": 0.1652,
      "step": 390
    },
    {
      "epoch": 0.41237113402061853,
      "grad_norm": 2.6472182273864746,
      "learning_rate": 2.875143184421535e-05,
      "loss": 0.0914,
      "step": 400
    },
    {
      "epoch": 0.422680412371134,
      "grad_norm": 0.5660482048988342,
      "learning_rate": 2.86368843069874e-05,
      "loss": 0.1529,
      "step": 410
    },
    {
      "epoch": 0.4329896907216495,
      "grad_norm": 0.3490018844604492,
      "learning_rate": 2.852233676975945e-05,
      "loss": 0.1111,
      "step": 420
    },
    {
      "epoch": 0.44329896907216493,
      "grad_norm": 4.462515830993652,
      "learning_rate": 2.8407789232531502e-05,
      "loss": 0.1256,
      "step": 430
    },
    {
      "epoch": 0.4536082474226804,
      "grad_norm": 0.2722024619579315,
      "learning_rate": 2.8293241695303553e-05,
      "loss": 0.1268,
      "step": 440
    },
    {
      "epoch": 0.4639175257731959,
      "grad_norm": 3.0581185817718506,
      "learning_rate": 2.81786941580756e-05,
      "loss": 0.1872,
      "step": 450
    },
    {
      "epoch": 0.4742268041237113,
      "grad_norm": 0.4485691785812378,
      "learning_rate": 2.8064146620847653e-05,
      "loss": 0.1119,
      "step": 460
    },
    {
      "epoch": 0.4845360824742268,
      "grad_norm": 0.3479576110839844,
      "learning_rate": 2.7949599083619704e-05,
      "loss": 0.0952,
      "step": 470
    },
    {
      "epoch": 0.4948453608247423,
      "grad_norm": 2.625110149383545,
      "learning_rate": 2.7835051546391755e-05,
      "loss": 0.0544,
      "step": 480
    },
    {
      "epoch": 0.5051546391752577,
      "grad_norm": 0.13807691633701324,
      "learning_rate": 2.7720504009163803e-05,
      "loss": 0.0533,
      "step": 490
    },
    {
      "epoch": 0.5154639175257731,
      "grad_norm": 2.3253605365753174,
      "learning_rate": 2.7605956471935854e-05,
      "loss": 0.0719,
      "step": 500
    },
    {
      "epoch": 0.5257731958762887,
      "grad_norm": 0.10762935131788254,
      "learning_rate": 2.7491408934707902e-05,
      "loss": 0.0838,
      "step": 510
    },
    {
      "epoch": 0.5360824742268041,
      "grad_norm": 0.3613987863063812,
      "learning_rate": 2.7376861397479957e-05,
      "loss": 0.1732,
      "step": 520
    },
    {
      "epoch": 0.5463917525773195,
      "grad_norm": 2.2884011268615723,
      "learning_rate": 2.7262313860252005e-05,
      "loss": 0.1647,
      "step": 530
    },
    {
      "epoch": 0.5567010309278351,
      "grad_norm": 1.7993592023849487,
      "learning_rate": 2.7147766323024056e-05,
      "loss": 0.1559,
      "step": 540
    },
    {
      "epoch": 0.5670103092783505,
      "grad_norm": 1.7095249891281128,
      "learning_rate": 2.70446735395189e-05,
      "loss": 0.086,
      "step": 550
    },
    {
      "epoch": 0.5773195876288659,
      "grad_norm": 0.1881275624036789,
      "learning_rate": 2.693012600229095e-05,
      "loss": 0.09,
      "step": 560
    },
    {
      "epoch": 0.5876288659793815,
      "grad_norm": 0.5030262470245361,
      "learning_rate": 2.6815578465063004e-05,
      "loss": 0.0859,
      "step": 570
    },
    {
      "epoch": 0.5979381443298969,
      "grad_norm": 0.2941288650035858,
      "learning_rate": 2.670103092783505e-05,
      "loss": 0.1249,
      "step": 580
    },
    {
      "epoch": 0.6082474226804123,
      "grad_norm": 0.36757808923721313,
      "learning_rate": 2.6586483390607103e-05,
      "loss": 0.1213,
      "step": 590
    },
    {
      "epoch": 0.6185567010309279,
      "grad_norm": 1.9992733001708984,
      "learning_rate": 2.6471935853379154e-05,
      "loss": 0.0731,
      "step": 600
    },
    {
      "epoch": 0.6288659793814433,
      "grad_norm": 2.4748663902282715,
      "learning_rate": 2.6357388316151202e-05,
      "loss": 0.0834,
      "step": 610
    },
    {
      "epoch": 0.6391752577319587,
      "grad_norm": 2.408506155014038,
      "learning_rate": 2.6242840778923257e-05,
      "loss": 0.0945,
      "step": 620
    },
    {
      "epoch": 0.6494845360824743,
      "grad_norm": 0.10369842499494553,
      "learning_rate": 2.6128293241695305e-05,
      "loss": 0.1055,
      "step": 630
    },
    {
      "epoch": 0.6597938144329897,
      "grad_norm": 3.6266393661499023,
      "learning_rate": 2.6013745704467356e-05,
      "loss": 0.1831,
      "step": 640
    },
    {
      "epoch": 0.6701030927835051,
      "grad_norm": 0.7044646143913269,
      "learning_rate": 2.5899198167239404e-05,
      "loss": 0.1231,
      "step": 650
    },
    {
      "epoch": 0.6804123711340206,
      "grad_norm": 0.21254697442054749,
      "learning_rate": 2.5784650630011455e-05,
      "loss": 0.1026,
      "step": 660
    },
    {
      "epoch": 0.6907216494845361,
      "grad_norm": 0.1241818368434906,
      "learning_rate": 2.5670103092783506e-05,
      "loss": 0.07,
      "step": 670
    },
    {
      "epoch": 0.7010309278350515,
      "grad_norm": 2.380262613296509,
      "learning_rate": 2.5555555555555557e-05,
      "loss": 0.1851,
      "step": 680
    },
    {
      "epoch": 0.711340206185567,
      "grad_norm": 0.19160880148410797,
      "learning_rate": 2.5441008018327605e-05,
      "loss": 0.1245,
      "step": 690
    },
    {
      "epoch": 0.7216494845360825,
      "grad_norm": 0.16937170922756195,
      "learning_rate": 2.5326460481099657e-05,
      "loss": 0.0731,
      "step": 700
    },
    {
      "epoch": 0.7319587628865979,
      "grad_norm": 3.7826178073883057,
      "learning_rate": 2.5211912943871708e-05,
      "loss": 0.1335,
      "step": 710
    },
    {
      "epoch": 0.7422680412371134,
      "grad_norm": 1.6277021169662476,
      "learning_rate": 2.5097365406643756e-05,
      "loss": 0.1095,
      "step": 720
    },
    {
      "epoch": 0.7525773195876289,
      "grad_norm": 1.4571443796157837,
      "learning_rate": 2.498281786941581e-05,
      "loss": 0.1416,
      "step": 730
    },
    {
      "epoch": 0.7628865979381443,
      "grad_norm": 0.1162184551358223,
      "learning_rate": 2.4868270332187858e-05,
      "loss": 0.1035,
      "step": 740
    },
    {
      "epoch": 0.7731958762886598,
      "grad_norm": 0.05871587246656418,
      "learning_rate": 2.475372279495991e-05,
      "loss": 0.0235,
      "step": 750
    },
    {
      "epoch": 0.7835051546391752,
      "grad_norm": 0.0951966866850853,
      "learning_rate": 2.4639175257731957e-05,
      "loss": 0.0821,
      "step": 760
    },
    {
      "epoch": 0.7938144329896907,
      "grad_norm": 0.13699640333652496,
      "learning_rate": 2.452462772050401e-05,
      "loss": 0.0907,
      "step": 770
    },
    {
      "epoch": 0.8041237113402062,
      "grad_norm": 1.293277382850647,
      "learning_rate": 2.441008018327606e-05,
      "loss": 0.1042,
      "step": 780
    },
    {
      "epoch": 0.8144329896907216,
      "grad_norm": 3.166578769683838,
      "learning_rate": 2.429553264604811e-05,
      "loss": 0.0678,
      "step": 790
    },
    {
      "epoch": 0.8247422680412371,
      "grad_norm": 0.08600921183824539,
      "learning_rate": 2.418098510882016e-05,
      "loss": 0.1292,
      "step": 800
    },
    {
      "epoch": 0.8350515463917526,
      "grad_norm": 6.330578804016113,
      "learning_rate": 2.406643757159221e-05,
      "loss": 0.1491,
      "step": 810
    },
    {
      "epoch": 0.845360824742268,
      "grad_norm": 3.1759073734283447,
      "learning_rate": 2.395189003436426e-05,
      "loss": 0.1794,
      "step": 820
    },
    {
      "epoch": 0.8556701030927835,
      "grad_norm": 0.2446589320898056,
      "learning_rate": 2.3837342497136313e-05,
      "loss": 0.0911,
      "step": 830
    },
    {
      "epoch": 0.865979381443299,
      "grad_norm": 1.6263593435287476,
      "learning_rate": 2.3722794959908364e-05,
      "loss": 0.1548,
      "step": 840
    },
    {
      "epoch": 0.8762886597938144,
      "grad_norm": 1.4983681440353394,
      "learning_rate": 2.3608247422680412e-05,
      "loss": 0.0655,
      "step": 850
    },
    {
      "epoch": 0.8865979381443299,
      "grad_norm": 1.4722660779953003,
      "learning_rate": 2.3493699885452463e-05,
      "loss": 0.0869,
      "step": 860
    },
    {
      "epoch": 0.8969072164948454,
      "grad_norm": 3.211874485015869,
      "learning_rate": 2.337915234822451e-05,
      "loss": 0.154,
      "step": 870
    },
    {
      "epoch": 0.9072164948453608,
      "grad_norm": 4.197707653045654,
      "learning_rate": 2.3264604810996566e-05,
      "loss": 0.1052,
      "step": 880
    },
    {
      "epoch": 0.9175257731958762,
      "grad_norm": 0.16066524386405945,
      "learning_rate": 2.3150057273768614e-05,
      "loss": 0.094,
      "step": 890
    },
    {
      "epoch": 0.9278350515463918,
      "grad_norm": 1.7180278301239014,
      "learning_rate": 2.3035509736540665e-05,
      "loss": 0.1809,
      "step": 900
    },
    {
      "epoch": 0.9381443298969072,
      "grad_norm": 3.2047743797302246,
      "learning_rate": 2.2920962199312713e-05,
      "loss": 0.168,
      "step": 910
    },
    {
      "epoch": 0.9484536082474226,
      "grad_norm": 1.868985891342163,
      "learning_rate": 2.2806414662084764e-05,
      "loss": 0.1405,
      "step": 920
    },
    {
      "epoch": 0.9587628865979382,
      "grad_norm": 0.24455225467681885,
      "learning_rate": 2.269186712485682e-05,
      "loss": 0.1149,
      "step": 930
    },
    {
      "epoch": 0.9690721649484536,
      "grad_norm": 1.8327713012695312,
      "learning_rate": 2.2577319587628867e-05,
      "loss": 0.0966,
      "step": 940
    },
    {
      "epoch": 0.979381443298969,
      "grad_norm": 0.27689123153686523,
      "learning_rate": 2.2462772050400918e-05,
      "loss": 0.1444,
      "step": 950
    },
    {
      "epoch": 0.9896907216494846,
      "grad_norm": 0.1984609067440033,
      "learning_rate": 2.2348224513172966e-05,
      "loss": 0.0403,
      "step": 960
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.10088545083999634,
      "learning_rate": 2.2233676975945017e-05,
      "loss": 0.0805,
      "step": 970
    },
    {
      "epoch": 1.0,
      "eval_f1": 0.6212765957446809,
      "eval_loss": 0.10410524159669876,
      "eval_precision": 0.8588235294117647,
      "eval_recall": 0.4866666666666667,
      "eval_runtime": 1.6897,
      "eval_samples_per_second": 1966.629,
      "eval_steps_per_second": 123.099,
      "step": 970
    }
  ],
  "logging_steps": 10,
  "max_steps": 2910,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 513509870889984.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
