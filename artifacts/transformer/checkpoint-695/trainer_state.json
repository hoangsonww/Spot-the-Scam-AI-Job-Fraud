{
  "best_global_step": 695,
  "best_metric": 0.06817688792943954,
  "best_model_checkpoint": "/home/snguyen/spot-the-scam-project/artifacts/transformer/checkpoint-695",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 695,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.014388489208633094,
      "grad_norm": 4.767597675323486,
      "learning_rate": 1.291866028708134e-06,
      "loss": 0.6776,
      "step": 10
    },
    {
      "epoch": 0.02877697841726619,
      "grad_norm": 3.8736822605133057,
      "learning_rate": 2.7272727272727272e-06,
      "loss": 0.6335,
      "step": 20
    },
    {
      "epoch": 0.04316546762589928,
      "grad_norm": 3.2966713905334473,
      "learning_rate": 4.162679425837321e-06,
      "loss": 0.553,
      "step": 30
    },
    {
      "epoch": 0.05755395683453238,
      "grad_norm": 3.391916275024414,
      "learning_rate": 5.5980861244019145e-06,
      "loss": 0.4414,
      "step": 40
    },
    {
      "epoch": 0.07194244604316546,
      "grad_norm": 2.077266216278076,
      "learning_rate": 7.033492822966507e-06,
      "loss": 0.2759,
      "step": 50
    },
    {
      "epoch": 0.08633093525179857,
      "grad_norm": 1.0729150772094727,
      "learning_rate": 8.4688995215311e-06,
      "loss": 0.1856,
      "step": 60
    },
    {
      "epoch": 0.10071942446043165,
      "grad_norm": 0.864267110824585,
      "learning_rate": 9.904306220095695e-06,
      "loss": 0.2568,
      "step": 70
    },
    {
      "epoch": 0.11510791366906475,
      "grad_norm": 0.7133802175521851,
      "learning_rate": 1.1339712918660286e-05,
      "loss": 0.1477,
      "step": 80
    },
    {
      "epoch": 0.12949640287769784,
      "grad_norm": 1.045699119567871,
      "learning_rate": 1.2775119617224882e-05,
      "loss": 0.1401,
      "step": 90
    },
    {
      "epoch": 0.14388489208633093,
      "grad_norm": 0.9476826190948486,
      "learning_rate": 1.4210526315789473e-05,
      "loss": 0.2141,
      "step": 100
    },
    {
      "epoch": 0.15827338129496402,
      "grad_norm": 1.3131334781646729,
      "learning_rate": 1.5645933014354067e-05,
      "loss": 0.1538,
      "step": 110
    },
    {
      "epoch": 0.17266187050359713,
      "grad_norm": 1.6851547956466675,
      "learning_rate": 1.708133971291866e-05,
      "loss": 0.2028,
      "step": 120
    },
    {
      "epoch": 0.18705035971223022,
      "grad_norm": 0.6355000734329224,
      "learning_rate": 1.8516746411483253e-05,
      "loss": 0.1459,
      "step": 130
    },
    {
      "epoch": 0.2014388489208633,
      "grad_norm": 0.42646053433418274,
      "learning_rate": 1.995215311004785e-05,
      "loss": 0.1007,
      "step": 140
    },
    {
      "epoch": 0.2158273381294964,
      "grad_norm": 4.787518501281738,
      "learning_rate": 2.138755980861244e-05,
      "loss": 0.1301,
      "step": 150
    },
    {
      "epoch": 0.2302158273381295,
      "grad_norm": 1.897356629371643,
      "learning_rate": 2.2822966507177032e-05,
      "loss": 0.2146,
      "step": 160
    },
    {
      "epoch": 0.2446043165467626,
      "grad_norm": 1.413034439086914,
      "learning_rate": 2.4258373205741627e-05,
      "loss": 0.153,
      "step": 170
    },
    {
      "epoch": 0.2589928057553957,
      "grad_norm": 0.46302667260169983,
      "learning_rate": 2.5693779904306222e-05,
      "loss": 0.1495,
      "step": 180
    },
    {
      "epoch": 0.2733812949640288,
      "grad_norm": 1.8984591960906982,
      "learning_rate": 2.7129186602870814e-05,
      "loss": 0.1117,
      "step": 190
    },
    {
      "epoch": 0.28776978417266186,
      "grad_norm": 3.858778238296509,
      "learning_rate": 2.8564593301435406e-05,
      "loss": 0.2662,
      "step": 200
    },
    {
      "epoch": 0.302158273381295,
      "grad_norm": 3.060361385345459,
      "learning_rate": 3e-05,
      "loss": 0.1575,
      "step": 210
    },
    {
      "epoch": 0.31654676258992803,
      "grad_norm": 1.7025481462478638,
      "learning_rate": 2.9840085287846483e-05,
      "loss": 0.1871,
      "step": 220
    },
    {
      "epoch": 0.33093525179856115,
      "grad_norm": 2.6734561920166016,
      "learning_rate": 2.968017057569296e-05,
      "loss": 0.0752,
      "step": 230
    },
    {
      "epoch": 0.34532374100719426,
      "grad_norm": 9.153828620910645,
      "learning_rate": 2.9520255863539447e-05,
      "loss": 0.2789,
      "step": 240
    },
    {
      "epoch": 0.3597122302158273,
      "grad_norm": 1.1766316890716553,
      "learning_rate": 2.936034115138593e-05,
      "loss": 0.1089,
      "step": 250
    },
    {
      "epoch": 0.37410071942446044,
      "grad_norm": 1.242830514907837,
      "learning_rate": 2.920042643923241e-05,
      "loss": 0.1383,
      "step": 260
    },
    {
      "epoch": 0.38848920863309355,
      "grad_norm": 1.9008326530456543,
      "learning_rate": 2.904051172707889e-05,
      "loss": 0.1151,
      "step": 270
    },
    {
      "epoch": 0.4028776978417266,
      "grad_norm": 3.199657917022705,
      "learning_rate": 2.8880597014925376e-05,
      "loss": 0.1176,
      "step": 280
    },
    {
      "epoch": 0.4172661870503597,
      "grad_norm": 1.7302137613296509,
      "learning_rate": 2.8720682302771858e-05,
      "loss": 0.1187,
      "step": 290
    },
    {
      "epoch": 0.4316546762589928,
      "grad_norm": 0.37601661682128906,
      "learning_rate": 2.8560767590618336e-05,
      "loss": 0.066,
      "step": 300
    },
    {
      "epoch": 0.4460431654676259,
      "grad_norm": 0.7147097587585449,
      "learning_rate": 2.840085287846482e-05,
      "loss": 0.1907,
      "step": 310
    },
    {
      "epoch": 0.460431654676259,
      "grad_norm": 0.38358354568481445,
      "learning_rate": 2.82409381663113e-05,
      "loss": 0.0858,
      "step": 320
    },
    {
      "epoch": 0.4748201438848921,
      "grad_norm": 1.9803627729415894,
      "learning_rate": 2.8081023454157786e-05,
      "loss": 0.153,
      "step": 330
    },
    {
      "epoch": 0.4892086330935252,
      "grad_norm": 0.18710483610630035,
      "learning_rate": 2.7921108742004265e-05,
      "loss": 0.0776,
      "step": 340
    },
    {
      "epoch": 0.5035971223021583,
      "grad_norm": 5.984102249145508,
      "learning_rate": 2.7761194029850747e-05,
      "loss": 0.114,
      "step": 350
    },
    {
      "epoch": 0.5179856115107914,
      "grad_norm": 1.1332311630249023,
      "learning_rate": 2.760127931769723e-05,
      "loss": 0.1552,
      "step": 360
    },
    {
      "epoch": 0.5323741007194245,
      "grad_norm": 0.7494312524795532,
      "learning_rate": 2.744136460554371e-05,
      "loss": 0.0803,
      "step": 370
    },
    {
      "epoch": 0.5467625899280576,
      "grad_norm": 2.975085496902466,
      "learning_rate": 2.7281449893390193e-05,
      "loss": 0.0695,
      "step": 380
    },
    {
      "epoch": 0.5611510791366906,
      "grad_norm": 3.1028759479522705,
      "learning_rate": 2.7121535181236675e-05,
      "loss": 0.187,
      "step": 390
    },
    {
      "epoch": 0.5755395683453237,
      "grad_norm": 6.678132057189941,
      "learning_rate": 2.6961620469083154e-05,
      "loss": 0.1086,
      "step": 400
    },
    {
      "epoch": 0.5899280575539568,
      "grad_norm": 4.0267815589904785,
      "learning_rate": 2.6801705756929636e-05,
      "loss": 0.0876,
      "step": 410
    },
    {
      "epoch": 0.60431654676259,
      "grad_norm": 3.800591230392456,
      "learning_rate": 2.664179104477612e-05,
      "loss": 0.1667,
      "step": 420
    },
    {
      "epoch": 0.6187050359712231,
      "grad_norm": 2.8194808959960938,
      "learning_rate": 2.6481876332622604e-05,
      "loss": 0.0675,
      "step": 430
    },
    {
      "epoch": 0.6330935251798561,
      "grad_norm": 0.5190096497535706,
      "learning_rate": 2.6321961620469082e-05,
      "loss": 0.0209,
      "step": 440
    },
    {
      "epoch": 0.6474820143884892,
      "grad_norm": 8.045195579528809,
      "learning_rate": 2.6162046908315565e-05,
      "loss": 0.0511,
      "step": 450
    },
    {
      "epoch": 0.6618705035971223,
      "grad_norm": 3.01597261428833,
      "learning_rate": 2.600213219616205e-05,
      "loss": 0.1244,
      "step": 460
    },
    {
      "epoch": 0.6762589928057554,
      "grad_norm": 0.37546855211257935,
      "learning_rate": 2.584221748400853e-05,
      "loss": 0.0887,
      "step": 470
    },
    {
      "epoch": 0.6906474820143885,
      "grad_norm": 0.06036531552672386,
      "learning_rate": 2.568230277185501e-05,
      "loss": 0.0632,
      "step": 480
    },
    {
      "epoch": 0.7050359712230215,
      "grad_norm": 2.3147408962249756,
      "learning_rate": 2.5522388059701493e-05,
      "loss": 0.0151,
      "step": 490
    },
    {
      "epoch": 0.7194244604316546,
      "grad_norm": 12.95970344543457,
      "learning_rate": 2.5362473347547975e-05,
      "loss": 0.0899,
      "step": 500
    },
    {
      "epoch": 0.7338129496402878,
      "grad_norm": 1.7828023433685303,
      "learning_rate": 2.5202558635394457e-05,
      "loss": 0.0746,
      "step": 510
    },
    {
      "epoch": 0.7482014388489209,
      "grad_norm": 2.75822114944458,
      "learning_rate": 2.504264392324094e-05,
      "loss": 0.0413,
      "step": 520
    },
    {
      "epoch": 0.762589928057554,
      "grad_norm": 0.08636615425348282,
      "learning_rate": 2.488272921108742e-05,
      "loss": 0.1107,
      "step": 530
    },
    {
      "epoch": 0.7769784172661871,
      "grad_norm": 5.455087661743164,
      "learning_rate": 2.47228144989339e-05,
      "loss": 0.0832,
      "step": 540
    },
    {
      "epoch": 0.7913669064748201,
      "grad_norm": 0.12403181195259094,
      "learning_rate": 2.4562899786780386e-05,
      "loss": 0.0885,
      "step": 550
    },
    {
      "epoch": 0.8057553956834532,
      "grad_norm": 1.582260251045227,
      "learning_rate": 2.4402985074626868e-05,
      "loss": 0.0458,
      "step": 560
    },
    {
      "epoch": 0.8201438848920863,
      "grad_norm": 3.6227715015411377,
      "learning_rate": 2.424307036247335e-05,
      "loss": 0.1477,
      "step": 570
    },
    {
      "epoch": 0.8345323741007195,
      "grad_norm": 3.8801467418670654,
      "learning_rate": 2.408315565031983e-05,
      "loss": 0.0577,
      "step": 580
    },
    {
      "epoch": 0.8489208633093526,
      "grad_norm": 2.7570881843566895,
      "learning_rate": 2.392324093816631e-05,
      "loss": 0.0579,
      "step": 590
    },
    {
      "epoch": 0.8633093525179856,
      "grad_norm": 1.8289506435394287,
      "learning_rate": 2.3763326226012796e-05,
      "loss": 0.1752,
      "step": 600
    },
    {
      "epoch": 0.8776978417266187,
      "grad_norm": 0.214692622423172,
      "learning_rate": 2.3603411513859275e-05,
      "loss": 0.0975,
      "step": 610
    },
    {
      "epoch": 0.8920863309352518,
      "grad_norm": 0.2552040219306946,
      "learning_rate": 2.3443496801705757e-05,
      "loss": 0.0956,
      "step": 620
    },
    {
      "epoch": 0.9064748201438849,
      "grad_norm": 0.5100186467170715,
      "learning_rate": 2.328358208955224e-05,
      "loss": 0.0664,
      "step": 630
    },
    {
      "epoch": 0.920863309352518,
      "grad_norm": 1.5062813758850098,
      "learning_rate": 2.312366737739872e-05,
      "loss": 0.0716,
      "step": 640
    },
    {
      "epoch": 0.935251798561151,
      "grad_norm": 6.813384056091309,
      "learning_rate": 2.2963752665245203e-05,
      "loss": 0.1357,
      "step": 650
    },
    {
      "epoch": 0.9496402877697842,
      "grad_norm": 0.5452286601066589,
      "learning_rate": 2.2803837953091685e-05,
      "loss": 0.0457,
      "step": 660
    },
    {
      "epoch": 0.9640287769784173,
      "grad_norm": 0.07252806425094604,
      "learning_rate": 2.2643923240938168e-05,
      "loss": 0.0653,
      "step": 670
    },
    {
      "epoch": 0.9784172661870504,
      "grad_norm": 3.0628950595855713,
      "learning_rate": 2.2484008528784646e-05,
      "loss": 0.0657,
      "step": 680
    },
    {
      "epoch": 0.9928057553956835,
      "grad_norm": 6.020812034606934,
      "learning_rate": 2.2324093816631132e-05,
      "loss": 0.0598,
      "step": 690
    },
    {
      "epoch": 1.0,
      "eval_f1": 0.7513227513227513,
      "eval_loss": 0.06817688792943954,
      "eval_precision": 0.8658536585365854,
      "eval_recall": 0.6635514018691588,
      "eval_runtime": 1.4885,
      "eval_samples_per_second": 1599.615,
      "eval_steps_per_second": 100.102,
      "step": 695
    }
  ],
  "logging_steps": 10,
  "max_steps": 2085,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 367895082917376.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
