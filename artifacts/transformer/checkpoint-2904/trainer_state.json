{
  "best_global_step": 1936,
  "best_metric": 0.08372092247009277,
  "best_model_checkpoint": "/home/snguyen/spot-the-scam-project/artifacts/transformer/checkpoint-1936",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 2904,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010330578512396695,
      "grad_norm": 4.703976154327393,
      "learning_rate": 9.278350515463919e-07,
      "loss": 0.6766,
      "step": 10
    },
    {
      "epoch": 0.02066115702479339,
      "grad_norm": 3.4400298595428467,
      "learning_rate": 1.9587628865979384e-06,
      "loss": 0.6511,
      "step": 20
    },
    {
      "epoch": 0.030991735537190084,
      "grad_norm": 4.108104705810547,
      "learning_rate": 2.989690721649485e-06,
      "loss": 0.6006,
      "step": 30
    },
    {
      "epoch": 0.04132231404958678,
      "grad_norm": 3.8866748809814453,
      "learning_rate": 4.020618556701031e-06,
      "loss": 0.5292,
      "step": 40
    },
    {
      "epoch": 0.05165289256198347,
      "grad_norm": 2.5028867721557617,
      "learning_rate": 5.051546391752578e-06,
      "loss": 0.4198,
      "step": 50
    },
    {
      "epoch": 0.06198347107438017,
      "grad_norm": 1.6685080528259277,
      "learning_rate": 6.082474226804124e-06,
      "loss": 0.3294,
      "step": 60
    },
    {
      "epoch": 0.07231404958677685,
      "grad_norm": 1.0191187858581543,
      "learning_rate": 7.11340206185567e-06,
      "loss": 0.2491,
      "step": 70
    },
    {
      "epoch": 0.08264462809917356,
      "grad_norm": 0.9723655581474304,
      "learning_rate": 8.144329896907216e-06,
      "loss": 0.2003,
      "step": 80
    },
    {
      "epoch": 0.09297520661157024,
      "grad_norm": 0.6860754489898682,
      "learning_rate": 9.175257731958764e-06,
      "loss": 0.1322,
      "step": 90
    },
    {
      "epoch": 0.10330578512396695,
      "grad_norm": 0.47402727603912354,
      "learning_rate": 1.020618556701031e-05,
      "loss": 0.1129,
      "step": 100
    },
    {
      "epoch": 0.11363636363636363,
      "grad_norm": 0.40855422616004944,
      "learning_rate": 1.1237113402061856e-05,
      "loss": 0.068,
      "step": 110
    },
    {
      "epoch": 0.12396694214876033,
      "grad_norm": 2.5328145027160645,
      "learning_rate": 1.2268041237113401e-05,
      "loss": 0.2872,
      "step": 120
    },
    {
      "epoch": 0.13429752066115702,
      "grad_norm": 1.6092427968978882,
      "learning_rate": 1.3298969072164948e-05,
      "loss": 0.1948,
      "step": 130
    },
    {
      "epoch": 0.1446280991735537,
      "grad_norm": 0.8369685411453247,
      "learning_rate": 1.4329896907216495e-05,
      "loss": 0.1408,
      "step": 140
    },
    {
      "epoch": 0.15495867768595042,
      "grad_norm": 5.178857803344727,
      "learning_rate": 1.536082474226804e-05,
      "loss": 0.3299,
      "step": 150
    },
    {
      "epoch": 0.1652892561983471,
      "grad_norm": 1.108429193496704,
      "learning_rate": 1.6391752577319588e-05,
      "loss": 0.1984,
      "step": 160
    },
    {
      "epoch": 0.1756198347107438,
      "grad_norm": 1.3731595277786255,
      "learning_rate": 1.7422680412371137e-05,
      "loss": 0.2273,
      "step": 170
    },
    {
      "epoch": 0.1859504132231405,
      "grad_norm": 1.8679790496826172,
      "learning_rate": 1.8453608247422682e-05,
      "loss": 0.19,
      "step": 180
    },
    {
      "epoch": 0.1962809917355372,
      "grad_norm": 0.4076886773109436,
      "learning_rate": 1.9484536082474227e-05,
      "loss": 0.2043,
      "step": 190
    },
    {
      "epoch": 0.2066115702479339,
      "grad_norm": 2.671358346939087,
      "learning_rate": 2.0515463917525773e-05,
      "loss": 0.1385,
      "step": 200
    },
    {
      "epoch": 0.21694214876033058,
      "grad_norm": 1.2910875082015991,
      "learning_rate": 2.154639175257732e-05,
      "loss": 0.1421,
      "step": 210
    },
    {
      "epoch": 0.22727272727272727,
      "grad_norm": 0.4317775070667267,
      "learning_rate": 2.2577319587628867e-05,
      "loss": 0.0995,
      "step": 220
    },
    {
      "epoch": 0.23760330578512398,
      "grad_norm": 0.3546595871448517,
      "learning_rate": 2.3608247422680412e-05,
      "loss": 0.116,
      "step": 230
    },
    {
      "epoch": 0.24793388429752067,
      "grad_norm": 0.3400242328643799,
      "learning_rate": 2.4639175257731957e-05,
      "loss": 0.0919,
      "step": 240
    },
    {
      "epoch": 0.25826446280991733,
      "grad_norm": 0.13257643580436707,
      "learning_rate": 2.5670103092783506e-05,
      "loss": 0.0857,
      "step": 250
    },
    {
      "epoch": 0.26859504132231404,
      "grad_norm": 1.43010413646698,
      "learning_rate": 2.670103092783505e-05,
      "loss": 0.1635,
      "step": 260
    },
    {
      "epoch": 0.27892561983471076,
      "grad_norm": 3.4565820693969727,
      "learning_rate": 2.77319587628866e-05,
      "loss": 0.1521,
      "step": 270
    },
    {
      "epoch": 0.2892561983471074,
      "grad_norm": 1.7479398250579834,
      "learning_rate": 2.8762886597938146e-05,
      "loss": 0.1312,
      "step": 280
    },
    {
      "epoch": 0.29958677685950413,
      "grad_norm": 0.3397315740585327,
      "learning_rate": 2.979381443298969e-05,
      "loss": 0.1201,
      "step": 290
    },
    {
      "epoch": 0.30991735537190085,
      "grad_norm": 2.7068402767181396,
      "learning_rate": 2.9908151549942597e-05,
      "loss": 0.1899,
      "step": 300
    },
    {
      "epoch": 0.3202479338842975,
      "grad_norm": 0.582635223865509,
      "learning_rate": 2.979334098737084e-05,
      "loss": 0.1217,
      "step": 310
    },
    {
      "epoch": 0.3305785123966942,
      "grad_norm": 5.252079486846924,
      "learning_rate": 2.9678530424799084e-05,
      "loss": 0.1351,
      "step": 320
    },
    {
      "epoch": 0.3409090909090909,
      "grad_norm": 1.9796040058135986,
      "learning_rate": 2.9563719862227327e-05,
      "loss": 0.1961,
      "step": 330
    },
    {
      "epoch": 0.3512396694214876,
      "grad_norm": 2.5909059047698975,
      "learning_rate": 2.944890929965557e-05,
      "loss": 0.1115,
      "step": 340
    },
    {
      "epoch": 0.3615702479338843,
      "grad_norm": 0.28774669766426086,
      "learning_rate": 2.9334098737083814e-05,
      "loss": 0.108,
      "step": 350
    },
    {
      "epoch": 0.371900826446281,
      "grad_norm": 0.676539421081543,
      "learning_rate": 2.9219288174512057e-05,
      "loss": 0.1044,
      "step": 360
    },
    {
      "epoch": 0.3822314049586777,
      "grad_norm": 5.058534622192383,
      "learning_rate": 2.91044776119403e-05,
      "loss": 0.1317,
      "step": 370
    },
    {
      "epoch": 0.3925619834710744,
      "grad_norm": 0.7016995549201965,
      "learning_rate": 2.8989667049368544e-05,
      "loss": 0.2024,
      "step": 380
    },
    {
      "epoch": 0.40289256198347106,
      "grad_norm": 2.7278494834899902,
      "learning_rate": 2.8874856486796787e-05,
      "loss": 0.1843,
      "step": 390
    },
    {
      "epoch": 0.4132231404958678,
      "grad_norm": 2.4777848720550537,
      "learning_rate": 2.876004592422503e-05,
      "loss": 0.1648,
      "step": 400
    },
    {
      "epoch": 0.42355371900826444,
      "grad_norm": 0.18564623594284058,
      "learning_rate": 2.8645235361653274e-05,
      "loss": 0.1628,
      "step": 410
    },
    {
      "epoch": 0.43388429752066116,
      "grad_norm": 0.4515726864337921,
      "learning_rate": 2.8530424799081517e-05,
      "loss": 0.1217,
      "step": 420
    },
    {
      "epoch": 0.44421487603305787,
      "grad_norm": 1.633537769317627,
      "learning_rate": 2.841561423650976e-05,
      "loss": 0.1168,
      "step": 430
    },
    {
      "epoch": 0.45454545454545453,
      "grad_norm": 0.11996642500162125,
      "learning_rate": 2.8300803673938004e-05,
      "loss": 0.0461,
      "step": 440
    },
    {
      "epoch": 0.46487603305785125,
      "grad_norm": 0.15292418003082275,
      "learning_rate": 2.8185993111366247e-05,
      "loss": 0.1679,
      "step": 450
    },
    {
      "epoch": 0.47520661157024796,
      "grad_norm": Infinity,
      "learning_rate": 2.807118254879449e-05,
      "loss": 0.0594,
      "step": 460
    },
    {
      "epoch": 0.4855371900826446,
      "grad_norm": 0.16092683374881744,
      "learning_rate": 2.7956371986222734e-05,
      "loss": 0.127,
      "step": 470
    },
    {
      "epoch": 0.49586776859504134,
      "grad_norm": 1.3988409042358398,
      "learning_rate": 2.7841561423650977e-05,
      "loss": 0.2205,
      "step": 480
    },
    {
      "epoch": 0.506198347107438,
      "grad_norm": 1.8357728719711304,
      "learning_rate": 2.772675086107922e-05,
      "loss": 0.1636,
      "step": 490
    },
    {
      "epoch": 0.5165289256198347,
      "grad_norm": 0.2015804499387741,
      "learning_rate": 2.7611940298507464e-05,
      "loss": 0.0379,
      "step": 500
    },
    {
      "epoch": 0.5268595041322314,
      "grad_norm": 2.8220150470733643,
      "learning_rate": 2.7497129735935707e-05,
      "loss": 0.3552,
      "step": 510
    },
    {
      "epoch": 0.5371900826446281,
      "grad_norm": 0.30692365765571594,
      "learning_rate": 2.738231917336395e-05,
      "loss": 0.0553,
      "step": 520
    },
    {
      "epoch": 0.5475206611570248,
      "grad_norm": 0.34080296754837036,
      "learning_rate": 2.7267508610792193e-05,
      "loss": 0.1087,
      "step": 530
    },
    {
      "epoch": 0.5578512396694215,
      "grad_norm": 0.5580190420150757,
      "learning_rate": 2.7152698048220437e-05,
      "loss": 0.0958,
      "step": 540
    },
    {
      "epoch": 0.5681818181818182,
      "grad_norm": 12.085930824279785,
      "learning_rate": 2.703788748564868e-05,
      "loss": 0.0611,
      "step": 550
    },
    {
      "epoch": 0.5785123966942148,
      "grad_norm": 0.10968444496393204,
      "learning_rate": 2.6923076923076923e-05,
      "loss": 0.0743,
      "step": 560
    },
    {
      "epoch": 0.5888429752066116,
      "grad_norm": 0.10683634132146835,
      "learning_rate": 2.6808266360505167e-05,
      "loss": 0.0253,
      "step": 570
    },
    {
      "epoch": 0.5991735537190083,
      "grad_norm": 2.8327040672302246,
      "learning_rate": 2.669345579793341e-05,
      "loss": 0.2562,
      "step": 580
    },
    {
      "epoch": 0.609504132231405,
      "grad_norm": 1.318297266960144,
      "learning_rate": 2.6578645235361653e-05,
      "loss": 0.1764,
      "step": 590
    },
    {
      "epoch": 0.6198347107438017,
      "grad_norm": 0.5438181757926941,
      "learning_rate": 2.64638346727899e-05,
      "loss": 0.0759,
      "step": 600
    },
    {
      "epoch": 0.6301652892561983,
      "grad_norm": 3.033223867416382,
      "learning_rate": 2.6349024110218143e-05,
      "loss": 0.0877,
      "step": 610
    },
    {
      "epoch": 0.640495867768595,
      "grad_norm": 1.8688043355941772,
      "learning_rate": 2.6234213547646387e-05,
      "loss": 0.1401,
      "step": 620
    },
    {
      "epoch": 0.6508264462809917,
      "grad_norm": 7.3099236488342285,
      "learning_rate": 2.611940298507463e-05,
      "loss": 0.1106,
      "step": 630
    },
    {
      "epoch": 0.6611570247933884,
      "grad_norm": 0.09869071841239929,
      "learning_rate": 2.6004592422502873e-05,
      "loss": 0.1311,
      "step": 640
    },
    {
      "epoch": 0.6714876033057852,
      "grad_norm": 0.11366278678178787,
      "learning_rate": 2.5889781859931116e-05,
      "loss": 0.1056,
      "step": 650
    },
    {
      "epoch": 0.6818181818181818,
      "grad_norm": 0.34495019912719727,
      "learning_rate": 2.577497129735936e-05,
      "loss": 0.1723,
      "step": 660
    },
    {
      "epoch": 0.6921487603305785,
      "grad_norm": 1.4882593154907227,
      "learning_rate": 2.5660160734787603e-05,
      "loss": 0.1289,
      "step": 670
    },
    {
      "epoch": 0.7024793388429752,
      "grad_norm": 0.1294734925031662,
      "learning_rate": 2.5545350172215846e-05,
      "loss": 0.0459,
      "step": 680
    },
    {
      "epoch": 0.7128099173553719,
      "grad_norm": 2.3632402420043945,
      "learning_rate": 2.543053960964409e-05,
      "loss": 0.0991,
      "step": 690
    },
    {
      "epoch": 0.7231404958677686,
      "grad_norm": 0.6482803821563721,
      "learning_rate": 2.5315729047072333e-05,
      "loss": 0.0951,
      "step": 700
    },
    {
      "epoch": 0.7334710743801653,
      "grad_norm": 10.988450050354004,
      "learning_rate": 2.5200918484500576e-05,
      "loss": 0.1382,
      "step": 710
    },
    {
      "epoch": 0.743801652892562,
      "grad_norm": 6.502532482147217,
      "learning_rate": 2.508610792192882e-05,
      "loss": 0.1248,
      "step": 720
    },
    {
      "epoch": 0.7541322314049587,
      "grad_norm": 1.6212464570999146,
      "learning_rate": 2.4971297359357063e-05,
      "loss": 0.1312,
      "step": 730
    },
    {
      "epoch": 0.7644628099173554,
      "grad_norm": 0.1698964685201645,
      "learning_rate": 2.4856486796785306e-05,
      "loss": 0.0426,
      "step": 740
    },
    {
      "epoch": 0.7747933884297521,
      "grad_norm": 0.9158139228820801,
      "learning_rate": 2.474167623421355e-05,
      "loss": 0.0804,
      "step": 750
    },
    {
      "epoch": 0.7851239669421488,
      "grad_norm": 0.331576943397522,
      "learning_rate": 2.4626865671641793e-05,
      "loss": 0.1417,
      "step": 760
    },
    {
      "epoch": 0.7954545454545454,
      "grad_norm": 1.113541841506958,
      "learning_rate": 2.4512055109070036e-05,
      "loss": 0.1026,
      "step": 770
    },
    {
      "epoch": 0.8057851239669421,
      "grad_norm": 0.2577393352985382,
      "learning_rate": 2.439724454649828e-05,
      "loss": 0.0726,
      "step": 780
    },
    {
      "epoch": 0.8161157024793388,
      "grad_norm": 0.1517639011144638,
      "learning_rate": 2.4282433983926523e-05,
      "loss": 0.0525,
      "step": 790
    },
    {
      "epoch": 0.8264462809917356,
      "grad_norm": 2.2239081859588623,
      "learning_rate": 2.4167623421354766e-05,
      "loss": 0.1137,
      "step": 800
    },
    {
      "epoch": 0.8367768595041323,
      "grad_norm": 3.3551881313323975,
      "learning_rate": 2.405281285878301e-05,
      "loss": 0.1175,
      "step": 810
    },
    {
      "epoch": 0.8471074380165289,
      "grad_norm": 6.345516681671143,
      "learning_rate": 2.3938002296211253e-05,
      "loss": 0.1228,
      "step": 820
    },
    {
      "epoch": 0.8574380165289256,
      "grad_norm": 0.5059385895729065,
      "learning_rate": 2.3823191733639496e-05,
      "loss": 0.1153,
      "step": 830
    },
    {
      "epoch": 0.8677685950413223,
      "grad_norm": 1.5861375331878662,
      "learning_rate": 2.370838117106774e-05,
      "loss": 0.082,
      "step": 840
    },
    {
      "epoch": 0.878099173553719,
      "grad_norm": 0.18188011646270752,
      "learning_rate": 2.3593570608495983e-05,
      "loss": 0.1176,
      "step": 850
    },
    {
      "epoch": 0.8884297520661157,
      "grad_norm": 0.838937520980835,
      "learning_rate": 2.3478760045924226e-05,
      "loss": 0.1271,
      "step": 860
    },
    {
      "epoch": 0.8987603305785123,
      "grad_norm": 0.20818538963794708,
      "learning_rate": 2.336394948335247e-05,
      "loss": 0.0957,
      "step": 870
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 0.15120859444141388,
      "learning_rate": 2.3249138920780712e-05,
      "loss": 0.0738,
      "step": 880
    },
    {
      "epoch": 0.9194214876033058,
      "grad_norm": 0.10466641187667847,
      "learning_rate": 2.3134328358208956e-05,
      "loss": 0.1121,
      "step": 890
    },
    {
      "epoch": 0.9297520661157025,
      "grad_norm": 3.2157866954803467,
      "learning_rate": 2.30195177956372e-05,
      "loss": 0.1101,
      "step": 900
    },
    {
      "epoch": 0.9400826446280992,
      "grad_norm": 0.13193802535533905,
      "learning_rate": 2.2904707233065442e-05,
      "loss": 0.0719,
      "step": 910
    },
    {
      "epoch": 0.9504132231404959,
      "grad_norm": 0.3981751799583435,
      "learning_rate": 2.2789896670493686e-05,
      "loss": 0.0862,
      "step": 920
    },
    {
      "epoch": 0.9607438016528925,
      "grad_norm": 0.1305660903453827,
      "learning_rate": 2.2675086107921932e-05,
      "loss": 0.1204,
      "step": 930
    },
    {
      "epoch": 0.9710743801652892,
      "grad_norm": 1.1762721538543701,
      "learning_rate": 2.2560275545350176e-05,
      "loss": 0.0717,
      "step": 940
    },
    {
      "epoch": 0.981404958677686,
      "grad_norm": 1.3196626901626587,
      "learning_rate": 2.244546498277842e-05,
      "loss": 0.1015,
      "step": 950
    },
    {
      "epoch": 0.9917355371900827,
      "grad_norm": 0.10447291284799576,
      "learning_rate": 2.2330654420206662e-05,
      "loss": 0.0817,
      "step": 960
    },
    {
      "epoch": 1.0,
      "eval_f1": 0.5596330275229358,
      "eval_loss": 0.10579660534858704,
      "eval_precision": 0.8840579710144928,
      "eval_recall": 0.40939597315436244,
      "eval_runtime": 2.2408,
      "eval_samples_per_second": 1480.723,
      "eval_steps_per_second": 92.824,
      "step": 968
    },
    {
      "epoch": 1.0020661157024793,
      "grad_norm": 2.311486005783081,
      "learning_rate": 2.2215843857634906e-05,
      "loss": 0.0974,
      "step": 970
    },
    {
      "epoch": 1.012396694214876,
      "grad_norm": 0.12361406534910202,
      "learning_rate": 2.210103329506315e-05,
      "loss": 0.0279,
      "step": 980
    },
    {
      "epoch": 1.0227272727272727,
      "grad_norm": 0.32095101475715637,
      "learning_rate": 2.1986222732491392e-05,
      "loss": 0.0522,
      "step": 990
    },
    {
      "epoch": 1.0330578512396693,
      "grad_norm": 6.848564147949219,
      "learning_rate": 2.1871412169919635e-05,
      "loss": 0.0634,
      "step": 1000
    },
    {
      "epoch": 1.0433884297520661,
      "grad_norm": 0.9597200751304626,
      "learning_rate": 2.175660160734788e-05,
      "loss": 0.0825,
      "step": 1010
    },
    {
      "epoch": 1.0537190082644627,
      "grad_norm": 1.8955026865005493,
      "learning_rate": 2.1641791044776122e-05,
      "loss": 0.1044,
      "step": 1020
    },
    {
      "epoch": 1.0640495867768596,
      "grad_norm": 0.05291564017534256,
      "learning_rate": 2.1526980482204365e-05,
      "loss": 0.0941,
      "step": 1030
    },
    {
      "epoch": 1.0743801652892562,
      "grad_norm": 0.10530944913625717,
      "learning_rate": 2.141216991963261e-05,
      "loss": 0.1121,
      "step": 1040
    },
    {
      "epoch": 1.084710743801653,
      "grad_norm": 3.0991244316101074,
      "learning_rate": 2.1297359357060852e-05,
      "loss": 0.0515,
      "step": 1050
    },
    {
      "epoch": 1.0950413223140496,
      "grad_norm": 1.0915745496749878,
      "learning_rate": 2.1182548794489095e-05,
      "loss": 0.0475,
      "step": 1060
    },
    {
      "epoch": 1.1053719008264462,
      "grad_norm": 0.06268442422151566,
      "learning_rate": 2.106773823191734e-05,
      "loss": 0.0954,
      "step": 1070
    },
    {
      "epoch": 1.115702479338843,
      "grad_norm": 0.068457692861557,
      "learning_rate": 2.0952927669345582e-05,
      "loss": 0.0124,
      "step": 1080
    },
    {
      "epoch": 1.1260330578512396,
      "grad_norm": 4.679382801055908,
      "learning_rate": 2.0838117106773825e-05,
      "loss": 0.0367,
      "step": 1090
    },
    {
      "epoch": 1.1363636363636362,
      "grad_norm": 0.058999281376600266,
      "learning_rate": 2.072330654420207e-05,
      "loss": 0.0508,
      "step": 1100
    },
    {
      "epoch": 1.146694214876033,
      "grad_norm": 0.07067402452230453,
      "learning_rate": 2.0608495981630312e-05,
      "loss": 0.0832,
      "step": 1110
    },
    {
      "epoch": 1.1570247933884297,
      "grad_norm": 0.12176882475614548,
      "learning_rate": 2.0493685419058555e-05,
      "loss": 0.034,
      "step": 1120
    },
    {
      "epoch": 1.1673553719008265,
      "grad_norm": 9.464786529541016,
      "learning_rate": 2.03788748564868e-05,
      "loss": 0.0493,
      "step": 1130
    },
    {
      "epoch": 1.177685950413223,
      "grad_norm": 6.560824871063232,
      "learning_rate": 2.0264064293915042e-05,
      "loss": 0.1055,
      "step": 1140
    },
    {
      "epoch": 1.18801652892562,
      "grad_norm": 0.32830026745796204,
      "learning_rate": 2.0149253731343285e-05,
      "loss": 0.0246,
      "step": 1150
    },
    {
      "epoch": 1.1983471074380165,
      "grad_norm": 0.0675118938088417,
      "learning_rate": 2.003444316877153e-05,
      "loss": 0.1005,
      "step": 1160
    },
    {
      "epoch": 1.2086776859504131,
      "grad_norm": 0.9539141654968262,
      "learning_rate": 1.991963260619977e-05,
      "loss": 0.0548,
      "step": 1170
    },
    {
      "epoch": 1.21900826446281,
      "grad_norm": 0.16660723090171814,
      "learning_rate": 1.9804822043628015e-05,
      "loss": 0.0962,
      "step": 1180
    },
    {
      "epoch": 1.2293388429752066,
      "grad_norm": 3.273716449737549,
      "learning_rate": 1.9690011481056258e-05,
      "loss": 0.0798,
      "step": 1190
    },
    {
      "epoch": 1.2396694214876034,
      "grad_norm": 5.815090656280518,
      "learning_rate": 1.95752009184845e-05,
      "loss": 0.0417,
      "step": 1200
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.0647139847278595,
      "learning_rate": 1.9460390355912745e-05,
      "loss": 0.0335,
      "step": 1210
    },
    {
      "epoch": 1.2603305785123968,
      "grad_norm": 2.0909781455993652,
      "learning_rate": 1.9345579793340988e-05,
      "loss": 0.0455,
      "step": 1220
    },
    {
      "epoch": 1.2706611570247934,
      "grad_norm": 0.06257973611354828,
      "learning_rate": 1.923076923076923e-05,
      "loss": 0.0375,
      "step": 1230
    },
    {
      "epoch": 1.28099173553719,
      "grad_norm": 0.13756097853183746,
      "learning_rate": 1.9115958668197475e-05,
      "loss": 0.0615,
      "step": 1240
    },
    {
      "epoch": 1.2913223140495869,
      "grad_norm": 0.06400162726640701,
      "learning_rate": 1.9001148105625718e-05,
      "loss": 0.0441,
      "step": 1250
    },
    {
      "epoch": 1.3016528925619835,
      "grad_norm": 0.7715556621551514,
      "learning_rate": 1.8886337543053965e-05,
      "loss": 0.0315,
      "step": 1260
    },
    {
      "epoch": 1.31198347107438,
      "grad_norm": 13.478341102600098,
      "learning_rate": 1.8771526980482208e-05,
      "loss": 0.0183,
      "step": 1270
    },
    {
      "epoch": 1.322314049586777,
      "grad_norm": 0.03623059764504433,
      "learning_rate": 1.8656716417910448e-05,
      "loss": 0.0409,
      "step": 1280
    },
    {
      "epoch": 1.3326446280991735,
      "grad_norm": 0.03126641735434532,
      "learning_rate": 1.854190585533869e-05,
      "loss": 0.0157,
      "step": 1290
    },
    {
      "epoch": 1.3429752066115703,
      "grad_norm": 0.23444493114948273,
      "learning_rate": 1.8427095292766935e-05,
      "loss": 0.1561,
      "step": 1300
    },
    {
      "epoch": 1.353305785123967,
      "grad_norm": 0.3812875747680664,
      "learning_rate": 1.8312284730195178e-05,
      "loss": 0.0342,
      "step": 1310
    },
    {
      "epoch": 1.3636363636363638,
      "grad_norm": 0.0401199571788311,
      "learning_rate": 1.819747416762342e-05,
      "loss": 0.1041,
      "step": 1320
    },
    {
      "epoch": 1.3739669421487604,
      "grad_norm": 4.646642208099365,
      "learning_rate": 1.8082663605051664e-05,
      "loss": 0.1067,
      "step": 1330
    },
    {
      "epoch": 1.384297520661157,
      "grad_norm": 0.04591190442442894,
      "learning_rate": 1.7967853042479908e-05,
      "loss": 0.0981,
      "step": 1340
    },
    {
      "epoch": 1.3946280991735538,
      "grad_norm": 0.08745554834604263,
      "learning_rate": 1.785304247990815e-05,
      "loss": 0.0616,
      "step": 1350
    },
    {
      "epoch": 1.4049586776859504,
      "grad_norm": 0.1081681102514267,
      "learning_rate": 1.7738231917336394e-05,
      "loss": 0.0451,
      "step": 1360
    },
    {
      "epoch": 1.415289256198347,
      "grad_norm": 3.9964396953582764,
      "learning_rate": 1.7623421354764638e-05,
      "loss": 0.1111,
      "step": 1370
    },
    {
      "epoch": 1.4256198347107438,
      "grad_norm": 0.12221821397542953,
      "learning_rate": 1.750861079219288e-05,
      "loss": 0.0709,
      "step": 1380
    },
    {
      "epoch": 1.4359504132231404,
      "grad_norm": 3.5499584674835205,
      "learning_rate": 1.7393800229621124e-05,
      "loss": 0.0416,
      "step": 1390
    },
    {
      "epoch": 1.4462809917355373,
      "grad_norm": 0.042199283838272095,
      "learning_rate": 1.7278989667049368e-05,
      "loss": 0.0412,
      "step": 1400
    },
    {
      "epoch": 1.4566115702479339,
      "grad_norm": 4.1418304443359375,
      "learning_rate": 1.716417910447761e-05,
      "loss": 0.1189,
      "step": 1410
    },
    {
      "epoch": 1.4669421487603307,
      "grad_norm": 3.625732898712158,
      "learning_rate": 1.7049368541905854e-05,
      "loss": 0.089,
      "step": 1420
    },
    {
      "epoch": 1.4772727272727273,
      "grad_norm": 5.018718719482422,
      "learning_rate": 1.6934557979334097e-05,
      "loss": 0.0851,
      "step": 1430
    },
    {
      "epoch": 1.487603305785124,
      "grad_norm": 1.3899238109588623,
      "learning_rate": 1.681974741676234e-05,
      "loss": 0.041,
      "step": 1440
    },
    {
      "epoch": 1.4979338842975207,
      "grad_norm": 0.056105878204107285,
      "learning_rate": 1.6704936854190584e-05,
      "loss": 0.0734,
      "step": 1450
    },
    {
      "epoch": 1.5082644628099173,
      "grad_norm": 13.807720184326172,
      "learning_rate": 1.6590126291618827e-05,
      "loss": 0.04,
      "step": 1460
    },
    {
      "epoch": 1.518595041322314,
      "grad_norm": 0.07853517681360245,
      "learning_rate": 1.647531572904707e-05,
      "loss": 0.0765,
      "step": 1470
    },
    {
      "epoch": 1.5289256198347108,
      "grad_norm": 9.813467025756836,
      "learning_rate": 1.6360505166475314e-05,
      "loss": 0.0622,
      "step": 1480
    },
    {
      "epoch": 1.5392561983471076,
      "grad_norm": 0.4560561180114746,
      "learning_rate": 1.6245694603903557e-05,
      "loss": 0.0412,
      "step": 1490
    },
    {
      "epoch": 1.549586776859504,
      "grad_norm": 4.721568584442139,
      "learning_rate": 1.61308840413318e-05,
      "loss": 0.0387,
      "step": 1500
    },
    {
      "epoch": 1.5599173553719008,
      "grad_norm": 0.8656852841377258,
      "learning_rate": 1.6016073478760044e-05,
      "loss": 0.0754,
      "step": 1510
    },
    {
      "epoch": 1.5702479338842976,
      "grad_norm": 3.358354091644287,
      "learning_rate": 1.5901262916188287e-05,
      "loss": 0.1288,
      "step": 1520
    },
    {
      "epoch": 1.5805785123966942,
      "grad_norm": 0.1323731243610382,
      "learning_rate": 1.578645235361653e-05,
      "loss": 0.0352,
      "step": 1530
    },
    {
      "epoch": 1.5909090909090908,
      "grad_norm": 0.4126746952533722,
      "learning_rate": 1.5671641791044774e-05,
      "loss": 0.0562,
      "step": 1540
    },
    {
      "epoch": 1.6012396694214877,
      "grad_norm": 0.08556484431028366,
      "learning_rate": 1.5556831228473017e-05,
      "loss": 0.0898,
      "step": 1550
    },
    {
      "epoch": 1.6115702479338843,
      "grad_norm": 4.069133281707764,
      "learning_rate": 1.544202066590126e-05,
      "loss": 0.0705,
      "step": 1560
    },
    {
      "epoch": 1.6219008264462809,
      "grad_norm": 1.7846415042877197,
      "learning_rate": 1.5327210103329504e-05,
      "loss": 0.0588,
      "step": 1570
    },
    {
      "epoch": 1.6322314049586777,
      "grad_norm": 0.05055300518870354,
      "learning_rate": 1.5212399540757749e-05,
      "loss": 0.0897,
      "step": 1580
    },
    {
      "epoch": 1.6425619834710745,
      "grad_norm": 0.10723086446523666,
      "learning_rate": 1.5097588978185992e-05,
      "loss": 0.0893,
      "step": 1590
    },
    {
      "epoch": 1.6528925619834711,
      "grad_norm": 0.25716471672058105,
      "learning_rate": 1.4982778415614237e-05,
      "loss": 0.0458,
      "step": 1600
    },
    {
      "epoch": 1.6632231404958677,
      "grad_norm": 0.05539458617568016,
      "learning_rate": 1.486796785304248e-05,
      "loss": 0.0626,
      "step": 1610
    },
    {
      "epoch": 1.6735537190082646,
      "grad_norm": 4.539200782775879,
      "learning_rate": 1.4753157290470724e-05,
      "loss": 0.1245,
      "step": 1620
    },
    {
      "epoch": 1.6838842975206612,
      "grad_norm": 6.722307205200195,
      "learning_rate": 1.4638346727898967e-05,
      "loss": 0.0566,
      "step": 1630
    },
    {
      "epoch": 1.6942148760330578,
      "grad_norm": 10.853208541870117,
      "learning_rate": 1.452353616532721e-05,
      "loss": 0.0349,
      "step": 1640
    },
    {
      "epoch": 1.7045454545454546,
      "grad_norm": 0.040719691663980484,
      "learning_rate": 1.4408725602755454e-05,
      "loss": 0.003,
      "step": 1650
    },
    {
      "epoch": 1.7148760330578512,
      "grad_norm": 0.03128989040851593,
      "learning_rate": 1.4293915040183697e-05,
      "loss": 0.0557,
      "step": 1660
    },
    {
      "epoch": 1.7252066115702478,
      "grad_norm": 5.296324729919434,
      "learning_rate": 1.4179104477611942e-05,
      "loss": 0.159,
      "step": 1670
    },
    {
      "epoch": 1.7355371900826446,
      "grad_norm": 0.11026624590158463,
      "learning_rate": 1.4064293915040185e-05,
      "loss": 0.0396,
      "step": 1680
    },
    {
      "epoch": 1.7458677685950414,
      "grad_norm": 0.03577600419521332,
      "learning_rate": 1.3949483352468428e-05,
      "loss": 0.0105,
      "step": 1690
    },
    {
      "epoch": 1.756198347107438,
      "grad_norm": 0.03857122361660004,
      "learning_rate": 1.3834672789896672e-05,
      "loss": 0.0664,
      "step": 1700
    },
    {
      "epoch": 1.7665289256198347,
      "grad_norm": 5.140746116638184,
      "learning_rate": 1.3719862227324915e-05,
      "loss": 0.0794,
      "step": 1710
    },
    {
      "epoch": 1.7768595041322315,
      "grad_norm": 2.3144688606262207,
      "learning_rate": 1.3605051664753158e-05,
      "loss": 0.1109,
      "step": 1720
    },
    {
      "epoch": 1.787190082644628,
      "grad_norm": 0.034797243773937225,
      "learning_rate": 1.3490241102181402e-05,
      "loss": 0.0518,
      "step": 1730
    },
    {
      "epoch": 1.7975206611570247,
      "grad_norm": 0.04481451213359833,
      "learning_rate": 1.3375430539609645e-05,
      "loss": 0.0176,
      "step": 1740
    },
    {
      "epoch": 1.8078512396694215,
      "grad_norm": 0.04771125689148903,
      "learning_rate": 1.3260619977037888e-05,
      "loss": 0.0581,
      "step": 1750
    },
    {
      "epoch": 1.8181818181818183,
      "grad_norm": 0.04309640824794769,
      "learning_rate": 1.3145809414466132e-05,
      "loss": 0.0036,
      "step": 1760
    },
    {
      "epoch": 1.8285123966942147,
      "grad_norm": 0.03966256603598595,
      "learning_rate": 1.3030998851894375e-05,
      "loss": 0.0645,
      "step": 1770
    },
    {
      "epoch": 1.8388429752066116,
      "grad_norm": 0.10036647319793701,
      "learning_rate": 1.2916188289322618e-05,
      "loss": 0.0248,
      "step": 1780
    },
    {
      "epoch": 1.8491735537190084,
      "grad_norm": 0.563675045967102,
      "learning_rate": 1.2801377726750862e-05,
      "loss": 0.0675,
      "step": 1790
    },
    {
      "epoch": 1.859504132231405,
      "grad_norm": 0.08177992701530457,
      "learning_rate": 1.2686567164179105e-05,
      "loss": 0.0755,
      "step": 1800
    },
    {
      "epoch": 1.8698347107438016,
      "grad_norm": 1.2194360494613647,
      "learning_rate": 1.2571756601607348e-05,
      "loss": 0.0834,
      "step": 1810
    },
    {
      "epoch": 1.8801652892561984,
      "grad_norm": 6.594037055969238,
      "learning_rate": 1.2456946039035591e-05,
      "loss": 0.077,
      "step": 1820
    },
    {
      "epoch": 1.890495867768595,
      "grad_norm": 3.1627306938171387,
      "learning_rate": 1.2342135476463835e-05,
      "loss": 0.0515,
      "step": 1830
    },
    {
      "epoch": 1.9008264462809916,
      "grad_norm": 0.28537365794181824,
      "learning_rate": 1.222732491389208e-05,
      "loss": 0.0282,
      "step": 1840
    },
    {
      "epoch": 1.9111570247933884,
      "grad_norm": 0.17186178267002106,
      "learning_rate": 1.2112514351320323e-05,
      "loss": 0.065,
      "step": 1850
    },
    {
      "epoch": 1.9214876033057853,
      "grad_norm": 0.11154166609048843,
      "learning_rate": 1.1997703788748566e-05,
      "loss": 0.0368,
      "step": 1860
    },
    {
      "epoch": 1.9318181818181817,
      "grad_norm": 0.2892882227897644,
      "learning_rate": 1.188289322617681e-05,
      "loss": 0.0778,
      "step": 1870
    },
    {
      "epoch": 1.9421487603305785,
      "grad_norm": 0.18745262920856476,
      "learning_rate": 1.1768082663605053e-05,
      "loss": 0.0668,
      "step": 1880
    },
    {
      "epoch": 1.9524793388429753,
      "grad_norm": 0.03350815176963806,
      "learning_rate": 1.1653272101033296e-05,
      "loss": 0.0601,
      "step": 1890
    },
    {
      "epoch": 1.962809917355372,
      "grad_norm": 4.264648914337158,
      "learning_rate": 1.153846153846154e-05,
      "loss": 0.0819,
      "step": 1900
    },
    {
      "epoch": 1.9731404958677685,
      "grad_norm": 0.07085417956113815,
      "learning_rate": 1.1423650975889783e-05,
      "loss": 0.0277,
      "step": 1910
    },
    {
      "epoch": 1.9834710743801653,
      "grad_norm": 0.241835355758667,
      "learning_rate": 1.1308840413318026e-05,
      "loss": 0.0401,
      "step": 1920
    },
    {
      "epoch": 1.993801652892562,
      "grad_norm": 0.15360112488269806,
      "learning_rate": 1.119402985074627e-05,
      "loss": 0.0269,
      "step": 1930
    },
    {
      "epoch": 2.0,
      "eval_f1": 0.75,
      "eval_loss": 0.08372092247009277,
      "eval_precision": 0.8015267175572519,
      "eval_recall": 0.7046979865771812,
      "eval_runtime": 1.8998,
      "eval_samples_per_second": 1746.52,
      "eval_steps_per_second": 109.486,
      "step": 1936
    },
    {
      "epoch": 2.0041322314049586,
      "grad_norm": 0.29434800148010254,
      "learning_rate": 1.1079219288174513e-05,
      "loss": 0.0389,
      "step": 1940
    },
    {
      "epoch": 2.0144628099173554,
      "grad_norm": 0.03364384546875954,
      "learning_rate": 1.0964408725602756e-05,
      "loss": 0.1016,
      "step": 1950
    },
    {
      "epoch": 2.024793388429752,
      "grad_norm": 0.1209648922085762,
      "learning_rate": 1.0849598163031e-05,
      "loss": 0.0114,
      "step": 1960
    },
    {
      "epoch": 2.0351239669421486,
      "grad_norm": 0.15485773980617523,
      "learning_rate": 1.0734787600459243e-05,
      "loss": 0.0165,
      "step": 1970
    },
    {
      "epoch": 2.0454545454545454,
      "grad_norm": 0.8469159603118896,
      "learning_rate": 1.0619977037887486e-05,
      "loss": 0.0072,
      "step": 1980
    },
    {
      "epoch": 2.0557851239669422,
      "grad_norm": 1.496315598487854,
      "learning_rate": 1.050516647531573e-05,
      "loss": 0.0684,
      "step": 1990
    },
    {
      "epoch": 2.0661157024793386,
      "grad_norm": 0.07400106638669968,
      "learning_rate": 1.0390355912743974e-05,
      "loss": 0.0112,
      "step": 2000
    },
    {
      "epoch": 2.0764462809917354,
      "grad_norm": 0.026873940601944923,
      "learning_rate": 1.0275545350172218e-05,
      "loss": 0.021,
      "step": 2010
    },
    {
      "epoch": 2.0867768595041323,
      "grad_norm": 0.017958778887987137,
      "learning_rate": 1.0160734787600461e-05,
      "loss": 0.042,
      "step": 2020
    },
    {
      "epoch": 2.097107438016529,
      "grad_norm": 0.06053684651851654,
      "learning_rate": 1.0045924225028704e-05,
      "loss": 0.024,
      "step": 2030
    },
    {
      "epoch": 2.1074380165289255,
      "grad_norm": 0.015860529616475105,
      "learning_rate": 9.931113662456947e-06,
      "loss": 0.0051,
      "step": 2040
    },
    {
      "epoch": 2.1177685950413223,
      "grad_norm": 0.029030796140432358,
      "learning_rate": 9.81630309988519e-06,
      "loss": 0.0012,
      "step": 2050
    },
    {
      "epoch": 2.128099173553719,
      "grad_norm": 0.014432760886847973,
      "learning_rate": 9.701492537313434e-06,
      "loss": 0.0376,
      "step": 2060
    },
    {
      "epoch": 2.1384297520661155,
      "grad_norm": 0.0509394146502018,
      "learning_rate": 9.586681974741677e-06,
      "loss": 0.0251,
      "step": 2070
    },
    {
      "epoch": 2.1487603305785123,
      "grad_norm": 0.01618088409304619,
      "learning_rate": 9.47187141216992e-06,
      "loss": 0.0564,
      "step": 2080
    },
    {
      "epoch": 2.159090909090909,
      "grad_norm": 0.01936931721866131,
      "learning_rate": 9.357060849598162e-06,
      "loss": 0.0017,
      "step": 2090
    },
    {
      "epoch": 2.169421487603306,
      "grad_norm": 0.017130615189671516,
      "learning_rate": 9.242250287026406e-06,
      "loss": 0.0016,
      "step": 2100
    },
    {
      "epoch": 2.1797520661157024,
      "grad_norm": 0.01669587381184101,
      "learning_rate": 9.127439724454649e-06,
      "loss": 0.01,
      "step": 2110
    },
    {
      "epoch": 2.190082644628099,
      "grad_norm": 0.08184333145618439,
      "learning_rate": 9.012629161882892e-06,
      "loss": 0.0014,
      "step": 2120
    },
    {
      "epoch": 2.200413223140496,
      "grad_norm": 0.02985869161784649,
      "learning_rate": 8.897818599311136e-06,
      "loss": 0.0289,
      "step": 2130
    },
    {
      "epoch": 2.2107438016528924,
      "grad_norm": 0.22759442031383514,
      "learning_rate": 8.783008036739379e-06,
      "loss": 0.0156,
      "step": 2140
    },
    {
      "epoch": 2.2210743801652892,
      "grad_norm": 0.01581576094031334,
      "learning_rate": 8.668197474167622e-06,
      "loss": 0.0384,
      "step": 2150
    },
    {
      "epoch": 2.231404958677686,
      "grad_norm": 0.08684463053941727,
      "learning_rate": 8.553386911595867e-06,
      "loss": 0.0008,
      "step": 2160
    },
    {
      "epoch": 2.2417355371900825,
      "grad_norm": 0.010637611150741577,
      "learning_rate": 8.43857634902411e-06,
      "loss": 0.0178,
      "step": 2170
    },
    {
      "epoch": 2.2520661157024793,
      "grad_norm": 0.015574842691421509,
      "learning_rate": 8.323765786452354e-06,
      "loss": 0.0091,
      "step": 2180
    },
    {
      "epoch": 2.262396694214876,
      "grad_norm": 2.1056108474731445,
      "learning_rate": 8.208955223880597e-06,
      "loss": 0.0048,
      "step": 2190
    },
    {
      "epoch": 2.2727272727272725,
      "grad_norm": 0.10512388497591019,
      "learning_rate": 8.09414466130884e-06,
      "loss": 0.0014,
      "step": 2200
    },
    {
      "epoch": 2.2830578512396693,
      "grad_norm": 16.4732666015625,
      "learning_rate": 7.979334098737084e-06,
      "loss": 0.0392,
      "step": 2210
    },
    {
      "epoch": 2.293388429752066,
      "grad_norm": 6.2373127937316895,
      "learning_rate": 7.864523536165327e-06,
      "loss": 0.0317,
      "step": 2220
    },
    {
      "epoch": 2.303719008264463,
      "grad_norm": 1.0776584148406982,
      "learning_rate": 7.74971297359357e-06,
      "loss": 0.0264,
      "step": 2230
    },
    {
      "epoch": 2.3140495867768593,
      "grad_norm": 0.053976260125637054,
      "learning_rate": 7.634902411021814e-06,
      "loss": 0.0067,
      "step": 2240
    },
    {
      "epoch": 2.324380165289256,
      "grad_norm": 4.416682243347168,
      "learning_rate": 7.520091848450057e-06,
      "loss": 0.0057,
      "step": 2250
    },
    {
      "epoch": 2.334710743801653,
      "grad_norm": 0.01854828931391239,
      "learning_rate": 7.405281285878301e-06,
      "loss": 0.0029,
      "step": 2260
    },
    {
      "epoch": 2.3450413223140494,
      "grad_norm": 0.015389355830848217,
      "learning_rate": 7.290470723306544e-06,
      "loss": 0.0229,
      "step": 2270
    },
    {
      "epoch": 2.355371900826446,
      "grad_norm": 0.009283600375056267,
      "learning_rate": 7.175660160734788e-06,
      "loss": 0.0063,
      "step": 2280
    },
    {
      "epoch": 2.365702479338843,
      "grad_norm": 5.796840667724609,
      "learning_rate": 7.060849598163032e-06,
      "loss": 0.0334,
      "step": 2290
    },
    {
      "epoch": 2.37603305785124,
      "grad_norm": 3.29937744140625,
      "learning_rate": 6.946039035591275e-06,
      "loss": 0.0558,
      "step": 2300
    },
    {
      "epoch": 2.3863636363636362,
      "grad_norm": 0.011194094084203243,
      "learning_rate": 6.831228473019518e-06,
      "loss": 0.001,
      "step": 2310
    },
    {
      "epoch": 2.396694214876033,
      "grad_norm": 0.026066169142723083,
      "learning_rate": 6.716417910447762e-06,
      "loss": 0.0338,
      "step": 2320
    },
    {
      "epoch": 2.40702479338843,
      "grad_norm": 0.015735050663352013,
      "learning_rate": 6.601607347876005e-06,
      "loss": 0.0046,
      "step": 2330
    },
    {
      "epoch": 2.4173553719008263,
      "grad_norm": 0.01950645074248314,
      "learning_rate": 6.486796785304248e-06,
      "loss": 0.0705,
      "step": 2340
    },
    {
      "epoch": 2.427685950413223,
      "grad_norm": 0.04001322388648987,
      "learning_rate": 6.371986222732492e-06,
      "loss": 0.0205,
      "step": 2350
    },
    {
      "epoch": 2.43801652892562,
      "grad_norm": 0.010707545094192028,
      "learning_rate": 6.257175660160735e-06,
      "loss": 0.0171,
      "step": 2360
    },
    {
      "epoch": 2.4483471074380168,
      "grad_norm": 0.05429968237876892,
      "learning_rate": 6.142365097588979e-06,
      "loss": 0.0728,
      "step": 2370
    },
    {
      "epoch": 2.458677685950413,
      "grad_norm": 0.06518734991550446,
      "learning_rate": 6.027554535017222e-06,
      "loss": 0.0006,
      "step": 2380
    },
    {
      "epoch": 2.46900826446281,
      "grad_norm": 0.206487774848938,
      "learning_rate": 5.912743972445466e-06,
      "loss": 0.0026,
      "step": 2390
    },
    {
      "epoch": 2.479338842975207,
      "grad_norm": 0.21829916536808014,
      "learning_rate": 5.797933409873709e-06,
      "loss": 0.0154,
      "step": 2400
    },
    {
      "epoch": 2.489669421487603,
      "grad_norm": 15.470427513122559,
      "learning_rate": 5.683122847301952e-06,
      "loss": 0.0437,
      "step": 2410
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.010408999398350716,
      "learning_rate": 5.5683122847301955e-06,
      "loss": 0.0047,
      "step": 2420
    },
    {
      "epoch": 2.510330578512397,
      "grad_norm": 0.012919877655804157,
      "learning_rate": 5.453501722158439e-06,
      "loss": 0.0012,
      "step": 2430
    },
    {
      "epoch": 2.5206611570247937,
      "grad_norm": 0.014037610962986946,
      "learning_rate": 5.338691159586682e-06,
      "loss": 0.0024,
      "step": 2440
    },
    {
      "epoch": 2.53099173553719,
      "grad_norm": 0.6078997254371643,
      "learning_rate": 5.2238805970149255e-06,
      "loss": 0.0314,
      "step": 2450
    },
    {
      "epoch": 2.541322314049587,
      "grad_norm": 0.011747683398425579,
      "learning_rate": 5.10907003444317e-06,
      "loss": 0.0008,
      "step": 2460
    },
    {
      "epoch": 2.5516528925619832,
      "grad_norm": 0.06111724302172661,
      "learning_rate": 4.994259471871413e-06,
      "loss": 0.0093,
      "step": 2470
    },
    {
      "epoch": 2.56198347107438,
      "grad_norm": 0.017711205407977104,
      "learning_rate": 4.879448909299656e-06,
      "loss": 0.0193,
      "step": 2480
    },
    {
      "epoch": 2.572314049586777,
      "grad_norm": 0.08639996498823166,
      "learning_rate": 4.7646383467278995e-06,
      "loss": 0.0203,
      "step": 2490
    },
    {
      "epoch": 2.5826446280991737,
      "grad_norm": 0.019805293530225754,
      "learning_rate": 4.649827784156142e-06,
      "loss": 0.0199,
      "step": 2500
    },
    {
      "epoch": 2.59297520661157,
      "grad_norm": 0.025174913927912712,
      "learning_rate": 4.535017221584385e-06,
      "loss": 0.0272,
      "step": 2510
    },
    {
      "epoch": 2.603305785123967,
      "grad_norm": 0.013711423613131046,
      "learning_rate": 4.420206659012629e-06,
      "loss": 0.0401,
      "step": 2520
    },
    {
      "epoch": 2.6136363636363638,
      "grad_norm": 5.518873691558838,
      "learning_rate": 4.305396096440872e-06,
      "loss": 0.0521,
      "step": 2530
    },
    {
      "epoch": 2.62396694214876,
      "grad_norm": 1.1359870433807373,
      "learning_rate": 4.190585533869116e-06,
      "loss": 0.073,
      "step": 2540
    },
    {
      "epoch": 2.634297520661157,
      "grad_norm": 0.01118761207908392,
      "learning_rate": 4.075774971297359e-06,
      "loss": 0.003,
      "step": 2550
    },
    {
      "epoch": 2.644628099173554,
      "grad_norm": 0.4222012162208557,
      "learning_rate": 3.960964408725603e-06,
      "loss": 0.03,
      "step": 2560
    },
    {
      "epoch": 2.6549586776859506,
      "grad_norm": 0.027082763612270355,
      "learning_rate": 3.846153846153846e-06,
      "loss": 0.0549,
      "step": 2570
    },
    {
      "epoch": 2.665289256198347,
      "grad_norm": 0.009213513694703579,
      "learning_rate": 3.7313432835820897e-06,
      "loss": 0.0133,
      "step": 2580
    },
    {
      "epoch": 2.675619834710744,
      "grad_norm": 0.1870582401752472,
      "learning_rate": 3.616532721010333e-06,
      "loss": 0.0257,
      "step": 2590
    },
    {
      "epoch": 2.6859504132231407,
      "grad_norm": 0.03753463923931122,
      "learning_rate": 3.5017221584385767e-06,
      "loss": 0.0063,
      "step": 2600
    },
    {
      "epoch": 2.696280991735537,
      "grad_norm": 0.027729174122214317,
      "learning_rate": 3.38691159586682e-06,
      "loss": 0.0351,
      "step": 2610
    },
    {
      "epoch": 2.706611570247934,
      "grad_norm": 0.010327420197427273,
      "learning_rate": 3.2721010332950633e-06,
      "loss": 0.0061,
      "step": 2620
    },
    {
      "epoch": 2.7169421487603307,
      "grad_norm": 0.030575547367334366,
      "learning_rate": 3.1572904707233066e-06,
      "loss": 0.0274,
      "step": 2630
    },
    {
      "epoch": 2.7272727272727275,
      "grad_norm": 4.0860466957092285,
      "learning_rate": 3.0424799081515503e-06,
      "loss": 0.0049,
      "step": 2640
    },
    {
      "epoch": 2.737603305785124,
      "grad_norm": 0.009876519441604614,
      "learning_rate": 2.9276693455797936e-06,
      "loss": 0.0833,
      "step": 2650
    },
    {
      "epoch": 2.7479338842975207,
      "grad_norm": 0.08294379711151123,
      "learning_rate": 2.812858783008037e-06,
      "loss": 0.0074,
      "step": 2660
    },
    {
      "epoch": 2.758264462809917,
      "grad_norm": 0.019592834636569023,
      "learning_rate": 2.6980482204362803e-06,
      "loss": 0.021,
      "step": 2670
    },
    {
      "epoch": 2.768595041322314,
      "grad_norm": 1.7994815111160278,
      "learning_rate": 2.583237657864524e-06,
      "loss": 0.0031,
      "step": 2680
    },
    {
      "epoch": 2.7789256198347108,
      "grad_norm": 0.4329666793346405,
      "learning_rate": 2.4684270952927673e-06,
      "loss": 0.0392,
      "step": 2690
    },
    {
      "epoch": 2.7892561983471076,
      "grad_norm": 0.021187681704759598,
      "learning_rate": 2.3536165327210106e-06,
      "loss": 0.0008,
      "step": 2700
    },
    {
      "epoch": 2.799586776859504,
      "grad_norm": 0.20203857123851776,
      "learning_rate": 2.2388059701492535e-06,
      "loss": 0.0009,
      "step": 2710
    },
    {
      "epoch": 2.809917355371901,
      "grad_norm": 0.11407459527254105,
      "learning_rate": 2.123995407577497e-06,
      "loss": 0.0155,
      "step": 2720
    },
    {
      "epoch": 2.8202479338842976,
      "grad_norm": 0.01591872237622738,
      "learning_rate": 2.0091848450057405e-06,
      "loss": 0.0467,
      "step": 2730
    },
    {
      "epoch": 2.830578512396694,
      "grad_norm": 0.02089337259531021,
      "learning_rate": 1.8943742824339838e-06,
      "loss": 0.0739,
      "step": 2740
    },
    {
      "epoch": 2.840909090909091,
      "grad_norm": 0.01793278194963932,
      "learning_rate": 1.7795637198622273e-06,
      "loss": 0.0111,
      "step": 2750
    },
    {
      "epoch": 2.8512396694214877,
      "grad_norm": 0.05585432052612305,
      "learning_rate": 1.6647531572904708e-06,
      "loss": 0.003,
      "step": 2760
    },
    {
      "epoch": 2.8615702479338845,
      "grad_norm": 0.11560693383216858,
      "learning_rate": 1.5499425947187141e-06,
      "loss": 0.0475,
      "step": 2770
    },
    {
      "epoch": 2.871900826446281,
      "grad_norm": 0.09326796233654022,
      "learning_rate": 1.4351320321469576e-06,
      "loss": 0.042,
      "step": 2780
    },
    {
      "epoch": 2.8822314049586777,
      "grad_norm": 0.06783308833837509,
      "learning_rate": 1.320321469575201e-06,
      "loss": 0.0913,
      "step": 2790
    },
    {
      "epoch": 2.8925619834710745,
      "grad_norm": 0.2417120337486267,
      "learning_rate": 1.2055109070034445e-06,
      "loss": 0.048,
      "step": 2800
    },
    {
      "epoch": 2.902892561983471,
      "grad_norm": 0.06778258085250854,
      "learning_rate": 1.0907003444316876e-06,
      "loss": 0.0015,
      "step": 2810
    },
    {
      "epoch": 2.9132231404958677,
      "grad_norm": 0.6627769470214844,
      "learning_rate": 9.75889781859931e-07,
      "loss": 0.0195,
      "step": 2820
    },
    {
      "epoch": 2.9235537190082646,
      "grad_norm": 1.0375572443008423,
      "learning_rate": 8.610792192881746e-07,
      "loss": 0.0056,
      "step": 2830
    },
    {
      "epoch": 2.9338842975206614,
      "grad_norm": 0.28327345848083496,
      "learning_rate": 7.46268656716418e-07,
      "loss": 0.0322,
      "step": 2840
    },
    {
      "epoch": 2.9442148760330578,
      "grad_norm": 0.009274428710341454,
      "learning_rate": 6.314580941446614e-07,
      "loss": 0.0013,
      "step": 2850
    },
    {
      "epoch": 2.9545454545454546,
      "grad_norm": 0.024777423590421677,
      "learning_rate": 5.166475315729047e-07,
      "loss": 0.0019,
      "step": 2860
    },
    {
      "epoch": 2.964876033057851,
      "grad_norm": 0.03672425076365471,
      "learning_rate": 4.018369690011481e-07,
      "loss": 0.0029,
      "step": 2870
    },
    {
      "epoch": 2.975206611570248,
      "grad_norm": 0.16736921668052673,
      "learning_rate": 2.870264064293915e-07,
      "loss": 0.0411,
      "step": 2880
    },
    {
      "epoch": 2.9855371900826446,
      "grad_norm": 7.7386860847473145,
      "learning_rate": 1.722158438576349e-07,
      "loss": 0.0601,
      "step": 2890
    },
    {
      "epoch": 2.9958677685950414,
      "grad_norm": 0.014023413881659508,
      "learning_rate": 5.74052812858783e-08,
      "loss": 0.0079,
      "step": 2900
    },
    {
      "epoch": 3.0,
      "eval_f1": 0.7647058823529411,
      "eval_loss": 0.0939759686589241,
      "eval_precision": 0.8455284552845529,
      "eval_recall": 0.697986577181208,
      "eval_runtime": 1.9009,
      "eval_samples_per_second": 1745.452,
      "eval_steps_per_second": 109.42,
      "step": 2904
    }
  ],
  "logging_steps": 10,
  "max_steps": 2904,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 1
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1538443251141120.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
