{
  "best_global_step": 1936,
  "best_metric": 0.08372092247009277,
  "best_model_checkpoint": "/home/snguyen/spot-the-scam-project/artifacts/transformer/checkpoint-1936",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 1936,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010330578512396695,
      "grad_norm": 4.703976154327393,
      "learning_rate": 9.278350515463919e-07,
      "loss": 0.6766,
      "step": 10
    },
    {
      "epoch": 0.02066115702479339,
      "grad_norm": 3.4400298595428467,
      "learning_rate": 1.9587628865979384e-06,
      "loss": 0.6511,
      "step": 20
    },
    {
      "epoch": 0.030991735537190084,
      "grad_norm": 4.108104705810547,
      "learning_rate": 2.989690721649485e-06,
      "loss": 0.6006,
      "step": 30
    },
    {
      "epoch": 0.04132231404958678,
      "grad_norm": 3.8866748809814453,
      "learning_rate": 4.020618556701031e-06,
      "loss": 0.5292,
      "step": 40
    },
    {
      "epoch": 0.05165289256198347,
      "grad_norm": 2.5028867721557617,
      "learning_rate": 5.051546391752578e-06,
      "loss": 0.4198,
      "step": 50
    },
    {
      "epoch": 0.06198347107438017,
      "grad_norm": 1.6685080528259277,
      "learning_rate": 6.082474226804124e-06,
      "loss": 0.3294,
      "step": 60
    },
    {
      "epoch": 0.07231404958677685,
      "grad_norm": 1.0191187858581543,
      "learning_rate": 7.11340206185567e-06,
      "loss": 0.2491,
      "step": 70
    },
    {
      "epoch": 0.08264462809917356,
      "grad_norm": 0.9723655581474304,
      "learning_rate": 8.144329896907216e-06,
      "loss": 0.2003,
      "step": 80
    },
    {
      "epoch": 0.09297520661157024,
      "grad_norm": 0.6860754489898682,
      "learning_rate": 9.175257731958764e-06,
      "loss": 0.1322,
      "step": 90
    },
    {
      "epoch": 0.10330578512396695,
      "grad_norm": 0.47402727603912354,
      "learning_rate": 1.020618556701031e-05,
      "loss": 0.1129,
      "step": 100
    },
    {
      "epoch": 0.11363636363636363,
      "grad_norm": 0.40855422616004944,
      "learning_rate": 1.1237113402061856e-05,
      "loss": 0.068,
      "step": 110
    },
    {
      "epoch": 0.12396694214876033,
      "grad_norm": 2.5328145027160645,
      "learning_rate": 1.2268041237113401e-05,
      "loss": 0.2872,
      "step": 120
    },
    {
      "epoch": 0.13429752066115702,
      "grad_norm": 1.6092427968978882,
      "learning_rate": 1.3298969072164948e-05,
      "loss": 0.1948,
      "step": 130
    },
    {
      "epoch": 0.1446280991735537,
      "grad_norm": 0.8369685411453247,
      "learning_rate": 1.4329896907216495e-05,
      "loss": 0.1408,
      "step": 140
    },
    {
      "epoch": 0.15495867768595042,
      "grad_norm": 5.178857803344727,
      "learning_rate": 1.536082474226804e-05,
      "loss": 0.3299,
      "step": 150
    },
    {
      "epoch": 0.1652892561983471,
      "grad_norm": 1.108429193496704,
      "learning_rate": 1.6391752577319588e-05,
      "loss": 0.1984,
      "step": 160
    },
    {
      "epoch": 0.1756198347107438,
      "grad_norm": 1.3731595277786255,
      "learning_rate": 1.7422680412371137e-05,
      "loss": 0.2273,
      "step": 170
    },
    {
      "epoch": 0.1859504132231405,
      "grad_norm": 1.8679790496826172,
      "learning_rate": 1.8453608247422682e-05,
      "loss": 0.19,
      "step": 180
    },
    {
      "epoch": 0.1962809917355372,
      "grad_norm": 0.4076886773109436,
      "learning_rate": 1.9484536082474227e-05,
      "loss": 0.2043,
      "step": 190
    },
    {
      "epoch": 0.2066115702479339,
      "grad_norm": 2.671358346939087,
      "learning_rate": 2.0515463917525773e-05,
      "loss": 0.1385,
      "step": 200
    },
    {
      "epoch": 0.21694214876033058,
      "grad_norm": 1.2910875082015991,
      "learning_rate": 2.154639175257732e-05,
      "loss": 0.1421,
      "step": 210
    },
    {
      "epoch": 0.22727272727272727,
      "grad_norm": 0.4317775070667267,
      "learning_rate": 2.2577319587628867e-05,
      "loss": 0.0995,
      "step": 220
    },
    {
      "epoch": 0.23760330578512398,
      "grad_norm": 0.3546595871448517,
      "learning_rate": 2.3608247422680412e-05,
      "loss": 0.116,
      "step": 230
    },
    {
      "epoch": 0.24793388429752067,
      "grad_norm": 0.3400242328643799,
      "learning_rate": 2.4639175257731957e-05,
      "loss": 0.0919,
      "step": 240
    },
    {
      "epoch": 0.25826446280991733,
      "grad_norm": 0.13257643580436707,
      "learning_rate": 2.5670103092783506e-05,
      "loss": 0.0857,
      "step": 250
    },
    {
      "epoch": 0.26859504132231404,
      "grad_norm": 1.43010413646698,
      "learning_rate": 2.670103092783505e-05,
      "loss": 0.1635,
      "step": 260
    },
    {
      "epoch": 0.27892561983471076,
      "grad_norm": 3.4565820693969727,
      "learning_rate": 2.77319587628866e-05,
      "loss": 0.1521,
      "step": 270
    },
    {
      "epoch": 0.2892561983471074,
      "grad_norm": 1.7479398250579834,
      "learning_rate": 2.8762886597938146e-05,
      "loss": 0.1312,
      "step": 280
    },
    {
      "epoch": 0.29958677685950413,
      "grad_norm": 0.3397315740585327,
      "learning_rate": 2.979381443298969e-05,
      "loss": 0.1201,
      "step": 290
    },
    {
      "epoch": 0.30991735537190085,
      "grad_norm": 2.7068402767181396,
      "learning_rate": 2.9908151549942597e-05,
      "loss": 0.1899,
      "step": 300
    },
    {
      "epoch": 0.3202479338842975,
      "grad_norm": 0.582635223865509,
      "learning_rate": 2.979334098737084e-05,
      "loss": 0.1217,
      "step": 310
    },
    {
      "epoch": 0.3305785123966942,
      "grad_norm": 5.252079486846924,
      "learning_rate": 2.9678530424799084e-05,
      "loss": 0.1351,
      "step": 320
    },
    {
      "epoch": 0.3409090909090909,
      "grad_norm": 1.9796040058135986,
      "learning_rate": 2.9563719862227327e-05,
      "loss": 0.1961,
      "step": 330
    },
    {
      "epoch": 0.3512396694214876,
      "grad_norm": 2.5909059047698975,
      "learning_rate": 2.944890929965557e-05,
      "loss": 0.1115,
      "step": 340
    },
    {
      "epoch": 0.3615702479338843,
      "grad_norm": 0.28774669766426086,
      "learning_rate": 2.9334098737083814e-05,
      "loss": 0.108,
      "step": 350
    },
    {
      "epoch": 0.371900826446281,
      "grad_norm": 0.676539421081543,
      "learning_rate": 2.9219288174512057e-05,
      "loss": 0.1044,
      "step": 360
    },
    {
      "epoch": 0.3822314049586777,
      "grad_norm": 5.058534622192383,
      "learning_rate": 2.91044776119403e-05,
      "loss": 0.1317,
      "step": 370
    },
    {
      "epoch": 0.3925619834710744,
      "grad_norm": 0.7016995549201965,
      "learning_rate": 2.8989667049368544e-05,
      "loss": 0.2024,
      "step": 380
    },
    {
      "epoch": 0.40289256198347106,
      "grad_norm": 2.7278494834899902,
      "learning_rate": 2.8874856486796787e-05,
      "loss": 0.1843,
      "step": 390
    },
    {
      "epoch": 0.4132231404958678,
      "grad_norm": 2.4777848720550537,
      "learning_rate": 2.876004592422503e-05,
      "loss": 0.1648,
      "step": 400
    },
    {
      "epoch": 0.42355371900826444,
      "grad_norm": 0.18564623594284058,
      "learning_rate": 2.8645235361653274e-05,
      "loss": 0.1628,
      "step": 410
    },
    {
      "epoch": 0.43388429752066116,
      "grad_norm": 0.4515726864337921,
      "learning_rate": 2.8530424799081517e-05,
      "loss": 0.1217,
      "step": 420
    },
    {
      "epoch": 0.44421487603305787,
      "grad_norm": 1.633537769317627,
      "learning_rate": 2.841561423650976e-05,
      "loss": 0.1168,
      "step": 430
    },
    {
      "epoch": 0.45454545454545453,
      "grad_norm": 0.11996642500162125,
      "learning_rate": 2.8300803673938004e-05,
      "loss": 0.0461,
      "step": 440
    },
    {
      "epoch": 0.46487603305785125,
      "grad_norm": 0.15292418003082275,
      "learning_rate": 2.8185993111366247e-05,
      "loss": 0.1679,
      "step": 450
    },
    {
      "epoch": 0.47520661157024796,
      "grad_norm": Infinity,
      "learning_rate": 2.807118254879449e-05,
      "loss": 0.0594,
      "step": 460
    },
    {
      "epoch": 0.4855371900826446,
      "grad_norm": 0.16092683374881744,
      "learning_rate": 2.7956371986222734e-05,
      "loss": 0.127,
      "step": 470
    },
    {
      "epoch": 0.49586776859504134,
      "grad_norm": 1.3988409042358398,
      "learning_rate": 2.7841561423650977e-05,
      "loss": 0.2205,
      "step": 480
    },
    {
      "epoch": 0.506198347107438,
      "grad_norm": 1.8357728719711304,
      "learning_rate": 2.772675086107922e-05,
      "loss": 0.1636,
      "step": 490
    },
    {
      "epoch": 0.5165289256198347,
      "grad_norm": 0.2015804499387741,
      "learning_rate": 2.7611940298507464e-05,
      "loss": 0.0379,
      "step": 500
    },
    {
      "epoch": 0.5268595041322314,
      "grad_norm": 2.8220150470733643,
      "learning_rate": 2.7497129735935707e-05,
      "loss": 0.3552,
      "step": 510
    },
    {
      "epoch": 0.5371900826446281,
      "grad_norm": 0.30692365765571594,
      "learning_rate": 2.738231917336395e-05,
      "loss": 0.0553,
      "step": 520
    },
    {
      "epoch": 0.5475206611570248,
      "grad_norm": 0.34080296754837036,
      "learning_rate": 2.7267508610792193e-05,
      "loss": 0.1087,
      "step": 530
    },
    {
      "epoch": 0.5578512396694215,
      "grad_norm": 0.5580190420150757,
      "learning_rate": 2.7152698048220437e-05,
      "loss": 0.0958,
      "step": 540
    },
    {
      "epoch": 0.5681818181818182,
      "grad_norm": 12.085930824279785,
      "learning_rate": 2.703788748564868e-05,
      "loss": 0.0611,
      "step": 550
    },
    {
      "epoch": 0.5785123966942148,
      "grad_norm": 0.10968444496393204,
      "learning_rate": 2.6923076923076923e-05,
      "loss": 0.0743,
      "step": 560
    },
    {
      "epoch": 0.5888429752066116,
      "grad_norm": 0.10683634132146835,
      "learning_rate": 2.6808266360505167e-05,
      "loss": 0.0253,
      "step": 570
    },
    {
      "epoch": 0.5991735537190083,
      "grad_norm": 2.8327040672302246,
      "learning_rate": 2.669345579793341e-05,
      "loss": 0.2562,
      "step": 580
    },
    {
      "epoch": 0.609504132231405,
      "grad_norm": 1.318297266960144,
      "learning_rate": 2.6578645235361653e-05,
      "loss": 0.1764,
      "step": 590
    },
    {
      "epoch": 0.6198347107438017,
      "grad_norm": 0.5438181757926941,
      "learning_rate": 2.64638346727899e-05,
      "loss": 0.0759,
      "step": 600
    },
    {
      "epoch": 0.6301652892561983,
      "grad_norm": 3.033223867416382,
      "learning_rate": 2.6349024110218143e-05,
      "loss": 0.0877,
      "step": 610
    },
    {
      "epoch": 0.640495867768595,
      "grad_norm": 1.8688043355941772,
      "learning_rate": 2.6234213547646387e-05,
      "loss": 0.1401,
      "step": 620
    },
    {
      "epoch": 0.6508264462809917,
      "grad_norm": 7.3099236488342285,
      "learning_rate": 2.611940298507463e-05,
      "loss": 0.1106,
      "step": 630
    },
    {
      "epoch": 0.6611570247933884,
      "grad_norm": 0.09869071841239929,
      "learning_rate": 2.6004592422502873e-05,
      "loss": 0.1311,
      "step": 640
    },
    {
      "epoch": 0.6714876033057852,
      "grad_norm": 0.11366278678178787,
      "learning_rate": 2.5889781859931116e-05,
      "loss": 0.1056,
      "step": 650
    },
    {
      "epoch": 0.6818181818181818,
      "grad_norm": 0.34495019912719727,
      "learning_rate": 2.577497129735936e-05,
      "loss": 0.1723,
      "step": 660
    },
    {
      "epoch": 0.6921487603305785,
      "grad_norm": 1.4882593154907227,
      "learning_rate": 2.5660160734787603e-05,
      "loss": 0.1289,
      "step": 670
    },
    {
      "epoch": 0.7024793388429752,
      "grad_norm": 0.1294734925031662,
      "learning_rate": 2.5545350172215846e-05,
      "loss": 0.0459,
      "step": 680
    },
    {
      "epoch": 0.7128099173553719,
      "grad_norm": 2.3632402420043945,
      "learning_rate": 2.543053960964409e-05,
      "loss": 0.0991,
      "step": 690
    },
    {
      "epoch": 0.7231404958677686,
      "grad_norm": 0.6482803821563721,
      "learning_rate": 2.5315729047072333e-05,
      "loss": 0.0951,
      "step": 700
    },
    {
      "epoch": 0.7334710743801653,
      "grad_norm": 10.988450050354004,
      "learning_rate": 2.5200918484500576e-05,
      "loss": 0.1382,
      "step": 710
    },
    {
      "epoch": 0.743801652892562,
      "grad_norm": 6.502532482147217,
      "learning_rate": 2.508610792192882e-05,
      "loss": 0.1248,
      "step": 720
    },
    {
      "epoch": 0.7541322314049587,
      "grad_norm": 1.6212464570999146,
      "learning_rate": 2.4971297359357063e-05,
      "loss": 0.1312,
      "step": 730
    },
    {
      "epoch": 0.7644628099173554,
      "grad_norm": 0.1698964685201645,
      "learning_rate": 2.4856486796785306e-05,
      "loss": 0.0426,
      "step": 740
    },
    {
      "epoch": 0.7747933884297521,
      "grad_norm": 0.9158139228820801,
      "learning_rate": 2.474167623421355e-05,
      "loss": 0.0804,
      "step": 750
    },
    {
      "epoch": 0.7851239669421488,
      "grad_norm": 0.331576943397522,
      "learning_rate": 2.4626865671641793e-05,
      "loss": 0.1417,
      "step": 760
    },
    {
      "epoch": 0.7954545454545454,
      "grad_norm": 1.113541841506958,
      "learning_rate": 2.4512055109070036e-05,
      "loss": 0.1026,
      "step": 770
    },
    {
      "epoch": 0.8057851239669421,
      "grad_norm": 0.2577393352985382,
      "learning_rate": 2.439724454649828e-05,
      "loss": 0.0726,
      "step": 780
    },
    {
      "epoch": 0.8161157024793388,
      "grad_norm": 0.1517639011144638,
      "learning_rate": 2.4282433983926523e-05,
      "loss": 0.0525,
      "step": 790
    },
    {
      "epoch": 0.8264462809917356,
      "grad_norm": 2.2239081859588623,
      "learning_rate": 2.4167623421354766e-05,
      "loss": 0.1137,
      "step": 800
    },
    {
      "epoch": 0.8367768595041323,
      "grad_norm": 3.3551881313323975,
      "learning_rate": 2.405281285878301e-05,
      "loss": 0.1175,
      "step": 810
    },
    {
      "epoch": 0.8471074380165289,
      "grad_norm": 6.345516681671143,
      "learning_rate": 2.3938002296211253e-05,
      "loss": 0.1228,
      "step": 820
    },
    {
      "epoch": 0.8574380165289256,
      "grad_norm": 0.5059385895729065,
      "learning_rate": 2.3823191733639496e-05,
      "loss": 0.1153,
      "step": 830
    },
    {
      "epoch": 0.8677685950413223,
      "grad_norm": 1.5861375331878662,
      "learning_rate": 2.370838117106774e-05,
      "loss": 0.082,
      "step": 840
    },
    {
      "epoch": 0.878099173553719,
      "grad_norm": 0.18188011646270752,
      "learning_rate": 2.3593570608495983e-05,
      "loss": 0.1176,
      "step": 850
    },
    {
      "epoch": 0.8884297520661157,
      "grad_norm": 0.838937520980835,
      "learning_rate": 2.3478760045924226e-05,
      "loss": 0.1271,
      "step": 860
    },
    {
      "epoch": 0.8987603305785123,
      "grad_norm": 0.20818538963794708,
      "learning_rate": 2.336394948335247e-05,
      "loss": 0.0957,
      "step": 870
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 0.15120859444141388,
      "learning_rate": 2.3249138920780712e-05,
      "loss": 0.0738,
      "step": 880
    },
    {
      "epoch": 0.9194214876033058,
      "grad_norm": 0.10466641187667847,
      "learning_rate": 2.3134328358208956e-05,
      "loss": 0.1121,
      "step": 890
    },
    {
      "epoch": 0.9297520661157025,
      "grad_norm": 3.2157866954803467,
      "learning_rate": 2.30195177956372e-05,
      "loss": 0.1101,
      "step": 900
    },
    {
      "epoch": 0.9400826446280992,
      "grad_norm": 0.13193802535533905,
      "learning_rate": 2.2904707233065442e-05,
      "loss": 0.0719,
      "step": 910
    },
    {
      "epoch": 0.9504132231404959,
      "grad_norm": 0.3981751799583435,
      "learning_rate": 2.2789896670493686e-05,
      "loss": 0.0862,
      "step": 920
    },
    {
      "epoch": 0.9607438016528925,
      "grad_norm": 0.1305660903453827,
      "learning_rate": 2.2675086107921932e-05,
      "loss": 0.1204,
      "step": 930
    },
    {
      "epoch": 0.9710743801652892,
      "grad_norm": 1.1762721538543701,
      "learning_rate": 2.2560275545350176e-05,
      "loss": 0.0717,
      "step": 940
    },
    {
      "epoch": 0.981404958677686,
      "grad_norm": 1.3196626901626587,
      "learning_rate": 2.244546498277842e-05,
      "loss": 0.1015,
      "step": 950
    },
    {
      "epoch": 0.9917355371900827,
      "grad_norm": 0.10447291284799576,
      "learning_rate": 2.2330654420206662e-05,
      "loss": 0.0817,
      "step": 960
    },
    {
      "epoch": 1.0,
      "eval_f1": 0.5596330275229358,
      "eval_loss": 0.10579660534858704,
      "eval_precision": 0.8840579710144928,
      "eval_recall": 0.40939597315436244,
      "eval_runtime": 2.2408,
      "eval_samples_per_second": 1480.723,
      "eval_steps_per_second": 92.824,
      "step": 968
    },
    {
      "epoch": 1.0020661157024793,
      "grad_norm": 2.311486005783081,
      "learning_rate": 2.2215843857634906e-05,
      "loss": 0.0974,
      "step": 970
    },
    {
      "epoch": 1.012396694214876,
      "grad_norm": 0.12361406534910202,
      "learning_rate": 2.210103329506315e-05,
      "loss": 0.0279,
      "step": 980
    },
    {
      "epoch": 1.0227272727272727,
      "grad_norm": 0.32095101475715637,
      "learning_rate": 2.1986222732491392e-05,
      "loss": 0.0522,
      "step": 990
    },
    {
      "epoch": 1.0330578512396693,
      "grad_norm": 6.848564147949219,
      "learning_rate": 2.1871412169919635e-05,
      "loss": 0.0634,
      "step": 1000
    },
    {
      "epoch": 1.0433884297520661,
      "grad_norm": 0.9597200751304626,
      "learning_rate": 2.175660160734788e-05,
      "loss": 0.0825,
      "step": 1010
    },
    {
      "epoch": 1.0537190082644627,
      "grad_norm": 1.8955026865005493,
      "learning_rate": 2.1641791044776122e-05,
      "loss": 0.1044,
      "step": 1020
    },
    {
      "epoch": 1.0640495867768596,
      "grad_norm": 0.05291564017534256,
      "learning_rate": 2.1526980482204365e-05,
      "loss": 0.0941,
      "step": 1030
    },
    {
      "epoch": 1.0743801652892562,
      "grad_norm": 0.10530944913625717,
      "learning_rate": 2.141216991963261e-05,
      "loss": 0.1121,
      "step": 1040
    },
    {
      "epoch": 1.084710743801653,
      "grad_norm": 3.0991244316101074,
      "learning_rate": 2.1297359357060852e-05,
      "loss": 0.0515,
      "step": 1050
    },
    {
      "epoch": 1.0950413223140496,
      "grad_norm": 1.0915745496749878,
      "learning_rate": 2.1182548794489095e-05,
      "loss": 0.0475,
      "step": 1060
    },
    {
      "epoch": 1.1053719008264462,
      "grad_norm": 0.06268442422151566,
      "learning_rate": 2.106773823191734e-05,
      "loss": 0.0954,
      "step": 1070
    },
    {
      "epoch": 1.115702479338843,
      "grad_norm": 0.068457692861557,
      "learning_rate": 2.0952927669345582e-05,
      "loss": 0.0124,
      "step": 1080
    },
    {
      "epoch": 1.1260330578512396,
      "grad_norm": 4.679382801055908,
      "learning_rate": 2.0838117106773825e-05,
      "loss": 0.0367,
      "step": 1090
    },
    {
      "epoch": 1.1363636363636362,
      "grad_norm": 0.058999281376600266,
      "learning_rate": 2.072330654420207e-05,
      "loss": 0.0508,
      "step": 1100
    },
    {
      "epoch": 1.146694214876033,
      "grad_norm": 0.07067402452230453,
      "learning_rate": 2.0608495981630312e-05,
      "loss": 0.0832,
      "step": 1110
    },
    {
      "epoch": 1.1570247933884297,
      "grad_norm": 0.12176882475614548,
      "learning_rate": 2.0493685419058555e-05,
      "loss": 0.034,
      "step": 1120
    },
    {
      "epoch": 1.1673553719008265,
      "grad_norm": 9.464786529541016,
      "learning_rate": 2.03788748564868e-05,
      "loss": 0.0493,
      "step": 1130
    },
    {
      "epoch": 1.177685950413223,
      "grad_norm": 6.560824871063232,
      "learning_rate": 2.0264064293915042e-05,
      "loss": 0.1055,
      "step": 1140
    },
    {
      "epoch": 1.18801652892562,
      "grad_norm": 0.32830026745796204,
      "learning_rate": 2.0149253731343285e-05,
      "loss": 0.0246,
      "step": 1150
    },
    {
      "epoch": 1.1983471074380165,
      "grad_norm": 0.0675118938088417,
      "learning_rate": 2.003444316877153e-05,
      "loss": 0.1005,
      "step": 1160
    },
    {
      "epoch": 1.2086776859504131,
      "grad_norm": 0.9539141654968262,
      "learning_rate": 1.991963260619977e-05,
      "loss": 0.0548,
      "step": 1170
    },
    {
      "epoch": 1.21900826446281,
      "grad_norm": 0.16660723090171814,
      "learning_rate": 1.9804822043628015e-05,
      "loss": 0.0962,
      "step": 1180
    },
    {
      "epoch": 1.2293388429752066,
      "grad_norm": 3.273716449737549,
      "learning_rate": 1.9690011481056258e-05,
      "loss": 0.0798,
      "step": 1190
    },
    {
      "epoch": 1.2396694214876034,
      "grad_norm": 5.815090656280518,
      "learning_rate": 1.95752009184845e-05,
      "loss": 0.0417,
      "step": 1200
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.0647139847278595,
      "learning_rate": 1.9460390355912745e-05,
      "loss": 0.0335,
      "step": 1210
    },
    {
      "epoch": 1.2603305785123968,
      "grad_norm": 2.0909781455993652,
      "learning_rate": 1.9345579793340988e-05,
      "loss": 0.0455,
      "step": 1220
    },
    {
      "epoch": 1.2706611570247934,
      "grad_norm": 0.06257973611354828,
      "learning_rate": 1.923076923076923e-05,
      "loss": 0.0375,
      "step": 1230
    },
    {
      "epoch": 1.28099173553719,
      "grad_norm": 0.13756097853183746,
      "learning_rate": 1.9115958668197475e-05,
      "loss": 0.0615,
      "step": 1240
    },
    {
      "epoch": 1.2913223140495869,
      "grad_norm": 0.06400162726640701,
      "learning_rate": 1.9001148105625718e-05,
      "loss": 0.0441,
      "step": 1250
    },
    {
      "epoch": 1.3016528925619835,
      "grad_norm": 0.7715556621551514,
      "learning_rate": 1.8886337543053965e-05,
      "loss": 0.0315,
      "step": 1260
    },
    {
      "epoch": 1.31198347107438,
      "grad_norm": 13.478341102600098,
      "learning_rate": 1.8771526980482208e-05,
      "loss": 0.0183,
      "step": 1270
    },
    {
      "epoch": 1.322314049586777,
      "grad_norm": 0.03623059764504433,
      "learning_rate": 1.8656716417910448e-05,
      "loss": 0.0409,
      "step": 1280
    },
    {
      "epoch": 1.3326446280991735,
      "grad_norm": 0.03126641735434532,
      "learning_rate": 1.854190585533869e-05,
      "loss": 0.0157,
      "step": 1290
    },
    {
      "epoch": 1.3429752066115703,
      "grad_norm": 0.23444493114948273,
      "learning_rate": 1.8427095292766935e-05,
      "loss": 0.1561,
      "step": 1300
    },
    {
      "epoch": 1.353305785123967,
      "grad_norm": 0.3812875747680664,
      "learning_rate": 1.8312284730195178e-05,
      "loss": 0.0342,
      "step": 1310
    },
    {
      "epoch": 1.3636363636363638,
      "grad_norm": 0.0401199571788311,
      "learning_rate": 1.819747416762342e-05,
      "loss": 0.1041,
      "step": 1320
    },
    {
      "epoch": 1.3739669421487604,
      "grad_norm": 4.646642208099365,
      "learning_rate": 1.8082663605051664e-05,
      "loss": 0.1067,
      "step": 1330
    },
    {
      "epoch": 1.384297520661157,
      "grad_norm": 0.04591190442442894,
      "learning_rate": 1.7967853042479908e-05,
      "loss": 0.0981,
      "step": 1340
    },
    {
      "epoch": 1.3946280991735538,
      "grad_norm": 0.08745554834604263,
      "learning_rate": 1.785304247990815e-05,
      "loss": 0.0616,
      "step": 1350
    },
    {
      "epoch": 1.4049586776859504,
      "grad_norm": 0.1081681102514267,
      "learning_rate": 1.7738231917336394e-05,
      "loss": 0.0451,
      "step": 1360
    },
    {
      "epoch": 1.415289256198347,
      "grad_norm": 3.9964396953582764,
      "learning_rate": 1.7623421354764638e-05,
      "loss": 0.1111,
      "step": 1370
    },
    {
      "epoch": 1.4256198347107438,
      "grad_norm": 0.12221821397542953,
      "learning_rate": 1.750861079219288e-05,
      "loss": 0.0709,
      "step": 1380
    },
    {
      "epoch": 1.4359504132231404,
      "grad_norm": 3.5499584674835205,
      "learning_rate": 1.7393800229621124e-05,
      "loss": 0.0416,
      "step": 1390
    },
    {
      "epoch": 1.4462809917355373,
      "grad_norm": 0.042199283838272095,
      "learning_rate": 1.7278989667049368e-05,
      "loss": 0.0412,
      "step": 1400
    },
    {
      "epoch": 1.4566115702479339,
      "grad_norm": 4.1418304443359375,
      "learning_rate": 1.716417910447761e-05,
      "loss": 0.1189,
      "step": 1410
    },
    {
      "epoch": 1.4669421487603307,
      "grad_norm": 3.625732898712158,
      "learning_rate": 1.7049368541905854e-05,
      "loss": 0.089,
      "step": 1420
    },
    {
      "epoch": 1.4772727272727273,
      "grad_norm": 5.018718719482422,
      "learning_rate": 1.6934557979334097e-05,
      "loss": 0.0851,
      "step": 1430
    },
    {
      "epoch": 1.487603305785124,
      "grad_norm": 1.3899238109588623,
      "learning_rate": 1.681974741676234e-05,
      "loss": 0.041,
      "step": 1440
    },
    {
      "epoch": 1.4979338842975207,
      "grad_norm": 0.056105878204107285,
      "learning_rate": 1.6704936854190584e-05,
      "loss": 0.0734,
      "step": 1450
    },
    {
      "epoch": 1.5082644628099173,
      "grad_norm": 13.807720184326172,
      "learning_rate": 1.6590126291618827e-05,
      "loss": 0.04,
      "step": 1460
    },
    {
      "epoch": 1.518595041322314,
      "grad_norm": 0.07853517681360245,
      "learning_rate": 1.647531572904707e-05,
      "loss": 0.0765,
      "step": 1470
    },
    {
      "epoch": 1.5289256198347108,
      "grad_norm": 9.813467025756836,
      "learning_rate": 1.6360505166475314e-05,
      "loss": 0.0622,
      "step": 1480
    },
    {
      "epoch": 1.5392561983471076,
      "grad_norm": 0.4560561180114746,
      "learning_rate": 1.6245694603903557e-05,
      "loss": 0.0412,
      "step": 1490
    },
    {
      "epoch": 1.549586776859504,
      "grad_norm": 4.721568584442139,
      "learning_rate": 1.61308840413318e-05,
      "loss": 0.0387,
      "step": 1500
    },
    {
      "epoch": 1.5599173553719008,
      "grad_norm": 0.8656852841377258,
      "learning_rate": 1.6016073478760044e-05,
      "loss": 0.0754,
      "step": 1510
    },
    {
      "epoch": 1.5702479338842976,
      "grad_norm": 3.358354091644287,
      "learning_rate": 1.5901262916188287e-05,
      "loss": 0.1288,
      "step": 1520
    },
    {
      "epoch": 1.5805785123966942,
      "grad_norm": 0.1323731243610382,
      "learning_rate": 1.578645235361653e-05,
      "loss": 0.0352,
      "step": 1530
    },
    {
      "epoch": 1.5909090909090908,
      "grad_norm": 0.4126746952533722,
      "learning_rate": 1.5671641791044774e-05,
      "loss": 0.0562,
      "step": 1540
    },
    {
      "epoch": 1.6012396694214877,
      "grad_norm": 0.08556484431028366,
      "learning_rate": 1.5556831228473017e-05,
      "loss": 0.0898,
      "step": 1550
    },
    {
      "epoch": 1.6115702479338843,
      "grad_norm": 4.069133281707764,
      "learning_rate": 1.544202066590126e-05,
      "loss": 0.0705,
      "step": 1560
    },
    {
      "epoch": 1.6219008264462809,
      "grad_norm": 1.7846415042877197,
      "learning_rate": 1.5327210103329504e-05,
      "loss": 0.0588,
      "step": 1570
    },
    {
      "epoch": 1.6322314049586777,
      "grad_norm": 0.05055300518870354,
      "learning_rate": 1.5212399540757749e-05,
      "loss": 0.0897,
      "step": 1580
    },
    {
      "epoch": 1.6425619834710745,
      "grad_norm": 0.10723086446523666,
      "learning_rate": 1.5097588978185992e-05,
      "loss": 0.0893,
      "step": 1590
    },
    {
      "epoch": 1.6528925619834711,
      "grad_norm": 0.25716471672058105,
      "learning_rate": 1.4982778415614237e-05,
      "loss": 0.0458,
      "step": 1600
    },
    {
      "epoch": 1.6632231404958677,
      "grad_norm": 0.05539458617568016,
      "learning_rate": 1.486796785304248e-05,
      "loss": 0.0626,
      "step": 1610
    },
    {
      "epoch": 1.6735537190082646,
      "grad_norm": 4.539200782775879,
      "learning_rate": 1.4753157290470724e-05,
      "loss": 0.1245,
      "step": 1620
    },
    {
      "epoch": 1.6838842975206612,
      "grad_norm": 6.722307205200195,
      "learning_rate": 1.4638346727898967e-05,
      "loss": 0.0566,
      "step": 1630
    },
    {
      "epoch": 1.6942148760330578,
      "grad_norm": 10.853208541870117,
      "learning_rate": 1.452353616532721e-05,
      "loss": 0.0349,
      "step": 1640
    },
    {
      "epoch": 1.7045454545454546,
      "grad_norm": 0.040719691663980484,
      "learning_rate": 1.4408725602755454e-05,
      "loss": 0.003,
      "step": 1650
    },
    {
      "epoch": 1.7148760330578512,
      "grad_norm": 0.03128989040851593,
      "learning_rate": 1.4293915040183697e-05,
      "loss": 0.0557,
      "step": 1660
    },
    {
      "epoch": 1.7252066115702478,
      "grad_norm": 5.296324729919434,
      "learning_rate": 1.4179104477611942e-05,
      "loss": 0.159,
      "step": 1670
    },
    {
      "epoch": 1.7355371900826446,
      "grad_norm": 0.11026624590158463,
      "learning_rate": 1.4064293915040185e-05,
      "loss": 0.0396,
      "step": 1680
    },
    {
      "epoch": 1.7458677685950414,
      "grad_norm": 0.03577600419521332,
      "learning_rate": 1.3949483352468428e-05,
      "loss": 0.0105,
      "step": 1690
    },
    {
      "epoch": 1.756198347107438,
      "grad_norm": 0.03857122361660004,
      "learning_rate": 1.3834672789896672e-05,
      "loss": 0.0664,
      "step": 1700
    },
    {
      "epoch": 1.7665289256198347,
      "grad_norm": 5.140746116638184,
      "learning_rate": 1.3719862227324915e-05,
      "loss": 0.0794,
      "step": 1710
    },
    {
      "epoch": 1.7768595041322315,
      "grad_norm": 2.3144688606262207,
      "learning_rate": 1.3605051664753158e-05,
      "loss": 0.1109,
      "step": 1720
    },
    {
      "epoch": 1.787190082644628,
      "grad_norm": 0.034797243773937225,
      "learning_rate": 1.3490241102181402e-05,
      "loss": 0.0518,
      "step": 1730
    },
    {
      "epoch": 1.7975206611570247,
      "grad_norm": 0.04481451213359833,
      "learning_rate": 1.3375430539609645e-05,
      "loss": 0.0176,
      "step": 1740
    },
    {
      "epoch": 1.8078512396694215,
      "grad_norm": 0.04771125689148903,
      "learning_rate": 1.3260619977037888e-05,
      "loss": 0.0581,
      "step": 1750
    },
    {
      "epoch": 1.8181818181818183,
      "grad_norm": 0.04309640824794769,
      "learning_rate": 1.3145809414466132e-05,
      "loss": 0.0036,
      "step": 1760
    },
    {
      "epoch": 1.8285123966942147,
      "grad_norm": 0.03966256603598595,
      "learning_rate": 1.3030998851894375e-05,
      "loss": 0.0645,
      "step": 1770
    },
    {
      "epoch": 1.8388429752066116,
      "grad_norm": 0.10036647319793701,
      "learning_rate": 1.2916188289322618e-05,
      "loss": 0.0248,
      "step": 1780
    },
    {
      "epoch": 1.8491735537190084,
      "grad_norm": 0.563675045967102,
      "learning_rate": 1.2801377726750862e-05,
      "loss": 0.0675,
      "step": 1790
    },
    {
      "epoch": 1.859504132231405,
      "grad_norm": 0.08177992701530457,
      "learning_rate": 1.2686567164179105e-05,
      "loss": 0.0755,
      "step": 1800
    },
    {
      "epoch": 1.8698347107438016,
      "grad_norm": 1.2194360494613647,
      "learning_rate": 1.2571756601607348e-05,
      "loss": 0.0834,
      "step": 1810
    },
    {
      "epoch": 1.8801652892561984,
      "grad_norm": 6.594037055969238,
      "learning_rate": 1.2456946039035591e-05,
      "loss": 0.077,
      "step": 1820
    },
    {
      "epoch": 1.890495867768595,
      "grad_norm": 3.1627306938171387,
      "learning_rate": 1.2342135476463835e-05,
      "loss": 0.0515,
      "step": 1830
    },
    {
      "epoch": 1.9008264462809916,
      "grad_norm": 0.28537365794181824,
      "learning_rate": 1.222732491389208e-05,
      "loss": 0.0282,
      "step": 1840
    },
    {
      "epoch": 1.9111570247933884,
      "grad_norm": 0.17186178267002106,
      "learning_rate": 1.2112514351320323e-05,
      "loss": 0.065,
      "step": 1850
    },
    {
      "epoch": 1.9214876033057853,
      "grad_norm": 0.11154166609048843,
      "learning_rate": 1.1997703788748566e-05,
      "loss": 0.0368,
      "step": 1860
    },
    {
      "epoch": 1.9318181818181817,
      "grad_norm": 0.2892882227897644,
      "learning_rate": 1.188289322617681e-05,
      "loss": 0.0778,
      "step": 1870
    },
    {
      "epoch": 1.9421487603305785,
      "grad_norm": 0.18745262920856476,
      "learning_rate": 1.1768082663605053e-05,
      "loss": 0.0668,
      "step": 1880
    },
    {
      "epoch": 1.9524793388429753,
      "grad_norm": 0.03350815176963806,
      "learning_rate": 1.1653272101033296e-05,
      "loss": 0.0601,
      "step": 1890
    },
    {
      "epoch": 1.962809917355372,
      "grad_norm": 4.264648914337158,
      "learning_rate": 1.153846153846154e-05,
      "loss": 0.0819,
      "step": 1900
    },
    {
      "epoch": 1.9731404958677685,
      "grad_norm": 0.07085417956113815,
      "learning_rate": 1.1423650975889783e-05,
      "loss": 0.0277,
      "step": 1910
    },
    {
      "epoch": 1.9834710743801653,
      "grad_norm": 0.241835355758667,
      "learning_rate": 1.1308840413318026e-05,
      "loss": 0.0401,
      "step": 1920
    },
    {
      "epoch": 1.993801652892562,
      "grad_norm": 0.15360112488269806,
      "learning_rate": 1.119402985074627e-05,
      "loss": 0.0269,
      "step": 1930
    },
    {
      "epoch": 2.0,
      "eval_f1": 0.75,
      "eval_loss": 0.08372092247009277,
      "eval_precision": 0.8015267175572519,
      "eval_recall": 0.7046979865771812,
      "eval_runtime": 1.8998,
      "eval_samples_per_second": 1746.52,
      "eval_steps_per_second": 109.486,
      "step": 1936
    }
  ],
  "logging_steps": 10,
  "max_steps": 2904,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1025628834094080.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
