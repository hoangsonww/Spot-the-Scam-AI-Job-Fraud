{
  "best_global_step": 1936,
  "best_metric": 0.08389206975698471,
  "best_model_checkpoint": "/home/snguyen/spot-the-scam-project/artifacts/transformer/checkpoint-1936",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 1936,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010330578512396695,
      "grad_norm": 4.703976154327393,
      "learning_rate": 9.278350515463919e-07,
      "loss": 0.6766,
      "step": 10
    },
    {
      "epoch": 0.02066115702479339,
      "grad_norm": 3.4400298595428467,
      "learning_rate": 1.9587628865979384e-06,
      "loss": 0.6511,
      "step": 20
    },
    {
      "epoch": 0.030991735537190084,
      "grad_norm": 4.108104705810547,
      "learning_rate": 2.989690721649485e-06,
      "loss": 0.6006,
      "step": 30
    },
    {
      "epoch": 0.04132231404958678,
      "grad_norm": 3.8866748809814453,
      "learning_rate": 4.020618556701031e-06,
      "loss": 0.5292,
      "step": 40
    },
    {
      "epoch": 0.05165289256198347,
      "grad_norm": 2.5028867721557617,
      "learning_rate": 5.051546391752578e-06,
      "loss": 0.4198,
      "step": 50
    },
    {
      "epoch": 0.06198347107438017,
      "grad_norm": 1.6685080528259277,
      "learning_rate": 6.082474226804124e-06,
      "loss": 0.3294,
      "step": 60
    },
    {
      "epoch": 0.07231404958677685,
      "grad_norm": 1.0191187858581543,
      "learning_rate": 7.11340206185567e-06,
      "loss": 0.2491,
      "step": 70
    },
    {
      "epoch": 0.08264462809917356,
      "grad_norm": 0.9723655581474304,
      "learning_rate": 8.144329896907216e-06,
      "loss": 0.2003,
      "step": 80
    },
    {
      "epoch": 0.09297520661157024,
      "grad_norm": 0.6860754489898682,
      "learning_rate": 9.175257731958764e-06,
      "loss": 0.1322,
      "step": 90
    },
    {
      "epoch": 0.10330578512396695,
      "grad_norm": 0.47402727603912354,
      "learning_rate": 1.020618556701031e-05,
      "loss": 0.1129,
      "step": 100
    },
    {
      "epoch": 0.11363636363636363,
      "grad_norm": 0.40855422616004944,
      "learning_rate": 1.1237113402061856e-05,
      "loss": 0.068,
      "step": 110
    },
    {
      "epoch": 0.12396694214876033,
      "grad_norm": 2.5328145027160645,
      "learning_rate": 1.2268041237113401e-05,
      "loss": 0.2872,
      "step": 120
    },
    {
      "epoch": 0.13429752066115702,
      "grad_norm": 1.6092427968978882,
      "learning_rate": 1.3298969072164948e-05,
      "loss": 0.1948,
      "step": 130
    },
    {
      "epoch": 0.1446280991735537,
      "grad_norm": 0.8369685411453247,
      "learning_rate": 1.4329896907216495e-05,
      "loss": 0.1408,
      "step": 140
    },
    {
      "epoch": 0.15495867768595042,
      "grad_norm": 5.178857803344727,
      "learning_rate": 1.536082474226804e-05,
      "loss": 0.3299,
      "step": 150
    },
    {
      "epoch": 0.1652892561983471,
      "grad_norm": 1.108429193496704,
      "learning_rate": 1.6391752577319588e-05,
      "loss": 0.1984,
      "step": 160
    },
    {
      "epoch": 0.1756198347107438,
      "grad_norm": 1.3731595277786255,
      "learning_rate": 1.7422680412371137e-05,
      "loss": 0.2273,
      "step": 170
    },
    {
      "epoch": 0.1859504132231405,
      "grad_norm": 1.8679790496826172,
      "learning_rate": 1.8453608247422682e-05,
      "loss": 0.19,
      "step": 180
    },
    {
      "epoch": 0.1962809917355372,
      "grad_norm": 0.4076886773109436,
      "learning_rate": 1.9484536082474227e-05,
      "loss": 0.2043,
      "step": 190
    },
    {
      "epoch": 0.2066115702479339,
      "grad_norm": 2.671358346939087,
      "learning_rate": 2.0515463917525773e-05,
      "loss": 0.1385,
      "step": 200
    },
    {
      "epoch": 0.21694214876033058,
      "grad_norm": 1.2910875082015991,
      "learning_rate": 2.154639175257732e-05,
      "loss": 0.1421,
      "step": 210
    },
    {
      "epoch": 0.22727272727272727,
      "grad_norm": 0.4317775070667267,
      "learning_rate": 2.2577319587628867e-05,
      "loss": 0.0995,
      "step": 220
    },
    {
      "epoch": 0.23760330578512398,
      "grad_norm": 0.3546595871448517,
      "learning_rate": 2.3608247422680412e-05,
      "loss": 0.116,
      "step": 230
    },
    {
      "epoch": 0.24793388429752067,
      "grad_norm": 0.3400242328643799,
      "learning_rate": 2.4639175257731957e-05,
      "loss": 0.0919,
      "step": 240
    },
    {
      "epoch": 0.25826446280991733,
      "grad_norm": 0.13257643580436707,
      "learning_rate": 2.5670103092783506e-05,
      "loss": 0.0857,
      "step": 250
    },
    {
      "epoch": 0.26859504132231404,
      "grad_norm": 1.43010413646698,
      "learning_rate": 2.670103092783505e-05,
      "loss": 0.1635,
      "step": 260
    },
    {
      "epoch": 0.27892561983471076,
      "grad_norm": 3.4565820693969727,
      "learning_rate": 2.77319587628866e-05,
      "loss": 0.1521,
      "step": 270
    },
    {
      "epoch": 0.2892561983471074,
      "grad_norm": 1.7479398250579834,
      "learning_rate": 2.8762886597938146e-05,
      "loss": 0.1312,
      "step": 280
    },
    {
      "epoch": 0.29958677685950413,
      "grad_norm": 0.3397315740585327,
      "learning_rate": 2.979381443298969e-05,
      "loss": 0.1201,
      "step": 290
    },
    {
      "epoch": 0.30991735537190085,
      "grad_norm": 2.7068402767181396,
      "learning_rate": 2.9908151549942597e-05,
      "loss": 0.1899,
      "step": 300
    },
    {
      "epoch": 0.3202479338842975,
      "grad_norm": 0.582635223865509,
      "learning_rate": 2.979334098737084e-05,
      "loss": 0.1217,
      "step": 310
    },
    {
      "epoch": 0.3305785123966942,
      "grad_norm": 5.252079486846924,
      "learning_rate": 2.9678530424799084e-05,
      "loss": 0.1351,
      "step": 320
    },
    {
      "epoch": 0.3409090909090909,
      "grad_norm": 1.9796040058135986,
      "learning_rate": 2.9563719862227327e-05,
      "loss": 0.1961,
      "step": 330
    },
    {
      "epoch": 0.3512396694214876,
      "grad_norm": 2.5909059047698975,
      "learning_rate": 2.944890929965557e-05,
      "loss": 0.1115,
      "step": 340
    },
    {
      "epoch": 0.3615702479338843,
      "grad_norm": 0.28774669766426086,
      "learning_rate": 2.9334098737083814e-05,
      "loss": 0.108,
      "step": 350
    },
    {
      "epoch": 0.371900826446281,
      "grad_norm": 0.676539421081543,
      "learning_rate": 2.9219288174512057e-05,
      "loss": 0.1044,
      "step": 360
    },
    {
      "epoch": 0.3822314049586777,
      "grad_norm": 5.058534622192383,
      "learning_rate": 2.91044776119403e-05,
      "loss": 0.1317,
      "step": 370
    },
    {
      "epoch": 0.3925619834710744,
      "grad_norm": 0.7016995549201965,
      "learning_rate": 2.8989667049368544e-05,
      "loss": 0.2024,
      "step": 380
    },
    {
      "epoch": 0.40289256198347106,
      "grad_norm": 2.7278494834899902,
      "learning_rate": 2.8874856486796787e-05,
      "loss": 0.1843,
      "step": 390
    },
    {
      "epoch": 0.4132231404958678,
      "grad_norm": 2.4777848720550537,
      "learning_rate": 2.876004592422503e-05,
      "loss": 0.1648,
      "step": 400
    },
    {
      "epoch": 0.42355371900826444,
      "grad_norm": 0.18564623594284058,
      "learning_rate": 2.8645235361653274e-05,
      "loss": 0.1628,
      "step": 410
    },
    {
      "epoch": 0.43388429752066116,
      "grad_norm": 0.4515726864337921,
      "learning_rate": 2.8530424799081517e-05,
      "loss": 0.1217,
      "step": 420
    },
    {
      "epoch": 0.44421487603305787,
      "grad_norm": 1.633537769317627,
      "learning_rate": 2.841561423650976e-05,
      "loss": 0.1168,
      "step": 430
    },
    {
      "epoch": 0.45454545454545453,
      "grad_norm": 0.11996642500162125,
      "learning_rate": 2.8300803673938004e-05,
      "loss": 0.0461,
      "step": 440
    },
    {
      "epoch": 0.46487603305785125,
      "grad_norm": 0.15292418003082275,
      "learning_rate": 2.8185993111366247e-05,
      "loss": 0.1679,
      "step": 450
    },
    {
      "epoch": 0.47520661157024796,
      "grad_norm": Infinity,
      "learning_rate": 2.807118254879449e-05,
      "loss": 0.0594,
      "step": 460
    },
    {
      "epoch": 0.4855371900826446,
      "grad_norm": 0.16092683374881744,
      "learning_rate": 2.7956371986222734e-05,
      "loss": 0.127,
      "step": 470
    },
    {
      "epoch": 0.49586776859504134,
      "grad_norm": 1.3988409042358398,
      "learning_rate": 2.7841561423650977e-05,
      "loss": 0.2205,
      "step": 480
    },
    {
      "epoch": 0.506198347107438,
      "grad_norm": 1.8357728719711304,
      "learning_rate": 2.772675086107922e-05,
      "loss": 0.1636,
      "step": 490
    },
    {
      "epoch": 0.5165289256198347,
      "grad_norm": 0.2015804499387741,
      "learning_rate": 2.7611940298507464e-05,
      "loss": 0.0379,
      "step": 500
    },
    {
      "epoch": 0.5268595041322314,
      "grad_norm": 2.8220150470733643,
      "learning_rate": 2.7497129735935707e-05,
      "loss": 0.3552,
      "step": 510
    },
    {
      "epoch": 0.5371900826446281,
      "grad_norm": 0.30692365765571594,
      "learning_rate": 2.738231917336395e-05,
      "loss": 0.0553,
      "step": 520
    },
    {
      "epoch": 0.5475206611570248,
      "grad_norm": 0.34080296754837036,
      "learning_rate": 2.7267508610792193e-05,
      "loss": 0.1087,
      "step": 530
    },
    {
      "epoch": 0.5578512396694215,
      "grad_norm": 0.5580190420150757,
      "learning_rate": 2.7152698048220437e-05,
      "loss": 0.0958,
      "step": 540
    },
    {
      "epoch": 0.5681818181818182,
      "grad_norm": 12.085930824279785,
      "learning_rate": 2.703788748564868e-05,
      "loss": 0.0611,
      "step": 550
    },
    {
      "epoch": 0.5785123966942148,
      "grad_norm": 0.10968444496393204,
      "learning_rate": 2.6923076923076923e-05,
      "loss": 0.0743,
      "step": 560
    },
    {
      "epoch": 0.5888429752066116,
      "grad_norm": 0.10683634132146835,
      "learning_rate": 2.6808266360505167e-05,
      "loss": 0.0253,
      "step": 570
    },
    {
      "epoch": 0.5991735537190083,
      "grad_norm": 2.8327040672302246,
      "learning_rate": 2.669345579793341e-05,
      "loss": 0.2562,
      "step": 580
    },
    {
      "epoch": 0.609504132231405,
      "grad_norm": 1.318297266960144,
      "learning_rate": 2.6578645235361653e-05,
      "loss": 0.1764,
      "step": 590
    },
    {
      "epoch": 0.6198347107438017,
      "grad_norm": 0.5438181757926941,
      "learning_rate": 2.64638346727899e-05,
      "loss": 0.0759,
      "step": 600
    },
    {
      "epoch": 0.6301652892561983,
      "grad_norm": 3.033223867416382,
      "learning_rate": 2.6349024110218143e-05,
      "loss": 0.0877,
      "step": 610
    },
    {
      "epoch": 0.640495867768595,
      "grad_norm": 1.8688043355941772,
      "learning_rate": 2.6234213547646387e-05,
      "loss": 0.1401,
      "step": 620
    },
    {
      "epoch": 0.6508264462809917,
      "grad_norm": 7.3099236488342285,
      "learning_rate": 2.611940298507463e-05,
      "loss": 0.1106,
      "step": 630
    },
    {
      "epoch": 0.6611570247933884,
      "grad_norm": 0.09869071841239929,
      "learning_rate": 2.6004592422502873e-05,
      "loss": 0.1311,
      "step": 640
    },
    {
      "epoch": 0.6714876033057852,
      "grad_norm": 0.11366278678178787,
      "learning_rate": 2.5889781859931116e-05,
      "loss": 0.1056,
      "step": 650
    },
    {
      "epoch": 0.6818181818181818,
      "grad_norm": 0.34495019912719727,
      "learning_rate": 2.577497129735936e-05,
      "loss": 0.1723,
      "step": 660
    },
    {
      "epoch": 0.6921487603305785,
      "grad_norm": 1.4882593154907227,
      "learning_rate": 2.5660160734787603e-05,
      "loss": 0.1289,
      "step": 670
    },
    {
      "epoch": 0.7024793388429752,
      "grad_norm": 0.1294734925031662,
      "learning_rate": 2.5545350172215846e-05,
      "loss": 0.0459,
      "step": 680
    },
    {
      "epoch": 0.7128099173553719,
      "grad_norm": 2.3632402420043945,
      "learning_rate": 2.543053960964409e-05,
      "loss": 0.0991,
      "step": 690
    },
    {
      "epoch": 0.7231404958677686,
      "grad_norm": 0.6482803821563721,
      "learning_rate": 2.5315729047072333e-05,
      "loss": 0.0951,
      "step": 700
    },
    {
      "epoch": 0.7334710743801653,
      "grad_norm": 10.988450050354004,
      "learning_rate": 2.5200918484500576e-05,
      "loss": 0.1382,
      "step": 710
    },
    {
      "epoch": 0.743801652892562,
      "grad_norm": 6.502532482147217,
      "learning_rate": 2.508610792192882e-05,
      "loss": 0.1248,
      "step": 720
    },
    {
      "epoch": 0.7541322314049587,
      "grad_norm": 1.6212464570999146,
      "learning_rate": 2.4971297359357063e-05,
      "loss": 0.1312,
      "step": 730
    },
    {
      "epoch": 0.7644628099173554,
      "grad_norm": 0.1698964685201645,
      "learning_rate": 2.4856486796785306e-05,
      "loss": 0.0426,
      "step": 740
    },
    {
      "epoch": 0.7747933884297521,
      "grad_norm": 0.9158139228820801,
      "learning_rate": 2.474167623421355e-05,
      "loss": 0.0804,
      "step": 750
    },
    {
      "epoch": 0.7851239669421488,
      "grad_norm": 0.331576943397522,
      "learning_rate": 2.4626865671641793e-05,
      "loss": 0.1417,
      "step": 760
    },
    {
      "epoch": 0.7954545454545454,
      "grad_norm": 1.113541841506958,
      "learning_rate": 2.4512055109070036e-05,
      "loss": 0.1026,
      "step": 770
    },
    {
      "epoch": 0.8057851239669421,
      "grad_norm": 0.2577393352985382,
      "learning_rate": 2.439724454649828e-05,
      "loss": 0.0726,
      "step": 780
    },
    {
      "epoch": 0.8161157024793388,
      "grad_norm": 0.1517639011144638,
      "learning_rate": 2.4282433983926523e-05,
      "loss": 0.0525,
      "step": 790
    },
    {
      "epoch": 0.8264462809917356,
      "grad_norm": 2.2239081859588623,
      "learning_rate": 2.4167623421354766e-05,
      "loss": 0.1137,
      "step": 800
    },
    {
      "epoch": 0.8367768595041323,
      "grad_norm": 3.3551881313323975,
      "learning_rate": 2.405281285878301e-05,
      "loss": 0.1175,
      "step": 810
    },
    {
      "epoch": 0.8471074380165289,
      "grad_norm": 6.345516681671143,
      "learning_rate": 2.3938002296211253e-05,
      "loss": 0.1228,
      "step": 820
    },
    {
      "epoch": 0.8574380165289256,
      "grad_norm": 0.5059385895729065,
      "learning_rate": 2.3823191733639496e-05,
      "loss": 0.1153,
      "step": 830
    },
    {
      "epoch": 0.8677685950413223,
      "grad_norm": 1.5861375331878662,
      "learning_rate": 2.370838117106774e-05,
      "loss": 0.082,
      "step": 840
    },
    {
      "epoch": 0.878099173553719,
      "grad_norm": 0.18188011646270752,
      "learning_rate": 2.3593570608495983e-05,
      "loss": 0.1176,
      "step": 850
    },
    {
      "epoch": 0.8884297520661157,
      "grad_norm": 0.8391039967536926,
      "learning_rate": 2.3478760045924226e-05,
      "loss": 0.1271,
      "step": 860
    },
    {
      "epoch": 0.8987603305785123,
      "grad_norm": 0.2083485871553421,
      "learning_rate": 2.336394948335247e-05,
      "loss": 0.0957,
      "step": 870
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 0.15146349370479584,
      "learning_rate": 2.3249138920780712e-05,
      "loss": 0.0738,
      "step": 880
    },
    {
      "epoch": 0.9194214876033058,
      "grad_norm": 0.1047869324684143,
      "learning_rate": 2.3134328358208956e-05,
      "loss": 0.1121,
      "step": 890
    },
    {
      "epoch": 0.9297520661157025,
      "grad_norm": 3.2168140411376953,
      "learning_rate": 2.30195177956372e-05,
      "loss": 0.1101,
      "step": 900
    },
    {
      "epoch": 0.9400826446280992,
      "grad_norm": 0.13192209601402283,
      "learning_rate": 2.2904707233065442e-05,
      "loss": 0.0719,
      "step": 910
    },
    {
      "epoch": 0.9504132231404959,
      "grad_norm": 0.39702078700065613,
      "learning_rate": 2.2789896670493686e-05,
      "loss": 0.0862,
      "step": 920
    },
    {
      "epoch": 0.9607438016528925,
      "grad_norm": 0.13047192990779877,
      "learning_rate": 2.2675086107921932e-05,
      "loss": 0.1204,
      "step": 930
    },
    {
      "epoch": 0.9710743801652892,
      "grad_norm": 1.1762135028839111,
      "learning_rate": 2.2560275545350176e-05,
      "loss": 0.0717,
      "step": 940
    },
    {
      "epoch": 0.981404958677686,
      "grad_norm": 1.3233284950256348,
      "learning_rate": 2.244546498277842e-05,
      "loss": 0.1014,
      "step": 950
    },
    {
      "epoch": 0.9917355371900827,
      "grad_norm": 0.10425760596990585,
      "learning_rate": 2.2330654420206662e-05,
      "loss": 0.0818,
      "step": 960
    },
    {
      "epoch": 1.0,
      "eval_f1": 0.5596330275229358,
      "eval_loss": 0.1058356985449791,
      "eval_precision": 0.8840579710144928,
      "eval_recall": 0.40939597315436244,
      "eval_runtime": 2.1741,
      "eval_samples_per_second": 1526.162,
      "eval_steps_per_second": 95.673,
      "step": 968
    },
    {
      "epoch": 1.0020661157024793,
      "grad_norm": 2.307504892349243,
      "learning_rate": 2.2215843857634906e-05,
      "loss": 0.0974,
      "step": 970
    },
    {
      "epoch": 1.012396694214876,
      "grad_norm": 0.123623788356781,
      "learning_rate": 2.210103329506315e-05,
      "loss": 0.0279,
      "step": 980
    },
    {
      "epoch": 1.0227272727272727,
      "grad_norm": 0.3242415487766266,
      "learning_rate": 2.1986222732491392e-05,
      "loss": 0.0522,
      "step": 990
    },
    {
      "epoch": 1.0330578512396693,
      "grad_norm": 6.822790622711182,
      "learning_rate": 2.1871412169919635e-05,
      "loss": 0.0633,
      "step": 1000
    },
    {
      "epoch": 1.0433884297520661,
      "grad_norm": 0.9614044427871704,
      "learning_rate": 2.175660160734788e-05,
      "loss": 0.0824,
      "step": 1010
    },
    {
      "epoch": 1.0537190082644627,
      "grad_norm": 1.8966021537780762,
      "learning_rate": 2.1641791044776122e-05,
      "loss": 0.1044,
      "step": 1020
    },
    {
      "epoch": 1.0640495867768596,
      "grad_norm": 0.05287262052297592,
      "learning_rate": 2.1526980482204365e-05,
      "loss": 0.0939,
      "step": 1030
    },
    {
      "epoch": 1.0743801652892562,
      "grad_norm": 0.10522923618555069,
      "learning_rate": 2.141216991963261e-05,
      "loss": 0.112,
      "step": 1040
    },
    {
      "epoch": 1.084710743801653,
      "grad_norm": 3.1031017303466797,
      "learning_rate": 2.1297359357060852e-05,
      "loss": 0.0514,
      "step": 1050
    },
    {
      "epoch": 1.0950413223140496,
      "grad_norm": 1.0611865520477295,
      "learning_rate": 2.1182548794489095e-05,
      "loss": 0.0474,
      "step": 1060
    },
    {
      "epoch": 1.1053719008264462,
      "grad_norm": 0.06263798475265503,
      "learning_rate": 2.106773823191734e-05,
      "loss": 0.0954,
      "step": 1070
    },
    {
      "epoch": 1.115702479338843,
      "grad_norm": 0.06872077286243439,
      "learning_rate": 2.0952927669345582e-05,
      "loss": 0.0124,
      "step": 1080
    },
    {
      "epoch": 1.1260330578512396,
      "grad_norm": 4.8909993171691895,
      "learning_rate": 2.0838117106773825e-05,
      "loss": 0.0362,
      "step": 1090
    },
    {
      "epoch": 1.1363636363636362,
      "grad_norm": 0.0586809366941452,
      "learning_rate": 2.072330654420207e-05,
      "loss": 0.0506,
      "step": 1100
    },
    {
      "epoch": 1.146694214876033,
      "grad_norm": 0.06938295066356659,
      "learning_rate": 2.0608495981630312e-05,
      "loss": 0.0835,
      "step": 1110
    },
    {
      "epoch": 1.1570247933884297,
      "grad_norm": 0.1178271621465683,
      "learning_rate": 2.0493685419058555e-05,
      "loss": 0.034,
      "step": 1120
    },
    {
      "epoch": 1.1673553719008265,
      "grad_norm": 9.415201187133789,
      "learning_rate": 2.03788748564868e-05,
      "loss": 0.0493,
      "step": 1130
    },
    {
      "epoch": 1.177685950413223,
      "grad_norm": 6.573145866394043,
      "learning_rate": 2.0264064293915042e-05,
      "loss": 0.1054,
      "step": 1140
    },
    {
      "epoch": 1.18801652892562,
      "grad_norm": 0.35469675064086914,
      "learning_rate": 2.0149253731343285e-05,
      "loss": 0.0247,
      "step": 1150
    },
    {
      "epoch": 1.1983471074380165,
      "grad_norm": 0.06778839975595474,
      "learning_rate": 2.003444316877153e-05,
      "loss": 0.1005,
      "step": 1160
    },
    {
      "epoch": 1.2086776859504131,
      "grad_norm": 0.9520415663719177,
      "learning_rate": 1.991963260619977e-05,
      "loss": 0.0546,
      "step": 1170
    },
    {
      "epoch": 1.21900826446281,
      "grad_norm": 0.16699615120887756,
      "learning_rate": 1.9804822043628015e-05,
      "loss": 0.096,
      "step": 1180
    },
    {
      "epoch": 1.2293388429752066,
      "grad_norm": 3.4162981510162354,
      "learning_rate": 1.9690011481056258e-05,
      "loss": 0.0805,
      "step": 1190
    },
    {
      "epoch": 1.2396694214876034,
      "grad_norm": 5.806140899658203,
      "learning_rate": 1.95752009184845e-05,
      "loss": 0.0416,
      "step": 1200
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.06414365768432617,
      "learning_rate": 1.9460390355912745e-05,
      "loss": 0.0335,
      "step": 1210
    },
    {
      "epoch": 1.2603305785123968,
      "grad_norm": 2.092292308807373,
      "learning_rate": 1.9345579793340988e-05,
      "loss": 0.0455,
      "step": 1220
    },
    {
      "epoch": 1.2706611570247934,
      "grad_norm": 0.062164291739463806,
      "learning_rate": 1.923076923076923e-05,
      "loss": 0.0374,
      "step": 1230
    },
    {
      "epoch": 1.28099173553719,
      "grad_norm": 0.13728547096252441,
      "learning_rate": 1.9115958668197475e-05,
      "loss": 0.0617,
      "step": 1240
    },
    {
      "epoch": 1.2913223140495869,
      "grad_norm": 0.06379790604114532,
      "learning_rate": 1.9001148105625718e-05,
      "loss": 0.0441,
      "step": 1250
    },
    {
      "epoch": 1.3016528925619835,
      "grad_norm": 0.7551154494285583,
      "learning_rate": 1.8886337543053965e-05,
      "loss": 0.0313,
      "step": 1260
    },
    {
      "epoch": 1.31198347107438,
      "grad_norm": 13.177129745483398,
      "learning_rate": 1.8771526980482208e-05,
      "loss": 0.0178,
      "step": 1270
    },
    {
      "epoch": 1.322314049586777,
      "grad_norm": 0.03594193980097771,
      "learning_rate": 1.8656716417910448e-05,
      "loss": 0.0411,
      "step": 1280
    },
    {
      "epoch": 1.3326446280991735,
      "grad_norm": 0.03119136393070221,
      "learning_rate": 1.854190585533869e-05,
      "loss": 0.0175,
      "step": 1290
    },
    {
      "epoch": 1.3429752066115703,
      "grad_norm": 0.20991139113903046,
      "learning_rate": 1.8427095292766935e-05,
      "loss": 0.1568,
      "step": 1300
    },
    {
      "epoch": 1.353305785123967,
      "grad_norm": 0.34645816683769226,
      "learning_rate": 1.8312284730195178e-05,
      "loss": 0.0333,
      "step": 1310
    },
    {
      "epoch": 1.3636363636363638,
      "grad_norm": 0.041028447449207306,
      "learning_rate": 1.819747416762342e-05,
      "loss": 0.1028,
      "step": 1320
    },
    {
      "epoch": 1.3739669421487604,
      "grad_norm": 4.654887676239014,
      "learning_rate": 1.8082663605051664e-05,
      "loss": 0.1066,
      "step": 1330
    },
    {
      "epoch": 1.384297520661157,
      "grad_norm": 0.045202746987342834,
      "learning_rate": 1.7967853042479908e-05,
      "loss": 0.098,
      "step": 1340
    },
    {
      "epoch": 1.3946280991735538,
      "grad_norm": 0.08618631213903427,
      "learning_rate": 1.785304247990815e-05,
      "loss": 0.0619,
      "step": 1350
    },
    {
      "epoch": 1.4049586776859504,
      "grad_norm": 0.10682868212461472,
      "learning_rate": 1.7738231917336394e-05,
      "loss": 0.0454,
      "step": 1360
    },
    {
      "epoch": 1.415289256198347,
      "grad_norm": 4.030128002166748,
      "learning_rate": 1.7623421354764638e-05,
      "loss": 0.1108,
      "step": 1370
    },
    {
      "epoch": 1.4256198347107438,
      "grad_norm": 0.11785311996936798,
      "learning_rate": 1.750861079219288e-05,
      "loss": 0.071,
      "step": 1380
    },
    {
      "epoch": 1.4359504132231404,
      "grad_norm": 3.49658203125,
      "learning_rate": 1.7393800229621124e-05,
      "loss": 0.0415,
      "step": 1390
    },
    {
      "epoch": 1.4462809917355373,
      "grad_norm": 0.04287709295749664,
      "learning_rate": 1.7278989667049368e-05,
      "loss": 0.0413,
      "step": 1400
    },
    {
      "epoch": 1.4566115702479339,
      "grad_norm": 4.077906131744385,
      "learning_rate": 1.716417910447761e-05,
      "loss": 0.1188,
      "step": 1410
    },
    {
      "epoch": 1.4669421487603307,
      "grad_norm": 3.540703773498535,
      "learning_rate": 1.7049368541905854e-05,
      "loss": 0.0871,
      "step": 1420
    },
    {
      "epoch": 1.4772727272727273,
      "grad_norm": 4.969836711883545,
      "learning_rate": 1.6934557979334097e-05,
      "loss": 0.0864,
      "step": 1430
    },
    {
      "epoch": 1.487603305785124,
      "grad_norm": 1.3659641742706299,
      "learning_rate": 1.681974741676234e-05,
      "loss": 0.0418,
      "step": 1440
    },
    {
      "epoch": 1.4979338842975207,
      "grad_norm": 0.05919983983039856,
      "learning_rate": 1.6704936854190584e-05,
      "loss": 0.0732,
      "step": 1450
    },
    {
      "epoch": 1.5082644628099173,
      "grad_norm": 13.804028511047363,
      "learning_rate": 1.6590126291618827e-05,
      "loss": 0.0382,
      "step": 1460
    },
    {
      "epoch": 1.518595041322314,
      "grad_norm": 0.0765862837433815,
      "learning_rate": 1.647531572904707e-05,
      "loss": 0.0746,
      "step": 1470
    },
    {
      "epoch": 1.5289256198347108,
      "grad_norm": 9.36489200592041,
      "learning_rate": 1.6360505166475314e-05,
      "loss": 0.0618,
      "step": 1480
    },
    {
      "epoch": 1.5392561983471076,
      "grad_norm": 0.39845091104507446,
      "learning_rate": 1.6245694603903557e-05,
      "loss": 0.0414,
      "step": 1490
    },
    {
      "epoch": 1.549586776859504,
      "grad_norm": 4.747336387634277,
      "learning_rate": 1.61308840413318e-05,
      "loss": 0.0373,
      "step": 1500
    },
    {
      "epoch": 1.5599173553719008,
      "grad_norm": 1.2551634311676025,
      "learning_rate": 1.6016073478760044e-05,
      "loss": 0.0739,
      "step": 1510
    },
    {
      "epoch": 1.5702479338842976,
      "grad_norm": 3.371098279953003,
      "learning_rate": 1.5901262916188287e-05,
      "loss": 0.1302,
      "step": 1520
    },
    {
      "epoch": 1.5805785123966942,
      "grad_norm": 0.12872624397277832,
      "learning_rate": 1.578645235361653e-05,
      "loss": 0.0355,
      "step": 1530
    },
    {
      "epoch": 1.5909090909090908,
      "grad_norm": 0.49822843074798584,
      "learning_rate": 1.5671641791044774e-05,
      "loss": 0.057,
      "step": 1540
    },
    {
      "epoch": 1.6012396694214877,
      "grad_norm": 0.08220572769641876,
      "learning_rate": 1.5556831228473017e-05,
      "loss": 0.0893,
      "step": 1550
    },
    {
      "epoch": 1.6115702479338843,
      "grad_norm": 4.054084300994873,
      "learning_rate": 1.544202066590126e-05,
      "loss": 0.0724,
      "step": 1560
    },
    {
      "epoch": 1.6219008264462809,
      "grad_norm": 1.999149203300476,
      "learning_rate": 1.5327210103329504e-05,
      "loss": 0.0587,
      "step": 1570
    },
    {
      "epoch": 1.6322314049586777,
      "grad_norm": 0.05214665085077286,
      "learning_rate": 1.5212399540757749e-05,
      "loss": 0.0909,
      "step": 1580
    },
    {
      "epoch": 1.6425619834710745,
      "grad_norm": 0.10713449865579605,
      "learning_rate": 1.5097588978185992e-05,
      "loss": 0.0876,
      "step": 1590
    },
    {
      "epoch": 1.6528925619834711,
      "grad_norm": 0.24414800107479095,
      "learning_rate": 1.4982778415614237e-05,
      "loss": 0.0459,
      "step": 1600
    },
    {
      "epoch": 1.6632231404958677,
      "grad_norm": 0.05590007081627846,
      "learning_rate": 1.486796785304248e-05,
      "loss": 0.0622,
      "step": 1610
    },
    {
      "epoch": 1.6735537190082646,
      "grad_norm": 3.7191364765167236,
      "learning_rate": 1.4753157290470724e-05,
      "loss": 0.1268,
      "step": 1620
    },
    {
      "epoch": 1.6838842975206612,
      "grad_norm": 7.080004692077637,
      "learning_rate": 1.4638346727898967e-05,
      "loss": 0.0585,
      "step": 1630
    },
    {
      "epoch": 1.6942148760330578,
      "grad_norm": 10.800445556640625,
      "learning_rate": 1.452353616532721e-05,
      "loss": 0.0357,
      "step": 1640
    },
    {
      "epoch": 1.7045454545454546,
      "grad_norm": 0.041540659964084625,
      "learning_rate": 1.4408725602755454e-05,
      "loss": 0.003,
      "step": 1650
    },
    {
      "epoch": 1.7148760330578512,
      "grad_norm": 0.031082525849342346,
      "learning_rate": 1.4293915040183697e-05,
      "loss": 0.0557,
      "step": 1660
    },
    {
      "epoch": 1.7252066115702478,
      "grad_norm": 5.370367527008057,
      "learning_rate": 1.4179104477611942e-05,
      "loss": 0.1584,
      "step": 1670
    },
    {
      "epoch": 1.7355371900826446,
      "grad_norm": 0.1258482187986374,
      "learning_rate": 1.4064293915040185e-05,
      "loss": 0.0391,
      "step": 1680
    },
    {
      "epoch": 1.7458677685950414,
      "grad_norm": 0.03635608032345772,
      "learning_rate": 1.3949483352468428e-05,
      "loss": 0.0103,
      "step": 1690
    },
    {
      "epoch": 1.756198347107438,
      "grad_norm": 0.039122920483350754,
      "learning_rate": 1.3834672789896672e-05,
      "loss": 0.0658,
      "step": 1700
    },
    {
      "epoch": 1.7665289256198347,
      "grad_norm": 5.181463241577148,
      "learning_rate": 1.3719862227324915e-05,
      "loss": 0.0799,
      "step": 1710
    },
    {
      "epoch": 1.7768595041322315,
      "grad_norm": 1.9748351573944092,
      "learning_rate": 1.3605051664753158e-05,
      "loss": 0.1161,
      "step": 1720
    },
    {
      "epoch": 1.787190082644628,
      "grad_norm": 0.03418581560254097,
      "learning_rate": 1.3490241102181402e-05,
      "loss": 0.0507,
      "step": 1730
    },
    {
      "epoch": 1.7975206611570247,
      "grad_norm": 0.04417262598872185,
      "learning_rate": 1.3375430539609645e-05,
      "loss": 0.0179,
      "step": 1740
    },
    {
      "epoch": 1.8078512396694215,
      "grad_norm": 0.04807627201080322,
      "learning_rate": 1.3260619977037888e-05,
      "loss": 0.0583,
      "step": 1750
    },
    {
      "epoch": 1.8181818181818183,
      "grad_norm": 0.042777515947818756,
      "learning_rate": 1.3145809414466132e-05,
      "loss": 0.0033,
      "step": 1760
    },
    {
      "epoch": 1.8285123966942147,
      "grad_norm": 0.03992082551121712,
      "learning_rate": 1.3030998851894375e-05,
      "loss": 0.0642,
      "step": 1770
    },
    {
      "epoch": 1.8388429752066116,
      "grad_norm": 0.0983252227306366,
      "learning_rate": 1.2916188289322618e-05,
      "loss": 0.0248,
      "step": 1780
    },
    {
      "epoch": 1.8491735537190084,
      "grad_norm": 0.5574432015419006,
      "learning_rate": 1.2801377726750862e-05,
      "loss": 0.0683,
      "step": 1790
    },
    {
      "epoch": 1.859504132231405,
      "grad_norm": 0.08306654542684555,
      "learning_rate": 1.2686567164179105e-05,
      "loss": 0.0753,
      "step": 1800
    },
    {
      "epoch": 1.8698347107438016,
      "grad_norm": 1.0142017602920532,
      "learning_rate": 1.2571756601607348e-05,
      "loss": 0.0807,
      "step": 1810
    },
    {
      "epoch": 1.8801652892561984,
      "grad_norm": 6.128114700317383,
      "learning_rate": 1.2456946039035591e-05,
      "loss": 0.078,
      "step": 1820
    },
    {
      "epoch": 1.890495867768595,
      "grad_norm": 3.1906442642211914,
      "learning_rate": 1.2342135476463835e-05,
      "loss": 0.051,
      "step": 1830
    },
    {
      "epoch": 1.9008264462809916,
      "grad_norm": 0.2776181697845459,
      "learning_rate": 1.222732491389208e-05,
      "loss": 0.0299,
      "step": 1840
    },
    {
      "epoch": 1.9111570247933884,
      "grad_norm": 0.17702387273311615,
      "learning_rate": 1.2112514351320323e-05,
      "loss": 0.0649,
      "step": 1850
    },
    {
      "epoch": 1.9214876033057853,
      "grad_norm": 0.10642986744642258,
      "learning_rate": 1.1997703788748566e-05,
      "loss": 0.0362,
      "step": 1860
    },
    {
      "epoch": 1.9318181818181817,
      "grad_norm": 0.3002626895904541,
      "learning_rate": 1.188289322617681e-05,
      "loss": 0.0786,
      "step": 1870
    },
    {
      "epoch": 1.9421487603305785,
      "grad_norm": 0.21868941187858582,
      "learning_rate": 1.1768082663605053e-05,
      "loss": 0.0683,
      "step": 1880
    },
    {
      "epoch": 1.9524793388429753,
      "grad_norm": 0.031779658049345016,
      "learning_rate": 1.1653272101033296e-05,
      "loss": 0.0613,
      "step": 1890
    },
    {
      "epoch": 1.962809917355372,
      "grad_norm": 4.187682628631592,
      "learning_rate": 1.153846153846154e-05,
      "loss": 0.0834,
      "step": 1900
    },
    {
      "epoch": 1.9731404958677685,
      "grad_norm": 0.07033954560756683,
      "learning_rate": 1.1423650975889783e-05,
      "loss": 0.0275,
      "step": 1910
    },
    {
      "epoch": 1.9834710743801653,
      "grad_norm": 0.23350340127944946,
      "learning_rate": 1.1308840413318026e-05,
      "loss": 0.0379,
      "step": 1920
    },
    {
      "epoch": 1.993801652892562,
      "grad_norm": 0.11745541542768478,
      "learning_rate": 1.119402985074627e-05,
      "loss": 0.0251,
      "step": 1930
    },
    {
      "epoch": 2.0,
      "eval_f1": 0.7509293680297398,
      "eval_loss": 0.08389206975698471,
      "eval_precision": 0.8416666666666667,
      "eval_recall": 0.6778523489932886,
      "eval_runtime": 1.971,
      "eval_samples_per_second": 1683.399,
      "eval_steps_per_second": 105.53,
      "step": 1936
    }
  ],
  "logging_steps": 10,
  "max_steps": 2904,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1025628834094080.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
