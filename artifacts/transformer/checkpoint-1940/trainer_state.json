{
  "best_global_step": 1940,
  "best_metric": 0.08797562122344971,
  "best_model_checkpoint": "/home/snguyen/spot-the-scam-project/artifacts/transformer/checkpoint-1940",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 1940,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010309278350515464,
      "grad_norm": 4.314894199371338,
      "learning_rate": 9.278350515463919e-07,
      "loss": 0.6838,
      "step": 10
    },
    {
      "epoch": 0.020618556701030927,
      "grad_norm": 3.7837984561920166,
      "learning_rate": 1.9587628865979384e-06,
      "loss": 0.6513,
      "step": 20
    },
    {
      "epoch": 0.030927835051546393,
      "grad_norm": 4.0145745277404785,
      "learning_rate": 2.989690721649485e-06,
      "loss": 0.6005,
      "step": 30
    },
    {
      "epoch": 0.041237113402061855,
      "grad_norm": 3.811756134033203,
      "learning_rate": 4.020618556701031e-06,
      "loss": 0.5166,
      "step": 40
    },
    {
      "epoch": 0.05154639175257732,
      "grad_norm": 3.2403111457824707,
      "learning_rate": 5.051546391752578e-06,
      "loss": 0.4146,
      "step": 50
    },
    {
      "epoch": 0.061855670103092786,
      "grad_norm": 2.0522730350494385,
      "learning_rate": 6.082474226804124e-06,
      "loss": 0.2646,
      "step": 60
    },
    {
      "epoch": 0.07216494845360824,
      "grad_norm": 1.110175609588623,
      "learning_rate": 7.11340206185567e-06,
      "loss": 0.2111,
      "step": 70
    },
    {
      "epoch": 0.08247422680412371,
      "grad_norm": 1.3175601959228516,
      "learning_rate": 8.144329896907216e-06,
      "loss": 0.2271,
      "step": 80
    },
    {
      "epoch": 0.09278350515463918,
      "grad_norm": 0.962579607963562,
      "learning_rate": 9.175257731958764e-06,
      "loss": 0.1704,
      "step": 90
    },
    {
      "epoch": 0.10309278350515463,
      "grad_norm": 0.6905212998390198,
      "learning_rate": 1.020618556701031e-05,
      "loss": 0.1418,
      "step": 100
    },
    {
      "epoch": 0.1134020618556701,
      "grad_norm": 2.1871984004974365,
      "learning_rate": 1.1237113402061856e-05,
      "loss": 0.2206,
      "step": 110
    },
    {
      "epoch": 0.12371134020618557,
      "grad_norm": 1.163896083831787,
      "learning_rate": 1.2268041237113401e-05,
      "loss": 0.088,
      "step": 120
    },
    {
      "epoch": 0.13402061855670103,
      "grad_norm": 0.36792489886283875,
      "learning_rate": 1.3298969072164948e-05,
      "loss": 0.1181,
      "step": 130
    },
    {
      "epoch": 0.14432989690721648,
      "grad_norm": 1.96794855594635,
      "learning_rate": 1.4329896907216495e-05,
      "loss": 0.1559,
      "step": 140
    },
    {
      "epoch": 0.15463917525773196,
      "grad_norm": 1.5609816312789917,
      "learning_rate": 1.536082474226804e-05,
      "loss": 0.1945,
      "step": 150
    },
    {
      "epoch": 0.16494845360824742,
      "grad_norm": 1.109866738319397,
      "learning_rate": 1.6391752577319588e-05,
      "loss": 0.1791,
      "step": 160
    },
    {
      "epoch": 0.17525773195876287,
      "grad_norm": 1.3609087467193604,
      "learning_rate": 1.7422680412371137e-05,
      "loss": 0.1757,
      "step": 170
    },
    {
      "epoch": 0.18556701030927836,
      "grad_norm": 0.5843567848205566,
      "learning_rate": 1.8453608247422682e-05,
      "loss": 0.1251,
      "step": 180
    },
    {
      "epoch": 0.1958762886597938,
      "grad_norm": 1.913251280784607,
      "learning_rate": 1.9484536082474227e-05,
      "loss": 0.1506,
      "step": 190
    },
    {
      "epoch": 0.20618556701030927,
      "grad_norm": 3.1643269062042236,
      "learning_rate": 2.0515463917525773e-05,
      "loss": 0.1996,
      "step": 200
    },
    {
      "epoch": 0.21649484536082475,
      "grad_norm": 0.1744464635848999,
      "learning_rate": 2.154639175257732e-05,
      "loss": 0.0667,
      "step": 210
    },
    {
      "epoch": 0.2268041237113402,
      "grad_norm": 0.15750037133693695,
      "learning_rate": 2.2577319587628867e-05,
      "loss": 0.0669,
      "step": 220
    },
    {
      "epoch": 0.23711340206185566,
      "grad_norm": 1.355411171913147,
      "learning_rate": 2.3608247422680412e-05,
      "loss": 0.2031,
      "step": 230
    },
    {
      "epoch": 0.24742268041237114,
      "grad_norm": 1.5184695720672607,
      "learning_rate": 2.4639175257731957e-05,
      "loss": 0.1038,
      "step": 240
    },
    {
      "epoch": 0.25773195876288657,
      "grad_norm": 2.379319667816162,
      "learning_rate": 2.5670103092783506e-05,
      "loss": 0.315,
      "step": 250
    },
    {
      "epoch": 0.26804123711340205,
      "grad_norm": 0.805148184299469,
      "learning_rate": 2.670103092783505e-05,
      "loss": 0.1428,
      "step": 260
    },
    {
      "epoch": 0.27835051546391754,
      "grad_norm": 2.0695419311523438,
      "learning_rate": 2.77319587628866e-05,
      "loss": 0.2112,
      "step": 270
    },
    {
      "epoch": 0.28865979381443296,
      "grad_norm": 1.8109172582626343,
      "learning_rate": 2.8762886597938146e-05,
      "loss": 0.3002,
      "step": 280
    },
    {
      "epoch": 0.29896907216494845,
      "grad_norm": 2.336009979248047,
      "learning_rate": 2.979381443298969e-05,
      "loss": 0.1971,
      "step": 290
    },
    {
      "epoch": 0.30927835051546393,
      "grad_norm": 0.6937296986579895,
      "learning_rate": 2.990836197021764e-05,
      "loss": 0.2583,
      "step": 300
    },
    {
      "epoch": 0.31958762886597936,
      "grad_norm": 0.6259313821792603,
      "learning_rate": 2.979381443298969e-05,
      "loss": 0.1387,
      "step": 310
    },
    {
      "epoch": 0.32989690721649484,
      "grad_norm": 0.18716026842594147,
      "learning_rate": 2.9679266895761742e-05,
      "loss": 0.1397,
      "step": 320
    },
    {
      "epoch": 0.3402061855670103,
      "grad_norm": 0.4251575171947479,
      "learning_rate": 2.9564719358533794e-05,
      "loss": 0.1918,
      "step": 330
    },
    {
      "epoch": 0.35051546391752575,
      "grad_norm": 1.5604524612426758,
      "learning_rate": 2.945017182130584e-05,
      "loss": 0.1667,
      "step": 340
    },
    {
      "epoch": 0.36082474226804123,
      "grad_norm": 0.5249528288841248,
      "learning_rate": 2.9335624284077893e-05,
      "loss": 0.1061,
      "step": 350
    },
    {
      "epoch": 0.3711340206185567,
      "grad_norm": 1.1840565204620361,
      "learning_rate": 2.9221076746849944e-05,
      "loss": 0.0814,
      "step": 360
    },
    {
      "epoch": 0.38144329896907214,
      "grad_norm": 1.1961110830307007,
      "learning_rate": 2.9106529209621995e-05,
      "loss": 0.086,
      "step": 370
    },
    {
      "epoch": 0.3917525773195876,
      "grad_norm": 4.562936305999756,
      "learning_rate": 2.8991981672394047e-05,
      "loss": 0.1534,
      "step": 380
    },
    {
      "epoch": 0.4020618556701031,
      "grad_norm": 1.4794033765792847,
      "learning_rate": 2.8877434135166094e-05,
      "loss": 0.1599,
      "step": 390
    },
    {
      "epoch": 0.41237113402061853,
      "grad_norm": 1.7613484859466553,
      "learning_rate": 2.8762886597938146e-05,
      "loss": 0.1037,
      "step": 400
    },
    {
      "epoch": 0.422680412371134,
      "grad_norm": 0.26197779178619385,
      "learning_rate": 2.8648339060710194e-05,
      "loss": 0.1489,
      "step": 410
    },
    {
      "epoch": 0.4329896907216495,
      "grad_norm": 0.3243570327758789,
      "learning_rate": 2.8533791523482248e-05,
      "loss": 0.1081,
      "step": 420
    },
    {
      "epoch": 0.44329896907216493,
      "grad_norm": 3.604532480239868,
      "learning_rate": 2.8419243986254296e-05,
      "loss": 0.1223,
      "step": 430
    },
    {
      "epoch": 0.4536082474226804,
      "grad_norm": 0.21145130693912506,
      "learning_rate": 2.8304696449026347e-05,
      "loss": 0.1264,
      "step": 440
    },
    {
      "epoch": 0.4639175257731959,
      "grad_norm": 3.1102986335754395,
      "learning_rate": 2.8190148911798395e-05,
      "loss": 0.1931,
      "step": 450
    },
    {
      "epoch": 0.4742268041237113,
      "grad_norm": 0.5126515626907349,
      "learning_rate": 2.8075601374570446e-05,
      "loss": 0.116,
      "step": 460
    },
    {
      "epoch": 0.4845360824742268,
      "grad_norm": 0.35979941487312317,
      "learning_rate": 2.7961053837342498e-05,
      "loss": 0.0904,
      "step": 470
    },
    {
      "epoch": 0.4948453608247423,
      "grad_norm": 2.98683500289917,
      "learning_rate": 2.784650630011455e-05,
      "loss": 0.0541,
      "step": 480
    },
    {
      "epoch": 0.5051546391752577,
      "grad_norm": 0.11792970448732376,
      "learning_rate": 2.77319587628866e-05,
      "loss": 0.0545,
      "step": 490
    },
    {
      "epoch": 0.5154639175257731,
      "grad_norm": 2.0062994956970215,
      "learning_rate": 2.7617411225658648e-05,
      "loss": 0.0763,
      "step": 500
    },
    {
      "epoch": 0.5257731958762887,
      "grad_norm": 0.0937633141875267,
      "learning_rate": 2.75028636884307e-05,
      "loss": 0.0841,
      "step": 510
    },
    {
      "epoch": 0.5360824742268041,
      "grad_norm": 0.2565065622329712,
      "learning_rate": 2.738831615120275e-05,
      "loss": 0.1802,
      "step": 520
    },
    {
      "epoch": 0.5463917525773195,
      "grad_norm": 1.2882879972457886,
      "learning_rate": 2.7273768613974802e-05,
      "loss": 0.1873,
      "step": 530
    },
    {
      "epoch": 0.5567010309278351,
      "grad_norm": 1.657853603363037,
      "learning_rate": 2.715922107674685e-05,
      "loss": 0.1381,
      "step": 540
    },
    {
      "epoch": 0.5670103092783505,
      "grad_norm": 2.1311137676239014,
      "learning_rate": 2.70446735395189e-05,
      "loss": 0.0813,
      "step": 550
    },
    {
      "epoch": 0.5773195876288659,
      "grad_norm": 0.2018716037273407,
      "learning_rate": 2.693012600229095e-05,
      "loss": 0.0915,
      "step": 560
    },
    {
      "epoch": 0.5876288659793815,
      "grad_norm": 0.8919218182563782,
      "learning_rate": 2.6815578465063004e-05,
      "loss": 0.1144,
      "step": 570
    },
    {
      "epoch": 0.5979381443298969,
      "grad_norm": 0.2343275547027588,
      "learning_rate": 2.670103092783505e-05,
      "loss": 0.1223,
      "step": 580
    },
    {
      "epoch": 0.6082474226804123,
      "grad_norm": 0.8960727453231812,
      "learning_rate": 2.6586483390607103e-05,
      "loss": 0.1274,
      "step": 590
    },
    {
      "epoch": 0.6185567010309279,
      "grad_norm": 1.9453614950180054,
      "learning_rate": 2.6471935853379154e-05,
      "loss": 0.0765,
      "step": 600
    },
    {
      "epoch": 0.6288659793814433,
      "grad_norm": 6.397735118865967,
      "learning_rate": 2.6357388316151202e-05,
      "loss": 0.1088,
      "step": 610
    },
    {
      "epoch": 0.6391752577319587,
      "grad_norm": 1.7207105159759521,
      "learning_rate": 2.6242840778923257e-05,
      "loss": 0.0957,
      "step": 620
    },
    {
      "epoch": 0.6494845360824743,
      "grad_norm": 0.1343318074941635,
      "learning_rate": 2.6128293241695305e-05,
      "loss": 0.1009,
      "step": 630
    },
    {
      "epoch": 0.6597938144329897,
      "grad_norm": 4.1273627281188965,
      "learning_rate": 2.6013745704467356e-05,
      "loss": 0.1743,
      "step": 640
    },
    {
      "epoch": 0.6701030927835051,
      "grad_norm": 0.714852511882782,
      "learning_rate": 2.5899198167239404e-05,
      "loss": 0.115,
      "step": 650
    },
    {
      "epoch": 0.6804123711340206,
      "grad_norm": 0.18657930195331573,
      "learning_rate": 2.5784650630011455e-05,
      "loss": 0.1061,
      "step": 660
    },
    {
      "epoch": 0.6907216494845361,
      "grad_norm": 0.1511472463607788,
      "learning_rate": 2.5670103092783506e-05,
      "loss": 0.0734,
      "step": 670
    },
    {
      "epoch": 0.7010309278350515,
      "grad_norm": 1.9807809591293335,
      "learning_rate": 2.5555555555555557e-05,
      "loss": 0.1707,
      "step": 680
    },
    {
      "epoch": 0.711340206185567,
      "grad_norm": 0.14550964534282684,
      "learning_rate": 2.5441008018327605e-05,
      "loss": 0.1264,
      "step": 690
    },
    {
      "epoch": 0.7216494845360825,
      "grad_norm": 0.13675682246685028,
      "learning_rate": 2.5326460481099657e-05,
      "loss": 0.0691,
      "step": 700
    },
    {
      "epoch": 0.7319587628865979,
      "grad_norm": 3.7185611724853516,
      "learning_rate": 2.5211912943871708e-05,
      "loss": 0.1795,
      "step": 710
    },
    {
      "epoch": 0.7422680412371134,
      "grad_norm": 1.8044629096984863,
      "learning_rate": 2.5097365406643756e-05,
      "loss": 0.1127,
      "step": 720
    },
    {
      "epoch": 0.7525773195876289,
      "grad_norm": 1.7722716331481934,
      "learning_rate": 2.498281786941581e-05,
      "loss": 0.1548,
      "step": 730
    },
    {
      "epoch": 0.7628865979381443,
      "grad_norm": 0.10730157792568207,
      "learning_rate": 2.4868270332187858e-05,
      "loss": 0.1283,
      "step": 740
    },
    {
      "epoch": 0.7731958762886598,
      "grad_norm": 0.05959043651819229,
      "learning_rate": 2.475372279495991e-05,
      "loss": 0.036,
      "step": 750
    },
    {
      "epoch": 0.7835051546391752,
      "grad_norm": 0.09583369642496109,
      "learning_rate": 2.4639175257731957e-05,
      "loss": 0.0958,
      "step": 760
    },
    {
      "epoch": 0.7938144329896907,
      "grad_norm": 0.18281808495521545,
      "learning_rate": 2.452462772050401e-05,
      "loss": 0.086,
      "step": 770
    },
    {
      "epoch": 0.8041237113402062,
      "grad_norm": 1.5408128499984741,
      "learning_rate": 2.441008018327606e-05,
      "loss": 0.0949,
      "step": 780
    },
    {
      "epoch": 0.8144329896907216,
      "grad_norm": 2.2456984519958496,
      "learning_rate": 2.429553264604811e-05,
      "loss": 0.0612,
      "step": 790
    },
    {
      "epoch": 0.8247422680412371,
      "grad_norm": 0.10736393928527832,
      "learning_rate": 2.418098510882016e-05,
      "loss": 0.1081,
      "step": 800
    },
    {
      "epoch": 0.8350515463917526,
      "grad_norm": 4.185237884521484,
      "learning_rate": 2.406643757159221e-05,
      "loss": 0.148,
      "step": 810
    },
    {
      "epoch": 0.845360824742268,
      "grad_norm": 4.017673969268799,
      "learning_rate": 2.395189003436426e-05,
      "loss": 0.1849,
      "step": 820
    },
    {
      "epoch": 0.8556701030927835,
      "grad_norm": 0.1946847140789032,
      "learning_rate": 2.3837342497136313e-05,
      "loss": 0.0983,
      "step": 830
    },
    {
      "epoch": 0.865979381443299,
      "grad_norm": 1.7497658729553223,
      "learning_rate": 2.3722794959908364e-05,
      "loss": 0.1541,
      "step": 840
    },
    {
      "epoch": 0.8762886597938144,
      "grad_norm": 0.5713124871253967,
      "learning_rate": 2.3608247422680412e-05,
      "loss": 0.0528,
      "step": 850
    },
    {
      "epoch": 0.8865979381443299,
      "grad_norm": 3.043968677520752,
      "learning_rate": 2.3493699885452463e-05,
      "loss": 0.098,
      "step": 860
    },
    {
      "epoch": 0.8969072164948454,
      "grad_norm": 3.163991689682007,
      "learning_rate": 2.337915234822451e-05,
      "loss": 0.1485,
      "step": 870
    },
    {
      "epoch": 0.9072164948453608,
      "grad_norm": 2.9232876300811768,
      "learning_rate": 2.3264604810996566e-05,
      "loss": 0.1057,
      "step": 880
    },
    {
      "epoch": 0.9175257731958762,
      "grad_norm": 0.25943681597709656,
      "learning_rate": 2.3150057273768614e-05,
      "loss": 0.0951,
      "step": 890
    },
    {
      "epoch": 0.9278350515463918,
      "grad_norm": 2.030359983444214,
      "learning_rate": 2.3035509736540665e-05,
      "loss": 0.1688,
      "step": 900
    },
    {
      "epoch": 0.9381443298969072,
      "grad_norm": 1.948674201965332,
      "learning_rate": 2.2920962199312713e-05,
      "loss": 0.1719,
      "step": 910
    },
    {
      "epoch": 0.9484536082474226,
      "grad_norm": 3.027761459350586,
      "learning_rate": 2.2806414662084764e-05,
      "loss": 0.1388,
      "step": 920
    },
    {
      "epoch": 0.9587628865979382,
      "grad_norm": 0.2172887921333313,
      "learning_rate": 2.269186712485682e-05,
      "loss": 0.1227,
      "step": 930
    },
    {
      "epoch": 0.9690721649484536,
      "grad_norm": 1.7748627662658691,
      "learning_rate": 2.2577319587628867e-05,
      "loss": 0.0768,
      "step": 940
    },
    {
      "epoch": 0.979381443298969,
      "grad_norm": 0.3330886960029602,
      "learning_rate": 2.2462772050400918e-05,
      "loss": 0.1461,
      "step": 950
    },
    {
      "epoch": 0.9896907216494846,
      "grad_norm": 0.28251418471336365,
      "learning_rate": 2.2348224513172966e-05,
      "loss": 0.0466,
      "step": 960
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.09794526547193527,
      "learning_rate": 2.2233676975945017e-05,
      "loss": 0.0798,
      "step": 970
    },
    {
      "epoch": 1.0,
      "eval_f1": 0.5945945945945946,
      "eval_loss": 0.10660228133201599,
      "eval_precision": 0.9166666666666666,
      "eval_recall": 0.44,
      "eval_runtime": 2.3711,
      "eval_samples_per_second": 1401.44,
      "eval_steps_per_second": 87.722,
      "step": 970
    },
    {
      "epoch": 1.0103092783505154,
      "grad_norm": 1.5181342363357544,
      "learning_rate": 2.211912943871707e-05,
      "loss": 0.1084,
      "step": 980
    },
    {
      "epoch": 1.0206185567010309,
      "grad_norm": 0.34650447964668274,
      "learning_rate": 2.200458190148912e-05,
      "loss": 0.0896,
      "step": 990
    },
    {
      "epoch": 1.0309278350515463,
      "grad_norm": 0.3005879819393158,
      "learning_rate": 2.1890034364261168e-05,
      "loss": 0.0828,
      "step": 1000
    },
    {
      "epoch": 1.041237113402062,
      "grad_norm": 0.39926406741142273,
      "learning_rate": 2.177548682703322e-05,
      "loss": 0.0923,
      "step": 1010
    },
    {
      "epoch": 1.0515463917525774,
      "grad_norm": 0.07718044519424438,
      "learning_rate": 2.1660939289805267e-05,
      "loss": 0.0192,
      "step": 1020
    },
    {
      "epoch": 1.0618556701030928,
      "grad_norm": 3.9765465259552,
      "learning_rate": 2.154639175257732e-05,
      "loss": 0.0737,
      "step": 1030
    },
    {
      "epoch": 1.0721649484536082,
      "grad_norm": 0.32922038435935974,
      "learning_rate": 2.1431844215349373e-05,
      "loss": 0.0219,
      "step": 1040
    },
    {
      "epoch": 1.0824742268041236,
      "grad_norm": 0.08451151847839355,
      "learning_rate": 2.131729667812142e-05,
      "loss": 0.099,
      "step": 1050
    },
    {
      "epoch": 1.0927835051546393,
      "grad_norm": 0.08641422539949417,
      "learning_rate": 2.1202749140893472e-05,
      "loss": 0.0749,
      "step": 1060
    },
    {
      "epoch": 1.1030927835051547,
      "grad_norm": 0.15607072412967682,
      "learning_rate": 2.108820160366552e-05,
      "loss": 0.0111,
      "step": 1070
    },
    {
      "epoch": 1.1134020618556701,
      "grad_norm": 1.6307711601257324,
      "learning_rate": 2.0973654066437574e-05,
      "loss": 0.0548,
      "step": 1080
    },
    {
      "epoch": 1.1237113402061856,
      "grad_norm": 0.049039073288440704,
      "learning_rate": 2.0859106529209622e-05,
      "loss": 0.0338,
      "step": 1090
    },
    {
      "epoch": 1.134020618556701,
      "grad_norm": 0.04898678511381149,
      "learning_rate": 2.0744558991981673e-05,
      "loss": 0.1003,
      "step": 1100
    },
    {
      "epoch": 1.1443298969072164,
      "grad_norm": 0.06471017003059387,
      "learning_rate": 2.063001145475372e-05,
      "loss": 0.0221,
      "step": 1110
    },
    {
      "epoch": 1.1546391752577319,
      "grad_norm": 0.10055708885192871,
      "learning_rate": 2.0515463917525773e-05,
      "loss": 0.0079,
      "step": 1120
    },
    {
      "epoch": 1.1649484536082475,
      "grad_norm": 9.467011451721191,
      "learning_rate": 2.0400916380297824e-05,
      "loss": 0.1066,
      "step": 1130
    },
    {
      "epoch": 1.175257731958763,
      "grad_norm": 0.2494686096906662,
      "learning_rate": 2.0286368843069875e-05,
      "loss": 0.0963,
      "step": 1140
    },
    {
      "epoch": 1.1855670103092784,
      "grad_norm": 0.2875441908836365,
      "learning_rate": 2.0171821305841926e-05,
      "loss": 0.0554,
      "step": 1150
    },
    {
      "epoch": 1.1958762886597938,
      "grad_norm": 0.05490108206868172,
      "learning_rate": 2.0057273768613974e-05,
      "loss": 0.0831,
      "step": 1160
    },
    {
      "epoch": 1.2061855670103092,
      "grad_norm": 3.938174247741699,
      "learning_rate": 1.9942726231386026e-05,
      "loss": 0.1163,
      "step": 1170
    },
    {
      "epoch": 1.2164948453608249,
      "grad_norm": 0.10626430064439774,
      "learning_rate": 1.9828178694158077e-05,
      "loss": 0.0293,
      "step": 1180
    },
    {
      "epoch": 1.2268041237113403,
      "grad_norm": 0.3312363922595978,
      "learning_rate": 1.9713631156930128e-05,
      "loss": 0.0557,
      "step": 1190
    },
    {
      "epoch": 1.2371134020618557,
      "grad_norm": 0.2557007372379303,
      "learning_rate": 1.9599083619702176e-05,
      "loss": 0.0435,
      "step": 1200
    },
    {
      "epoch": 1.2474226804123711,
      "grad_norm": 0.3951517343521118,
      "learning_rate": 1.9484536082474227e-05,
      "loss": 0.1137,
      "step": 1210
    },
    {
      "epoch": 1.2577319587628866,
      "grad_norm": 0.39596691727638245,
      "learning_rate": 1.9369988545246275e-05,
      "loss": 0.0332,
      "step": 1220
    },
    {
      "epoch": 1.268041237113402,
      "grad_norm": 2.641446828842163,
      "learning_rate": 1.925544100801833e-05,
      "loss": 0.0515,
      "step": 1230
    },
    {
      "epoch": 1.2783505154639174,
      "grad_norm": 0.3006839454174042,
      "learning_rate": 1.9140893470790378e-05,
      "loss": 0.0117,
      "step": 1240
    },
    {
      "epoch": 1.2886597938144329,
      "grad_norm": 0.025934886187314987,
      "learning_rate": 1.902634593356243e-05,
      "loss": 0.0318,
      "step": 1250
    },
    {
      "epoch": 1.2989690721649485,
      "grad_norm": 2.181419849395752,
      "learning_rate": 1.891179839633448e-05,
      "loss": 0.055,
      "step": 1260
    },
    {
      "epoch": 1.309278350515464,
      "grad_norm": 0.21857011318206787,
      "learning_rate": 1.8797250859106528e-05,
      "loss": 0.1202,
      "step": 1270
    },
    {
      "epoch": 1.3195876288659794,
      "grad_norm": 4.466646194458008,
      "learning_rate": 1.8682703321878583e-05,
      "loss": 0.0975,
      "step": 1280
    },
    {
      "epoch": 1.3298969072164948,
      "grad_norm": 0.15101240575313568,
      "learning_rate": 1.856815578465063e-05,
      "loss": 0.0386,
      "step": 1290
    },
    {
      "epoch": 1.3402061855670104,
      "grad_norm": 5.8556952476501465,
      "learning_rate": 1.8453608247422682e-05,
      "loss": 0.046,
      "step": 1300
    },
    {
      "epoch": 1.3505154639175259,
      "grad_norm": 0.2349279373884201,
      "learning_rate": 1.833906071019473e-05,
      "loss": 0.0211,
      "step": 1310
    },
    {
      "epoch": 1.3608247422680413,
      "grad_norm": 0.049428269267082214,
      "learning_rate": 1.822451317296678e-05,
      "loss": 0.0689,
      "step": 1320
    },
    {
      "epoch": 1.3711340206185567,
      "grad_norm": 3.5232977867126465,
      "learning_rate": 1.8109965635738832e-05,
      "loss": 0.1529,
      "step": 1330
    },
    {
      "epoch": 1.3814432989690721,
      "grad_norm": 0.0936928242444992,
      "learning_rate": 1.7995418098510884e-05,
      "loss": 0.0267,
      "step": 1340
    },
    {
      "epoch": 1.3917525773195876,
      "grad_norm": 11.349885940551758,
      "learning_rate": 1.788087056128293e-05,
      "loss": 0.1318,
      "step": 1350
    },
    {
      "epoch": 1.402061855670103,
      "grad_norm": 2.499816417694092,
      "learning_rate": 1.7766323024054983e-05,
      "loss": 0.0432,
      "step": 1360
    },
    {
      "epoch": 1.4123711340206184,
      "grad_norm": 2.952983856201172,
      "learning_rate": 1.765177548682703e-05,
      "loss": 0.1456,
      "step": 1370
    },
    {
      "epoch": 1.422680412371134,
      "grad_norm": 3.2507667541503906,
      "learning_rate": 1.7537227949599085e-05,
      "loss": 0.1444,
      "step": 1380
    },
    {
      "epoch": 1.4329896907216495,
      "grad_norm": 1.925906777381897,
      "learning_rate": 1.7422680412371137e-05,
      "loss": 0.0696,
      "step": 1390
    },
    {
      "epoch": 1.443298969072165,
      "grad_norm": 9.283888816833496,
      "learning_rate": 1.7308132875143184e-05,
      "loss": 0.1173,
      "step": 1400
    },
    {
      "epoch": 1.4536082474226804,
      "grad_norm": 0.6610294580459595,
      "learning_rate": 1.7193585337915236e-05,
      "loss": 0.0365,
      "step": 1410
    },
    {
      "epoch": 1.463917525773196,
      "grad_norm": 9.736104965209961,
      "learning_rate": 1.7079037800687284e-05,
      "loss": 0.0798,
      "step": 1420
    },
    {
      "epoch": 1.4742268041237114,
      "grad_norm": 11.596229553222656,
      "learning_rate": 1.6964490263459338e-05,
      "loss": 0.0558,
      "step": 1430
    },
    {
      "epoch": 1.4845360824742269,
      "grad_norm": 0.48457595705986023,
      "learning_rate": 1.6849942726231386e-05,
      "loss": 0.0899,
      "step": 1440
    },
    {
      "epoch": 1.4948453608247423,
      "grad_norm": 0.15068580210208893,
      "learning_rate": 1.6735395189003437e-05,
      "loss": 0.152,
      "step": 1450
    },
    {
      "epoch": 1.5051546391752577,
      "grad_norm": 3.44191837310791,
      "learning_rate": 1.6620847651775485e-05,
      "loss": 0.0932,
      "step": 1460
    },
    {
      "epoch": 1.5154639175257731,
      "grad_norm": 0.11435795575380325,
      "learning_rate": 1.6506300114547537e-05,
      "loss": 0.0513,
      "step": 1470
    },
    {
      "epoch": 1.5257731958762886,
      "grad_norm": 0.17770279943943024,
      "learning_rate": 1.6391752577319588e-05,
      "loss": 0.0104,
      "step": 1480
    },
    {
      "epoch": 1.536082474226804,
      "grad_norm": 0.10471107065677643,
      "learning_rate": 1.627720504009164e-05,
      "loss": 0.0292,
      "step": 1490
    },
    {
      "epoch": 1.5463917525773194,
      "grad_norm": 0.03535692021250725,
      "learning_rate": 1.616265750286369e-05,
      "loss": 0.0123,
      "step": 1500
    },
    {
      "epoch": 1.556701030927835,
      "grad_norm": 0.4459609389305115,
      "learning_rate": 1.6048109965635738e-05,
      "loss": 0.0411,
      "step": 1510
    },
    {
      "epoch": 1.5670103092783505,
      "grad_norm": 0.047359250485897064,
      "learning_rate": 1.593356242840779e-05,
      "loss": 0.0453,
      "step": 1520
    },
    {
      "epoch": 1.577319587628866,
      "grad_norm": 0.09367845952510834,
      "learning_rate": 1.581901489117984e-05,
      "loss": 0.0508,
      "step": 1530
    },
    {
      "epoch": 1.5876288659793816,
      "grad_norm": 6.115415096282959,
      "learning_rate": 1.5704467353951892e-05,
      "loss": 0.0891,
      "step": 1540
    },
    {
      "epoch": 1.597938144329897,
      "grad_norm": 0.09974430501461029,
      "learning_rate": 1.558991981672394e-05,
      "loss": 0.0322,
      "step": 1550
    },
    {
      "epoch": 1.6082474226804124,
      "grad_norm": 0.027998797595500946,
      "learning_rate": 1.547537227949599e-05,
      "loss": 0.0435,
      "step": 1560
    },
    {
      "epoch": 1.6185567010309279,
      "grad_norm": 0.09235437214374542,
      "learning_rate": 1.536082474226804e-05,
      "loss": 0.0276,
      "step": 1570
    },
    {
      "epoch": 1.6288659793814433,
      "grad_norm": 3.0135509967803955,
      "learning_rate": 1.5246277205040092e-05,
      "loss": 0.0556,
      "step": 1580
    },
    {
      "epoch": 1.6391752577319587,
      "grad_norm": 0.49747762084007263,
      "learning_rate": 1.5131729667812142e-05,
      "loss": 0.0594,
      "step": 1590
    },
    {
      "epoch": 1.6494845360824741,
      "grad_norm": 5.247930526733398,
      "learning_rate": 1.5017182130584193e-05,
      "loss": 0.0626,
      "step": 1600
    },
    {
      "epoch": 1.6597938144329896,
      "grad_norm": 0.1945468783378601,
      "learning_rate": 1.4902634593356242e-05,
      "loss": 0.0761,
      "step": 1610
    },
    {
      "epoch": 1.670103092783505,
      "grad_norm": 0.06561008840799332,
      "learning_rate": 1.4788087056128294e-05,
      "loss": 0.0413,
      "step": 1620
    },
    {
      "epoch": 1.6804123711340206,
      "grad_norm": 0.24969761073589325,
      "learning_rate": 1.4673539518900343e-05,
      "loss": 0.1482,
      "step": 1630
    },
    {
      "epoch": 1.690721649484536,
      "grad_norm": 0.21886323392391205,
      "learning_rate": 1.4558991981672395e-05,
      "loss": 0.0611,
      "step": 1640
    },
    {
      "epoch": 1.7010309278350515,
      "grad_norm": 0.10902930796146393,
      "learning_rate": 1.4444444444444444e-05,
      "loss": 0.012,
      "step": 1650
    },
    {
      "epoch": 1.7113402061855671,
      "grad_norm": 0.10889165848493576,
      "learning_rate": 1.4329896907216495e-05,
      "loss": 0.0244,
      "step": 1660
    },
    {
      "epoch": 1.7216494845360826,
      "grad_norm": 3.738332986831665,
      "learning_rate": 1.4215349369988547e-05,
      "loss": 0.0659,
      "step": 1670
    },
    {
      "epoch": 1.731958762886598,
      "grad_norm": 9.69139289855957,
      "learning_rate": 1.4100801832760596e-05,
      "loss": 0.0809,
      "step": 1680
    },
    {
      "epoch": 1.7422680412371134,
      "grad_norm": 0.5566422343254089,
      "learning_rate": 1.3986254295532648e-05,
      "loss": 0.0447,
      "step": 1690
    },
    {
      "epoch": 1.7525773195876289,
      "grad_norm": 0.41007381677627563,
      "learning_rate": 1.3871706758304697e-05,
      "loss": 0.0845,
      "step": 1700
    },
    {
      "epoch": 1.7628865979381443,
      "grad_norm": 0.0727664902806282,
      "learning_rate": 1.3757159221076747e-05,
      "loss": 0.1089,
      "step": 1710
    },
    {
      "epoch": 1.7731958762886597,
      "grad_norm": 0.116238072514534,
      "learning_rate": 1.3642611683848798e-05,
      "loss": 0.0972,
      "step": 1720
    },
    {
      "epoch": 1.7835051546391751,
      "grad_norm": 4.934554576873779,
      "learning_rate": 1.3528064146620847e-05,
      "loss": 0.0136,
      "step": 1730
    },
    {
      "epoch": 1.7938144329896906,
      "grad_norm": 0.3907771110534668,
      "learning_rate": 1.3413516609392899e-05,
      "loss": 0.0062,
      "step": 1740
    },
    {
      "epoch": 1.8041237113402062,
      "grad_norm": 0.03194218873977661,
      "learning_rate": 1.3298969072164948e-05,
      "loss": 0.025,
      "step": 1750
    },
    {
      "epoch": 1.8144329896907216,
      "grad_norm": 4.297050476074219,
      "learning_rate": 1.3184421534936998e-05,
      "loss": 0.0082,
      "step": 1760
    },
    {
      "epoch": 1.824742268041237,
      "grad_norm": 0.025012066587805748,
      "learning_rate": 1.3069873997709051e-05,
      "loss": 0.0862,
      "step": 1770
    },
    {
      "epoch": 1.8350515463917527,
      "grad_norm": 0.10267119854688644,
      "learning_rate": 1.29553264604811e-05,
      "loss": 0.0302,
      "step": 1780
    },
    {
      "epoch": 1.8453608247422681,
      "grad_norm": 0.03358142822980881,
      "learning_rate": 1.284077892325315e-05,
      "loss": 0.0723,
      "step": 1790
    },
    {
      "epoch": 1.8556701030927836,
      "grad_norm": 0.09067459404468536,
      "learning_rate": 1.2726231386025201e-05,
      "loss": 0.0798,
      "step": 1800
    },
    {
      "epoch": 1.865979381443299,
      "grad_norm": 0.543217122554779,
      "learning_rate": 1.2611683848797251e-05,
      "loss": 0.0763,
      "step": 1810
    },
    {
      "epoch": 1.8762886597938144,
      "grad_norm": 8.3363037109375,
      "learning_rate": 1.2497136311569302e-05,
      "loss": 0.0525,
      "step": 1820
    },
    {
      "epoch": 1.8865979381443299,
      "grad_norm": 0.0956055298447609,
      "learning_rate": 1.2382588774341352e-05,
      "loss": 0.0028,
      "step": 1830
    },
    {
      "epoch": 1.8969072164948453,
      "grad_norm": 0.021153941750526428,
      "learning_rate": 1.2268041237113401e-05,
      "loss": 0.0294,
      "step": 1840
    },
    {
      "epoch": 1.9072164948453607,
      "grad_norm": 0.05811178311705589,
      "learning_rate": 1.2153493699885453e-05,
      "loss": 0.0103,
      "step": 1850
    },
    {
      "epoch": 1.9175257731958761,
      "grad_norm": 0.2170945554971695,
      "learning_rate": 1.2038946162657502e-05,
      "loss": 0.1042,
      "step": 1860
    },
    {
      "epoch": 1.9278350515463918,
      "grad_norm": 0.21763212978839874,
      "learning_rate": 1.1924398625429553e-05,
      "loss": 0.0705,
      "step": 1870
    },
    {
      "epoch": 1.9381443298969072,
      "grad_norm": 0.04690312221646309,
      "learning_rate": 1.1809851088201605e-05,
      "loss": 0.0458,
      "step": 1880
    },
    {
      "epoch": 1.9484536082474226,
      "grad_norm": 0.024800246581435204,
      "learning_rate": 1.1695303550973654e-05,
      "loss": 0.0436,
      "step": 1890
    },
    {
      "epoch": 1.9587628865979383,
      "grad_norm": 0.05869826674461365,
      "learning_rate": 1.1580756013745706e-05,
      "loss": 0.086,
      "step": 1900
    },
    {
      "epoch": 1.9690721649484537,
      "grad_norm": 0.037563398480415344,
      "learning_rate": 1.1466208476517755e-05,
      "loss": 0.1142,
      "step": 1910
    },
    {
      "epoch": 1.9793814432989691,
      "grad_norm": 0.07701834291219711,
      "learning_rate": 1.1351660939289806e-05,
      "loss": 0.0619,
      "step": 1920
    },
    {
      "epoch": 1.9896907216494846,
      "grad_norm": 1.0819627046585083,
      "learning_rate": 1.1237113402061856e-05,
      "loss": 0.0949,
      "step": 1930
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.012773696333169937,
      "learning_rate": 1.1122565864833906e-05,
      "loss": 0.04,
      "step": 1940
    },
    {
      "epoch": 2.0,
      "eval_f1": 0.7131147540983607,
      "eval_loss": 0.08797562122344971,
      "eval_precision": 0.925531914893617,
      "eval_recall": 0.58,
      "eval_runtime": 2.1149,
      "eval_samples_per_second": 1571.207,
      "eval_steps_per_second": 98.348,
      "step": 1940
    }
  ],
  "logging_steps": 10,
  "max_steps": 2910,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1027019741779968.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
