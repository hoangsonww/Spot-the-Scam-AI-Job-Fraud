{
  "best_global_step": 1390,
  "best_metric": 0.05680820718407631,
  "best_model_checkpoint": "/home/snguyen/spot-the-scam-project/artifacts/transformer/checkpoint-1390",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 2085,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.014388489208633094,
      "grad_norm": 4.767597675323486,
      "learning_rate": 1.291866028708134e-06,
      "loss": 0.6776,
      "step": 10
    },
    {
      "epoch": 0.02877697841726619,
      "grad_norm": 3.8736822605133057,
      "learning_rate": 2.7272727272727272e-06,
      "loss": 0.6335,
      "step": 20
    },
    {
      "epoch": 0.04316546762589928,
      "grad_norm": 3.2966713905334473,
      "learning_rate": 4.162679425837321e-06,
      "loss": 0.553,
      "step": 30
    },
    {
      "epoch": 0.05755395683453238,
      "grad_norm": 3.391916275024414,
      "learning_rate": 5.5980861244019145e-06,
      "loss": 0.4414,
      "step": 40
    },
    {
      "epoch": 0.07194244604316546,
      "grad_norm": 2.077266216278076,
      "learning_rate": 7.033492822966507e-06,
      "loss": 0.2759,
      "step": 50
    },
    {
      "epoch": 0.08633093525179857,
      "grad_norm": 1.0729150772094727,
      "learning_rate": 8.4688995215311e-06,
      "loss": 0.1856,
      "step": 60
    },
    {
      "epoch": 0.10071942446043165,
      "grad_norm": 0.864267110824585,
      "learning_rate": 9.904306220095695e-06,
      "loss": 0.2568,
      "step": 70
    },
    {
      "epoch": 0.11510791366906475,
      "grad_norm": 0.7133802175521851,
      "learning_rate": 1.1339712918660286e-05,
      "loss": 0.1477,
      "step": 80
    },
    {
      "epoch": 0.12949640287769784,
      "grad_norm": 1.045699119567871,
      "learning_rate": 1.2775119617224882e-05,
      "loss": 0.1401,
      "step": 90
    },
    {
      "epoch": 0.14388489208633093,
      "grad_norm": 0.9476826190948486,
      "learning_rate": 1.4210526315789473e-05,
      "loss": 0.2141,
      "step": 100
    },
    {
      "epoch": 0.15827338129496402,
      "grad_norm": 1.3131334781646729,
      "learning_rate": 1.5645933014354067e-05,
      "loss": 0.1538,
      "step": 110
    },
    {
      "epoch": 0.17266187050359713,
      "grad_norm": 1.6851547956466675,
      "learning_rate": 1.708133971291866e-05,
      "loss": 0.2028,
      "step": 120
    },
    {
      "epoch": 0.18705035971223022,
      "grad_norm": 0.6355000734329224,
      "learning_rate": 1.8516746411483253e-05,
      "loss": 0.1459,
      "step": 130
    },
    {
      "epoch": 0.2014388489208633,
      "grad_norm": 0.42646053433418274,
      "learning_rate": 1.995215311004785e-05,
      "loss": 0.1007,
      "step": 140
    },
    {
      "epoch": 0.2158273381294964,
      "grad_norm": 4.787518501281738,
      "learning_rate": 2.138755980861244e-05,
      "loss": 0.1301,
      "step": 150
    },
    {
      "epoch": 0.2302158273381295,
      "grad_norm": 1.897356629371643,
      "learning_rate": 2.2822966507177032e-05,
      "loss": 0.2146,
      "step": 160
    },
    {
      "epoch": 0.2446043165467626,
      "grad_norm": 1.413034439086914,
      "learning_rate": 2.4258373205741627e-05,
      "loss": 0.153,
      "step": 170
    },
    {
      "epoch": 0.2589928057553957,
      "grad_norm": 0.46302667260169983,
      "learning_rate": 2.5693779904306222e-05,
      "loss": 0.1495,
      "step": 180
    },
    {
      "epoch": 0.2733812949640288,
      "grad_norm": 1.8984591960906982,
      "learning_rate": 2.7129186602870814e-05,
      "loss": 0.1117,
      "step": 190
    },
    {
      "epoch": 0.28776978417266186,
      "grad_norm": 3.858778238296509,
      "learning_rate": 2.8564593301435406e-05,
      "loss": 0.2662,
      "step": 200
    },
    {
      "epoch": 0.302158273381295,
      "grad_norm": 3.060361385345459,
      "learning_rate": 3e-05,
      "loss": 0.1575,
      "step": 210
    },
    {
      "epoch": 0.31654676258992803,
      "grad_norm": 1.7025481462478638,
      "learning_rate": 2.9840085287846483e-05,
      "loss": 0.1871,
      "step": 220
    },
    {
      "epoch": 0.33093525179856115,
      "grad_norm": 2.6734561920166016,
      "learning_rate": 2.968017057569296e-05,
      "loss": 0.0752,
      "step": 230
    },
    {
      "epoch": 0.34532374100719426,
      "grad_norm": 9.153828620910645,
      "learning_rate": 2.9520255863539447e-05,
      "loss": 0.2789,
      "step": 240
    },
    {
      "epoch": 0.3597122302158273,
      "grad_norm": 1.1766316890716553,
      "learning_rate": 2.936034115138593e-05,
      "loss": 0.1089,
      "step": 250
    },
    {
      "epoch": 0.37410071942446044,
      "grad_norm": 1.242830514907837,
      "learning_rate": 2.920042643923241e-05,
      "loss": 0.1383,
      "step": 260
    },
    {
      "epoch": 0.38848920863309355,
      "grad_norm": 1.9008326530456543,
      "learning_rate": 2.904051172707889e-05,
      "loss": 0.1151,
      "step": 270
    },
    {
      "epoch": 0.4028776978417266,
      "grad_norm": 3.199657917022705,
      "learning_rate": 2.8880597014925376e-05,
      "loss": 0.1176,
      "step": 280
    },
    {
      "epoch": 0.4172661870503597,
      "grad_norm": 1.7302137613296509,
      "learning_rate": 2.8720682302771858e-05,
      "loss": 0.1187,
      "step": 290
    },
    {
      "epoch": 0.4316546762589928,
      "grad_norm": 0.37601661682128906,
      "learning_rate": 2.8560767590618336e-05,
      "loss": 0.066,
      "step": 300
    },
    {
      "epoch": 0.4460431654676259,
      "grad_norm": 0.7147097587585449,
      "learning_rate": 2.840085287846482e-05,
      "loss": 0.1907,
      "step": 310
    },
    {
      "epoch": 0.460431654676259,
      "grad_norm": 0.38358354568481445,
      "learning_rate": 2.82409381663113e-05,
      "loss": 0.0858,
      "step": 320
    },
    {
      "epoch": 0.4748201438848921,
      "grad_norm": 1.9803627729415894,
      "learning_rate": 2.8081023454157786e-05,
      "loss": 0.153,
      "step": 330
    },
    {
      "epoch": 0.4892086330935252,
      "grad_norm": 0.18710483610630035,
      "learning_rate": 2.7921108742004265e-05,
      "loss": 0.0776,
      "step": 340
    },
    {
      "epoch": 0.5035971223021583,
      "grad_norm": 5.984102249145508,
      "learning_rate": 2.7761194029850747e-05,
      "loss": 0.114,
      "step": 350
    },
    {
      "epoch": 0.5179856115107914,
      "grad_norm": 1.1332311630249023,
      "learning_rate": 2.760127931769723e-05,
      "loss": 0.1552,
      "step": 360
    },
    {
      "epoch": 0.5323741007194245,
      "grad_norm": 0.7494312524795532,
      "learning_rate": 2.744136460554371e-05,
      "loss": 0.0803,
      "step": 370
    },
    {
      "epoch": 0.5467625899280576,
      "grad_norm": 2.975085496902466,
      "learning_rate": 2.7281449893390193e-05,
      "loss": 0.0695,
      "step": 380
    },
    {
      "epoch": 0.5611510791366906,
      "grad_norm": 3.1028759479522705,
      "learning_rate": 2.7121535181236675e-05,
      "loss": 0.187,
      "step": 390
    },
    {
      "epoch": 0.5755395683453237,
      "grad_norm": 6.678132057189941,
      "learning_rate": 2.6961620469083154e-05,
      "loss": 0.1086,
      "step": 400
    },
    {
      "epoch": 0.5899280575539568,
      "grad_norm": 4.0267815589904785,
      "learning_rate": 2.6801705756929636e-05,
      "loss": 0.0876,
      "step": 410
    },
    {
      "epoch": 0.60431654676259,
      "grad_norm": 3.800591230392456,
      "learning_rate": 2.664179104477612e-05,
      "loss": 0.1667,
      "step": 420
    },
    {
      "epoch": 0.6187050359712231,
      "grad_norm": 2.8194808959960938,
      "learning_rate": 2.6481876332622604e-05,
      "loss": 0.0675,
      "step": 430
    },
    {
      "epoch": 0.6330935251798561,
      "grad_norm": 0.5190096497535706,
      "learning_rate": 2.6321961620469082e-05,
      "loss": 0.0209,
      "step": 440
    },
    {
      "epoch": 0.6474820143884892,
      "grad_norm": 8.045195579528809,
      "learning_rate": 2.6162046908315565e-05,
      "loss": 0.0511,
      "step": 450
    },
    {
      "epoch": 0.6618705035971223,
      "grad_norm": 3.01597261428833,
      "learning_rate": 2.600213219616205e-05,
      "loss": 0.1244,
      "step": 460
    },
    {
      "epoch": 0.6762589928057554,
      "grad_norm": 0.37546855211257935,
      "learning_rate": 2.584221748400853e-05,
      "loss": 0.0887,
      "step": 470
    },
    {
      "epoch": 0.6906474820143885,
      "grad_norm": 0.06036531552672386,
      "learning_rate": 2.568230277185501e-05,
      "loss": 0.0632,
      "step": 480
    },
    {
      "epoch": 0.7050359712230215,
      "grad_norm": 2.3147408962249756,
      "learning_rate": 2.5522388059701493e-05,
      "loss": 0.0151,
      "step": 490
    },
    {
      "epoch": 0.7194244604316546,
      "grad_norm": 12.95970344543457,
      "learning_rate": 2.5362473347547975e-05,
      "loss": 0.0899,
      "step": 500
    },
    {
      "epoch": 0.7338129496402878,
      "grad_norm": 1.7828023433685303,
      "learning_rate": 2.5202558635394457e-05,
      "loss": 0.0746,
      "step": 510
    },
    {
      "epoch": 0.7482014388489209,
      "grad_norm": 2.75822114944458,
      "learning_rate": 2.504264392324094e-05,
      "loss": 0.0413,
      "step": 520
    },
    {
      "epoch": 0.762589928057554,
      "grad_norm": 0.08636615425348282,
      "learning_rate": 2.488272921108742e-05,
      "loss": 0.1107,
      "step": 530
    },
    {
      "epoch": 0.7769784172661871,
      "grad_norm": 5.455087661743164,
      "learning_rate": 2.47228144989339e-05,
      "loss": 0.0832,
      "step": 540
    },
    {
      "epoch": 0.7913669064748201,
      "grad_norm": 0.12403181195259094,
      "learning_rate": 2.4562899786780386e-05,
      "loss": 0.0885,
      "step": 550
    },
    {
      "epoch": 0.8057553956834532,
      "grad_norm": 1.582260251045227,
      "learning_rate": 2.4402985074626868e-05,
      "loss": 0.0458,
      "step": 560
    },
    {
      "epoch": 0.8201438848920863,
      "grad_norm": 3.6227715015411377,
      "learning_rate": 2.424307036247335e-05,
      "loss": 0.1477,
      "step": 570
    },
    {
      "epoch": 0.8345323741007195,
      "grad_norm": 3.8801467418670654,
      "learning_rate": 2.408315565031983e-05,
      "loss": 0.0577,
      "step": 580
    },
    {
      "epoch": 0.8489208633093526,
      "grad_norm": 2.7570881843566895,
      "learning_rate": 2.392324093816631e-05,
      "loss": 0.0579,
      "step": 590
    },
    {
      "epoch": 0.8633093525179856,
      "grad_norm": 1.8289506435394287,
      "learning_rate": 2.3763326226012796e-05,
      "loss": 0.1752,
      "step": 600
    },
    {
      "epoch": 0.8776978417266187,
      "grad_norm": 0.214692622423172,
      "learning_rate": 2.3603411513859275e-05,
      "loss": 0.0975,
      "step": 610
    },
    {
      "epoch": 0.8920863309352518,
      "grad_norm": 0.2552040219306946,
      "learning_rate": 2.3443496801705757e-05,
      "loss": 0.0956,
      "step": 620
    },
    {
      "epoch": 0.9064748201438849,
      "grad_norm": 0.5100186467170715,
      "learning_rate": 2.328358208955224e-05,
      "loss": 0.0664,
      "step": 630
    },
    {
      "epoch": 0.920863309352518,
      "grad_norm": 1.5062813758850098,
      "learning_rate": 2.312366737739872e-05,
      "loss": 0.0716,
      "step": 640
    },
    {
      "epoch": 0.935251798561151,
      "grad_norm": 6.813384056091309,
      "learning_rate": 2.2963752665245203e-05,
      "loss": 0.1357,
      "step": 650
    },
    {
      "epoch": 0.9496402877697842,
      "grad_norm": 0.5452286601066589,
      "learning_rate": 2.2803837953091685e-05,
      "loss": 0.0457,
      "step": 660
    },
    {
      "epoch": 0.9640287769784173,
      "grad_norm": 0.07252806425094604,
      "learning_rate": 2.2643923240938168e-05,
      "loss": 0.0653,
      "step": 670
    },
    {
      "epoch": 0.9784172661870504,
      "grad_norm": 3.0628950595855713,
      "learning_rate": 2.2484008528784646e-05,
      "loss": 0.0657,
      "step": 680
    },
    {
      "epoch": 0.9928057553956835,
      "grad_norm": 6.020812034606934,
      "learning_rate": 2.2324093816631132e-05,
      "loss": 0.0598,
      "step": 690
    },
    {
      "epoch": 1.0,
      "eval_f1": 0.7513227513227513,
      "eval_loss": 0.06817688792943954,
      "eval_precision": 0.8658536585365854,
      "eval_recall": 0.6635514018691588,
      "eval_runtime": 1.4885,
      "eval_samples_per_second": 1599.615,
      "eval_steps_per_second": 100.102,
      "step": 695
    },
    {
      "epoch": 1.0071942446043165,
      "grad_norm": 0.12513911724090576,
      "learning_rate": 2.2164179104477614e-05,
      "loss": 0.0428,
      "step": 700
    },
    {
      "epoch": 1.0215827338129497,
      "grad_norm": 3.229304552078247,
      "learning_rate": 2.2004264392324096e-05,
      "loss": 0.0628,
      "step": 710
    },
    {
      "epoch": 1.0359712230215827,
      "grad_norm": 0.11909506469964981,
      "learning_rate": 2.1844349680170575e-05,
      "loss": 0.0148,
      "step": 720
    },
    {
      "epoch": 1.0503597122302157,
      "grad_norm": 0.05998183414340019,
      "learning_rate": 2.1684434968017057e-05,
      "loss": 0.011,
      "step": 730
    },
    {
      "epoch": 1.064748201438849,
      "grad_norm": 6.414567947387695,
      "learning_rate": 2.1524520255863542e-05,
      "loss": 0.1359,
      "step": 740
    },
    {
      "epoch": 1.079136690647482,
      "grad_norm": 0.09915841370820999,
      "learning_rate": 2.136460554371002e-05,
      "loss": 0.0331,
      "step": 750
    },
    {
      "epoch": 1.0935251798561152,
      "grad_norm": 11.538399696350098,
      "learning_rate": 2.1204690831556503e-05,
      "loss": 0.0407,
      "step": 760
    },
    {
      "epoch": 1.1079136690647482,
      "grad_norm": 7.187890529632568,
      "learning_rate": 2.1044776119402985e-05,
      "loss": 0.0663,
      "step": 770
    },
    {
      "epoch": 1.1223021582733812,
      "grad_norm": 0.057199668139219284,
      "learning_rate": 2.0884861407249467e-05,
      "loss": 0.0076,
      "step": 780
    },
    {
      "epoch": 1.1366906474820144,
      "grad_norm": 0.04259386286139488,
      "learning_rate": 2.072494669509595e-05,
      "loss": 0.0083,
      "step": 790
    },
    {
      "epoch": 1.1510791366906474,
      "grad_norm": 2.7350735664367676,
      "learning_rate": 2.056503198294243e-05,
      "loss": 0.0476,
      "step": 800
    },
    {
      "epoch": 1.1654676258992807,
      "grad_norm": 1.2214857339859009,
      "learning_rate": 2.0405117270788914e-05,
      "loss": 0.0048,
      "step": 810
    },
    {
      "epoch": 1.1798561151079137,
      "grad_norm": 0.03376379609107971,
      "learning_rate": 2.0245202558635392e-05,
      "loss": 0.09,
      "step": 820
    },
    {
      "epoch": 1.1942446043165469,
      "grad_norm": 0.11247099936008453,
      "learning_rate": 2.0085287846481878e-05,
      "loss": 0.0842,
      "step": 830
    },
    {
      "epoch": 1.20863309352518,
      "grad_norm": 0.24572747945785522,
      "learning_rate": 1.992537313432836e-05,
      "loss": 0.0966,
      "step": 840
    },
    {
      "epoch": 1.223021582733813,
      "grad_norm": 10.084996223449707,
      "learning_rate": 1.976545842217484e-05,
      "loss": 0.0863,
      "step": 850
    },
    {
      "epoch": 1.2374100719424461,
      "grad_norm": 0.12680552899837494,
      "learning_rate": 1.960554371002132e-05,
      "loss": 0.0596,
      "step": 860
    },
    {
      "epoch": 1.2517985611510791,
      "grad_norm": 0.1586289256811142,
      "learning_rate": 1.9445628997867806e-05,
      "loss": 0.0783,
      "step": 870
    },
    {
      "epoch": 1.2661870503597124,
      "grad_norm": 2.7823565006256104,
      "learning_rate": 1.928571428571429e-05,
      "loss": 0.036,
      "step": 880
    },
    {
      "epoch": 1.2805755395683454,
      "grad_norm": 0.07924534380435944,
      "learning_rate": 1.9125799573560767e-05,
      "loss": 0.0528,
      "step": 890
    },
    {
      "epoch": 1.2949640287769784,
      "grad_norm": 2.4185597896575928,
      "learning_rate": 1.896588486140725e-05,
      "loss": 0.1033,
      "step": 900
    },
    {
      "epoch": 1.3093525179856116,
      "grad_norm": 5.919374942779541,
      "learning_rate": 1.880597014925373e-05,
      "loss": 0.0439,
      "step": 910
    },
    {
      "epoch": 1.3237410071942446,
      "grad_norm": 0.0506017692387104,
      "learning_rate": 1.8646055437100213e-05,
      "loss": 0.0075,
      "step": 920
    },
    {
      "epoch": 1.3381294964028778,
      "grad_norm": 0.601270854473114,
      "learning_rate": 1.8486140724946696e-05,
      "loss": 0.0239,
      "step": 930
    },
    {
      "epoch": 1.3525179856115108,
      "grad_norm": 3.505735158920288,
      "learning_rate": 1.8326226012793178e-05,
      "loss": 0.1269,
      "step": 940
    },
    {
      "epoch": 1.3669064748201438,
      "grad_norm": 0.2750212848186493,
      "learning_rate": 1.816631130063966e-05,
      "loss": 0.0215,
      "step": 950
    },
    {
      "epoch": 1.381294964028777,
      "grad_norm": 0.3143557906150818,
      "learning_rate": 1.8006396588486142e-05,
      "loss": 0.0279,
      "step": 960
    },
    {
      "epoch": 1.39568345323741,
      "grad_norm": 6.863857269287109,
      "learning_rate": 1.7846481876332624e-05,
      "loss": 0.0494,
      "step": 970
    },
    {
      "epoch": 1.4100719424460433,
      "grad_norm": 0.04032382369041443,
      "learning_rate": 1.7686567164179106e-05,
      "loss": 0.0561,
      "step": 980
    },
    {
      "epoch": 1.4244604316546763,
      "grad_norm": 0.03625652939081192,
      "learning_rate": 1.7526652452025585e-05,
      "loss": 0.0376,
      "step": 990
    },
    {
      "epoch": 1.4388489208633093,
      "grad_norm": 0.057600293308496475,
      "learning_rate": 1.7366737739872067e-05,
      "loss": 0.0452,
      "step": 1000
    },
    {
      "epoch": 1.4532374100719425,
      "grad_norm": 0.09755736589431763,
      "learning_rate": 1.7206823027718552e-05,
      "loss": 0.0268,
      "step": 1010
    },
    {
      "epoch": 1.4676258992805755,
      "grad_norm": 1.0185669660568237,
      "learning_rate": 1.7046908315565034e-05,
      "loss": 0.0779,
      "step": 1020
    },
    {
      "epoch": 1.4820143884892087,
      "grad_norm": 0.05485837534070015,
      "learning_rate": 1.6886993603411513e-05,
      "loss": 0.0312,
      "step": 1030
    },
    {
      "epoch": 1.4964028776978417,
      "grad_norm": 0.03349527716636658,
      "learning_rate": 1.6727078891257995e-05,
      "loss": 0.0357,
      "step": 1040
    },
    {
      "epoch": 1.5107913669064748,
      "grad_norm": 7.181187152862549,
      "learning_rate": 1.656716417910448e-05,
      "loss": 0.0821,
      "step": 1050
    },
    {
      "epoch": 1.5251798561151078,
      "grad_norm": 0.07203520834445953,
      "learning_rate": 1.640724946695096e-05,
      "loss": 0.0386,
      "step": 1060
    },
    {
      "epoch": 1.539568345323741,
      "grad_norm": 0.04289071634411812,
      "learning_rate": 1.624733475479744e-05,
      "loss": 0.0058,
      "step": 1070
    },
    {
      "epoch": 1.5539568345323742,
      "grad_norm": 0.027332235127687454,
      "learning_rate": 1.6087420042643924e-05,
      "loss": 0.0102,
      "step": 1080
    },
    {
      "epoch": 1.5683453237410072,
      "grad_norm": 0.06977972388267517,
      "learning_rate": 1.5927505330490402e-05,
      "loss": 0.0039,
      "step": 1090
    },
    {
      "epoch": 1.5827338129496402,
      "grad_norm": 0.020118823274970055,
      "learning_rate": 1.5767590618336888e-05,
      "loss": 0.0348,
      "step": 1100
    },
    {
      "epoch": 1.5971223021582732,
      "grad_norm": 0.04263699799776077,
      "learning_rate": 1.560767590618337e-05,
      "loss": 0.0463,
      "step": 1110
    },
    {
      "epoch": 1.6115107913669064,
      "grad_norm": 0.056067194789648056,
      "learning_rate": 1.5447761194029852e-05,
      "loss": 0.0055,
      "step": 1120
    },
    {
      "epoch": 1.6258992805755397,
      "grad_norm": 0.01878982223570347,
      "learning_rate": 1.528784648187633e-05,
      "loss": 0.0012,
      "step": 1130
    },
    {
      "epoch": 1.6402877697841727,
      "grad_norm": 0.014609388075768948,
      "learning_rate": 1.5127931769722815e-05,
      "loss": 0.1266,
      "step": 1140
    },
    {
      "epoch": 1.6546762589928057,
      "grad_norm": 2.8563709259033203,
      "learning_rate": 1.4968017057569295e-05,
      "loss": 0.0985,
      "step": 1150
    },
    {
      "epoch": 1.6690647482014387,
      "grad_norm": 0.05400508642196655,
      "learning_rate": 1.4808102345415779e-05,
      "loss": 0.0018,
      "step": 1160
    },
    {
      "epoch": 1.683453237410072,
      "grad_norm": 0.10560747236013412,
      "learning_rate": 1.464818763326226e-05,
      "loss": 0.074,
      "step": 1170
    },
    {
      "epoch": 1.6978417266187051,
      "grad_norm": 0.029205303639173508,
      "learning_rate": 1.4488272921108743e-05,
      "loss": 0.0129,
      "step": 1180
    },
    {
      "epoch": 1.7122302158273381,
      "grad_norm": 0.2840074896812439,
      "learning_rate": 1.4328358208955224e-05,
      "loss": 0.0706,
      "step": 1190
    },
    {
      "epoch": 1.7266187050359711,
      "grad_norm": 0.03490229323506355,
      "learning_rate": 1.4168443496801707e-05,
      "loss": 0.0259,
      "step": 1200
    },
    {
      "epoch": 1.7410071942446042,
      "grad_norm": 0.6338908076286316,
      "learning_rate": 1.4008528784648188e-05,
      "loss": 0.091,
      "step": 1210
    },
    {
      "epoch": 1.7553956834532374,
      "grad_norm": 0.02595469169318676,
      "learning_rate": 1.384861407249467e-05,
      "loss": 0.0186,
      "step": 1220
    },
    {
      "epoch": 1.7697841726618706,
      "grad_norm": 15.0270357131958,
      "learning_rate": 1.3688699360341152e-05,
      "loss": 0.0831,
      "step": 1230
    },
    {
      "epoch": 1.7841726618705036,
      "grad_norm": 0.1196243092417717,
      "learning_rate": 1.3528784648187632e-05,
      "loss": 0.0045,
      "step": 1240
    },
    {
      "epoch": 1.7985611510791366,
      "grad_norm": 5.989015579223633,
      "learning_rate": 1.3368869936034116e-05,
      "loss": 0.0233,
      "step": 1250
    },
    {
      "epoch": 1.8129496402877698,
      "grad_norm": 0.02967667579650879,
      "learning_rate": 1.3208955223880597e-05,
      "loss": 0.0297,
      "step": 1260
    },
    {
      "epoch": 1.8273381294964028,
      "grad_norm": 0.0790388360619545,
      "learning_rate": 1.304904051172708e-05,
      "loss": 0.0036,
      "step": 1270
    },
    {
      "epoch": 1.841726618705036,
      "grad_norm": 5.6145339012146,
      "learning_rate": 1.288912579957356e-05,
      "loss": 0.068,
      "step": 1280
    },
    {
      "epoch": 1.856115107913669,
      "grad_norm": 9.579246520996094,
      "learning_rate": 1.2729211087420043e-05,
      "loss": 0.0961,
      "step": 1290
    },
    {
      "epoch": 1.870503597122302,
      "grad_norm": 0.035864684730768204,
      "learning_rate": 1.2569296375266525e-05,
      "loss": 0.1276,
      "step": 1300
    },
    {
      "epoch": 1.8848920863309353,
      "grad_norm": 0.33435383439064026,
      "learning_rate": 1.2409381663113007e-05,
      "loss": 0.0108,
      "step": 1310
    },
    {
      "epoch": 1.8992805755395683,
      "grad_norm": 0.06884203851222992,
      "learning_rate": 1.224946695095949e-05,
      "loss": 0.01,
      "step": 1320
    },
    {
      "epoch": 1.9136690647482015,
      "grad_norm": 0.027802599593997,
      "learning_rate": 1.208955223880597e-05,
      "loss": 0.0273,
      "step": 1330
    },
    {
      "epoch": 1.9280575539568345,
      "grad_norm": 0.061067014932632446,
      "learning_rate": 1.1929637526652452e-05,
      "loss": 0.0341,
      "step": 1340
    },
    {
      "epoch": 1.9424460431654675,
      "grad_norm": 0.03901116922497749,
      "learning_rate": 1.1769722814498934e-05,
      "loss": 0.028,
      "step": 1350
    },
    {
      "epoch": 1.9568345323741008,
      "grad_norm": 0.2880949079990387,
      "learning_rate": 1.1609808102345416e-05,
      "loss": 0.0232,
      "step": 1360
    },
    {
      "epoch": 1.9712230215827338,
      "grad_norm": 0.021609291434288025,
      "learning_rate": 1.1449893390191898e-05,
      "loss": 0.1106,
      "step": 1370
    },
    {
      "epoch": 1.985611510791367,
      "grad_norm": 0.03198213875293732,
      "learning_rate": 1.128997867803838e-05,
      "loss": 0.0085,
      "step": 1380
    },
    {
      "epoch": 2.0,
      "grad_norm": 26.4646053314209,
      "learning_rate": 1.1130063965884862e-05,
      "loss": 0.1305,
      "step": 1390
    },
    {
      "epoch": 2.0,
      "eval_f1": 0.86,
      "eval_loss": 0.05680820718407631,
      "eval_precision": 0.9247311827956989,
      "eval_recall": 0.8037383177570093,
      "eval_runtime": 1.4579,
      "eval_samples_per_second": 1633.121,
      "eval_steps_per_second": 102.199,
      "step": 1390
    },
    {
      "epoch": 2.014388489208633,
      "grad_norm": 0.05040348693728447,
      "learning_rate": 1.0970149253731344e-05,
      "loss": 0.004,
      "step": 1400
    },
    {
      "epoch": 2.028776978417266,
      "grad_norm": 0.04022379219532013,
      "learning_rate": 1.0810234541577825e-05,
      "loss": 0.0027,
      "step": 1410
    },
    {
      "epoch": 2.0431654676258995,
      "grad_norm": 0.02104143425822258,
      "learning_rate": 1.0650319829424307e-05,
      "loss": 0.0184,
      "step": 1420
    },
    {
      "epoch": 2.0575539568345325,
      "grad_norm": 0.5430322885513306,
      "learning_rate": 1.0490405117270789e-05,
      "loss": 0.0064,
      "step": 1430
    },
    {
      "epoch": 2.0719424460431655,
      "grad_norm": 0.014393707737326622,
      "learning_rate": 1.0330490405117271e-05,
      "loss": 0.0221,
      "step": 1440
    },
    {
      "epoch": 2.0863309352517985,
      "grad_norm": 0.05673160403966904,
      "learning_rate": 1.0170575692963753e-05,
      "loss": 0.0014,
      "step": 1450
    },
    {
      "epoch": 2.1007194244604315,
      "grad_norm": 0.5504863858222961,
      "learning_rate": 1.0010660980810235e-05,
      "loss": 0.041,
      "step": 1460
    },
    {
      "epoch": 2.115107913669065,
      "grad_norm": 0.0401957631111145,
      "learning_rate": 9.850746268656717e-06,
      "loss": 0.0055,
      "step": 1470
    },
    {
      "epoch": 2.129496402877698,
      "grad_norm": 5.381216526031494,
      "learning_rate": 9.690831556503198e-06,
      "loss": 0.0122,
      "step": 1480
    },
    {
      "epoch": 2.143884892086331,
      "grad_norm": 0.07094039022922516,
      "learning_rate": 9.53091684434968e-06,
      "loss": 0.0304,
      "step": 1490
    },
    {
      "epoch": 2.158273381294964,
      "grad_norm": 0.01505714189261198,
      "learning_rate": 9.371002132196162e-06,
      "loss": 0.0082,
      "step": 1500
    },
    {
      "epoch": 2.172661870503597,
      "grad_norm": 0.0994189903140068,
      "learning_rate": 9.211087420042644e-06,
      "loss": 0.0424,
      "step": 1510
    },
    {
      "epoch": 2.1870503597122304,
      "grad_norm": 2.720414876937866,
      "learning_rate": 9.051172707889126e-06,
      "loss": 0.0441,
      "step": 1520
    },
    {
      "epoch": 2.2014388489208634,
      "grad_norm": 0.02572430483996868,
      "learning_rate": 8.891257995735607e-06,
      "loss": 0.0813,
      "step": 1530
    },
    {
      "epoch": 2.2158273381294964,
      "grad_norm": 0.030687876045703888,
      "learning_rate": 8.73134328358209e-06,
      "loss": 0.0191,
      "step": 1540
    },
    {
      "epoch": 2.2302158273381294,
      "grad_norm": 0.022911954671144485,
      "learning_rate": 8.571428571428571e-06,
      "loss": 0.0112,
      "step": 1550
    },
    {
      "epoch": 2.2446043165467624,
      "grad_norm": 2.6038084030151367,
      "learning_rate": 8.411513859275055e-06,
      "loss": 0.0346,
      "step": 1560
    },
    {
      "epoch": 2.258992805755396,
      "grad_norm": 0.07139125466346741,
      "learning_rate": 8.251599147121535e-06,
      "loss": 0.0011,
      "step": 1570
    },
    {
      "epoch": 2.273381294964029,
      "grad_norm": 3.8236453533172607,
      "learning_rate": 8.091684434968017e-06,
      "loss": 0.0419,
      "step": 1580
    },
    {
      "epoch": 2.287769784172662,
      "grad_norm": 0.021921372041106224,
      "learning_rate": 7.9317697228145e-06,
      "loss": 0.0048,
      "step": 1590
    },
    {
      "epoch": 2.302158273381295,
      "grad_norm": 0.02090817503631115,
      "learning_rate": 7.77185501066098e-06,
      "loss": 0.0013,
      "step": 1600
    },
    {
      "epoch": 2.316546762589928,
      "grad_norm": 7.7187604904174805,
      "learning_rate": 7.6119402985074636e-06,
      "loss": 0.0133,
      "step": 1610
    },
    {
      "epoch": 2.3309352517985613,
      "grad_norm": 0.06676303595304489,
      "learning_rate": 7.452025586353944e-06,
      "loss": 0.0135,
      "step": 1620
    },
    {
      "epoch": 2.3453237410071943,
      "grad_norm": 0.9322689175605774,
      "learning_rate": 7.292110874200426e-06,
      "loss": 0.0023,
      "step": 1630
    },
    {
      "epoch": 2.3597122302158273,
      "grad_norm": 0.023292986676096916,
      "learning_rate": 7.132196162046908e-06,
      "loss": 0.0232,
      "step": 1640
    },
    {
      "epoch": 2.3741007194244603,
      "grad_norm": 4.870674133300781,
      "learning_rate": 6.97228144989339e-06,
      "loss": 0.0711,
      "step": 1650
    },
    {
      "epoch": 2.3884892086330938,
      "grad_norm": 0.07433521002531052,
      "learning_rate": 6.812366737739872e-06,
      "loss": 0.0035,
      "step": 1660
    },
    {
      "epoch": 2.402877697841727,
      "grad_norm": 0.032572198659181595,
      "learning_rate": 6.6524520255863545e-06,
      "loss": 0.0015,
      "step": 1670
    },
    {
      "epoch": 2.41726618705036,
      "grad_norm": 4.281795501708984,
      "learning_rate": 6.492537313432836e-06,
      "loss": 0.0848,
      "step": 1680
    },
    {
      "epoch": 2.431654676258993,
      "grad_norm": 7.634047508239746,
      "learning_rate": 6.332622601279318e-06,
      "loss": 0.0472,
      "step": 1690
    },
    {
      "epoch": 2.446043165467626,
      "grad_norm": 0.1118224561214447,
      "learning_rate": 6.1727078891258e-06,
      "loss": 0.0012,
      "step": 1700
    },
    {
      "epoch": 2.460431654676259,
      "grad_norm": 0.19808024168014526,
      "learning_rate": 6.012793176972281e-06,
      "loss": 0.0142,
      "step": 1710
    },
    {
      "epoch": 2.4748201438848922,
      "grad_norm": 0.029172824695706367,
      "learning_rate": 5.852878464818763e-06,
      "loss": 0.0423,
      "step": 1720
    },
    {
      "epoch": 2.4892086330935252,
      "grad_norm": 0.021972861140966415,
      "learning_rate": 5.6929637526652455e-06,
      "loss": 0.001,
      "step": 1730
    },
    {
      "epoch": 2.5035971223021583,
      "grad_norm": 0.02308974415063858,
      "learning_rate": 5.5330490405117276e-06,
      "loss": 0.0164,
      "step": 1740
    },
    {
      "epoch": 2.5179856115107913,
      "grad_norm": 0.02150503359735012,
      "learning_rate": 5.373134328358209e-06,
      "loss": 0.001,
      "step": 1750
    },
    {
      "epoch": 2.5323741007194247,
      "grad_norm": 0.015522762201726437,
      "learning_rate": 5.213219616204691e-06,
      "loss": 0.0108,
      "step": 1760
    },
    {
      "epoch": 2.5467625899280577,
      "grad_norm": 0.012833495624363422,
      "learning_rate": 5.053304904051173e-06,
      "loss": 0.0013,
      "step": 1770
    },
    {
      "epoch": 2.5611510791366907,
      "grad_norm": 0.013203635811805725,
      "learning_rate": 4.893390191897655e-06,
      "loss": 0.0007,
      "step": 1780
    },
    {
      "epoch": 2.5755395683453237,
      "grad_norm": 0.021471163257956505,
      "learning_rate": 4.733475479744136e-06,
      "loss": 0.0311,
      "step": 1790
    },
    {
      "epoch": 2.5899280575539567,
      "grad_norm": 1.1091023683547974,
      "learning_rate": 4.5735607675906185e-06,
      "loss": 0.0019,
      "step": 1800
    },
    {
      "epoch": 2.6043165467625897,
      "grad_norm": 0.018182994797825813,
      "learning_rate": 4.4136460554371e-06,
      "loss": 0.057,
      "step": 1810
    },
    {
      "epoch": 2.618705035971223,
      "grad_norm": 0.049217093735933304,
      "learning_rate": 4.253731343283582e-06,
      "loss": 0.0392,
      "step": 1820
    },
    {
      "epoch": 2.633093525179856,
      "grad_norm": 0.019230417907238007,
      "learning_rate": 4.093816631130064e-06,
      "loss": 0.0564,
      "step": 1830
    },
    {
      "epoch": 2.647482014388489,
      "grad_norm": 5.212375640869141,
      "learning_rate": 3.933901918976546e-06,
      "loss": 0.0081,
      "step": 1840
    },
    {
      "epoch": 2.661870503597122,
      "grad_norm": 0.28251585364341736,
      "learning_rate": 3.773987206823028e-06,
      "loss": 0.0014,
      "step": 1850
    },
    {
      "epoch": 2.6762589928057556,
      "grad_norm": 2.0850493907928467,
      "learning_rate": 3.6140724946695095e-06,
      "loss": 0.0055,
      "step": 1860
    },
    {
      "epoch": 2.6906474820143886,
      "grad_norm": 0.05038575083017349,
      "learning_rate": 3.4541577825159916e-06,
      "loss": 0.0125,
      "step": 1870
    },
    {
      "epoch": 2.7050359712230216,
      "grad_norm": 0.07220063358545303,
      "learning_rate": 3.2942430703624737e-06,
      "loss": 0.0247,
      "step": 1880
    },
    {
      "epoch": 2.7194244604316546,
      "grad_norm": 0.04881754890084267,
      "learning_rate": 3.1343283582089554e-06,
      "loss": 0.0022,
      "step": 1890
    },
    {
      "epoch": 2.7338129496402876,
      "grad_norm": 0.016412261873483658,
      "learning_rate": 2.974413646055437e-06,
      "loss": 0.0031,
      "step": 1900
    },
    {
      "epoch": 2.7482014388489207,
      "grad_norm": 0.01992158032953739,
      "learning_rate": 2.814498933901919e-06,
      "loss": 0.0007,
      "step": 1910
    },
    {
      "epoch": 2.762589928057554,
      "grad_norm": 0.012017088010907173,
      "learning_rate": 2.654584221748401e-06,
      "loss": 0.0012,
      "step": 1920
    },
    {
      "epoch": 2.776978417266187,
      "grad_norm": 0.05983365699648857,
      "learning_rate": 2.494669509594883e-06,
      "loss": 0.0013,
      "step": 1930
    },
    {
      "epoch": 2.79136690647482,
      "grad_norm": 0.012276580557227135,
      "learning_rate": 2.3347547974413646e-06,
      "loss": 0.0011,
      "step": 1940
    },
    {
      "epoch": 2.805755395683453,
      "grad_norm": 0.703606128692627,
      "learning_rate": 2.1748400852878463e-06,
      "loss": 0.0092,
      "step": 1950
    },
    {
      "epoch": 2.8201438848920866,
      "grad_norm": 0.011833607219159603,
      "learning_rate": 2.0149253731343284e-06,
      "loss": 0.0461,
      "step": 1960
    },
    {
      "epoch": 2.8345323741007196,
      "grad_norm": 6.83667516708374,
      "learning_rate": 1.85501066098081e-06,
      "loss": 0.0406,
      "step": 1970
    },
    {
      "epoch": 2.8489208633093526,
      "grad_norm": 0.011395408771932125,
      "learning_rate": 1.6950959488272922e-06,
      "loss": 0.0012,
      "step": 1980
    },
    {
      "epoch": 2.8633093525179856,
      "grad_norm": 0.04253735393285751,
      "learning_rate": 1.535181236673774e-06,
      "loss": 0.0862,
      "step": 1990
    },
    {
      "epoch": 2.8776978417266186,
      "grad_norm": 2.5212018489837646,
      "learning_rate": 1.375266524520256e-06,
      "loss": 0.0521,
      "step": 2000
    },
    {
      "epoch": 2.8920863309352516,
      "grad_norm": 0.043409716337919235,
      "learning_rate": 1.2153518123667379e-06,
      "loss": 0.0016,
      "step": 2010
    },
    {
      "epoch": 2.906474820143885,
      "grad_norm": 0.01511769276112318,
      "learning_rate": 1.0554371002132196e-06,
      "loss": 0.0029,
      "step": 2020
    },
    {
      "epoch": 2.920863309352518,
      "grad_norm": 0.013335817493498325,
      "learning_rate": 8.955223880597015e-07,
      "loss": 0.0255,
      "step": 2030
    },
    {
      "epoch": 2.935251798561151,
      "grad_norm": 0.015346136875450611,
      "learning_rate": 7.356076759061834e-07,
      "loss": 0.001,
      "step": 2040
    },
    {
      "epoch": 2.949640287769784,
      "grad_norm": 0.016358207911252975,
      "learning_rate": 5.756929637526653e-07,
      "loss": 0.0007,
      "step": 2050
    },
    {
      "epoch": 2.9640287769784175,
      "grad_norm": 0.012197220697999,
      "learning_rate": 4.1577825159914716e-07,
      "loss": 0.0009,
      "step": 2060
    },
    {
      "epoch": 2.9784172661870505,
      "grad_norm": 0.009562147781252861,
      "learning_rate": 2.55863539445629e-07,
      "loss": 0.0012,
      "step": 2070
    },
    {
      "epoch": 2.9928057553956835,
      "grad_norm": 0.009785384871065617,
      "learning_rate": 9.594882729211088e-08,
      "loss": 0.0468,
      "step": 2080
    },
    {
      "epoch": 3.0,
      "eval_f1": 0.8516746411483254,
      "eval_loss": 0.06548281013965607,
      "eval_precision": 0.8725490196078431,
      "eval_recall": 0.8317757009345794,
      "eval_runtime": 1.3847,
      "eval_samples_per_second": 1719.461,
      "eval_steps_per_second": 107.602,
      "step": 2085
    }
  ],
  "logging_steps": 10,
  "max_steps": 2085,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 1
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1103685248752128.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
