{
  "best_global_step": 968,
  "best_metric": 0.10579660534858704,
  "best_model_checkpoint": "/home/snguyen/spot-the-scam-project/artifacts/transformer/checkpoint-968",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 968,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010330578512396695,
      "grad_norm": 4.703976154327393,
      "learning_rate": 9.278350515463919e-07,
      "loss": 0.6766,
      "step": 10
    },
    {
      "epoch": 0.02066115702479339,
      "grad_norm": 3.4400298595428467,
      "learning_rate": 1.9587628865979384e-06,
      "loss": 0.6511,
      "step": 20
    },
    {
      "epoch": 0.030991735537190084,
      "grad_norm": 4.108104705810547,
      "learning_rate": 2.989690721649485e-06,
      "loss": 0.6006,
      "step": 30
    },
    {
      "epoch": 0.04132231404958678,
      "grad_norm": 3.8866748809814453,
      "learning_rate": 4.020618556701031e-06,
      "loss": 0.5292,
      "step": 40
    },
    {
      "epoch": 0.05165289256198347,
      "grad_norm": 2.5028867721557617,
      "learning_rate": 5.051546391752578e-06,
      "loss": 0.4198,
      "step": 50
    },
    {
      "epoch": 0.06198347107438017,
      "grad_norm": 1.6685080528259277,
      "learning_rate": 6.082474226804124e-06,
      "loss": 0.3294,
      "step": 60
    },
    {
      "epoch": 0.07231404958677685,
      "grad_norm": 1.0191187858581543,
      "learning_rate": 7.11340206185567e-06,
      "loss": 0.2491,
      "step": 70
    },
    {
      "epoch": 0.08264462809917356,
      "grad_norm": 0.9723655581474304,
      "learning_rate": 8.144329896907216e-06,
      "loss": 0.2003,
      "step": 80
    },
    {
      "epoch": 0.09297520661157024,
      "grad_norm": 0.6860754489898682,
      "learning_rate": 9.175257731958764e-06,
      "loss": 0.1322,
      "step": 90
    },
    {
      "epoch": 0.10330578512396695,
      "grad_norm": 0.47402727603912354,
      "learning_rate": 1.020618556701031e-05,
      "loss": 0.1129,
      "step": 100
    },
    {
      "epoch": 0.11363636363636363,
      "grad_norm": 0.40855422616004944,
      "learning_rate": 1.1237113402061856e-05,
      "loss": 0.068,
      "step": 110
    },
    {
      "epoch": 0.12396694214876033,
      "grad_norm": 2.5328145027160645,
      "learning_rate": 1.2268041237113401e-05,
      "loss": 0.2872,
      "step": 120
    },
    {
      "epoch": 0.13429752066115702,
      "grad_norm": 1.6092427968978882,
      "learning_rate": 1.3298969072164948e-05,
      "loss": 0.1948,
      "step": 130
    },
    {
      "epoch": 0.1446280991735537,
      "grad_norm": 0.8369685411453247,
      "learning_rate": 1.4329896907216495e-05,
      "loss": 0.1408,
      "step": 140
    },
    {
      "epoch": 0.15495867768595042,
      "grad_norm": 5.178857803344727,
      "learning_rate": 1.536082474226804e-05,
      "loss": 0.3299,
      "step": 150
    },
    {
      "epoch": 0.1652892561983471,
      "grad_norm": 1.108429193496704,
      "learning_rate": 1.6391752577319588e-05,
      "loss": 0.1984,
      "step": 160
    },
    {
      "epoch": 0.1756198347107438,
      "grad_norm": 1.3731595277786255,
      "learning_rate": 1.7422680412371137e-05,
      "loss": 0.2273,
      "step": 170
    },
    {
      "epoch": 0.1859504132231405,
      "grad_norm": 1.8679790496826172,
      "learning_rate": 1.8453608247422682e-05,
      "loss": 0.19,
      "step": 180
    },
    {
      "epoch": 0.1962809917355372,
      "grad_norm": 0.4076886773109436,
      "learning_rate": 1.9484536082474227e-05,
      "loss": 0.2043,
      "step": 190
    },
    {
      "epoch": 0.2066115702479339,
      "grad_norm": 2.671358346939087,
      "learning_rate": 2.0515463917525773e-05,
      "loss": 0.1385,
      "step": 200
    },
    {
      "epoch": 0.21694214876033058,
      "grad_norm": 1.2910875082015991,
      "learning_rate": 2.154639175257732e-05,
      "loss": 0.1421,
      "step": 210
    },
    {
      "epoch": 0.22727272727272727,
      "grad_norm": 0.4317775070667267,
      "learning_rate": 2.2577319587628867e-05,
      "loss": 0.0995,
      "step": 220
    },
    {
      "epoch": 0.23760330578512398,
      "grad_norm": 0.3546595871448517,
      "learning_rate": 2.3608247422680412e-05,
      "loss": 0.116,
      "step": 230
    },
    {
      "epoch": 0.24793388429752067,
      "grad_norm": 0.3400242328643799,
      "learning_rate": 2.4639175257731957e-05,
      "loss": 0.0919,
      "step": 240
    },
    {
      "epoch": 0.25826446280991733,
      "grad_norm": 0.13257643580436707,
      "learning_rate": 2.5670103092783506e-05,
      "loss": 0.0857,
      "step": 250
    },
    {
      "epoch": 0.26859504132231404,
      "grad_norm": 1.43010413646698,
      "learning_rate": 2.670103092783505e-05,
      "loss": 0.1635,
      "step": 260
    },
    {
      "epoch": 0.27892561983471076,
      "grad_norm": 3.4565820693969727,
      "learning_rate": 2.77319587628866e-05,
      "loss": 0.1521,
      "step": 270
    },
    {
      "epoch": 0.2892561983471074,
      "grad_norm": 1.7479398250579834,
      "learning_rate": 2.8762886597938146e-05,
      "loss": 0.1312,
      "step": 280
    },
    {
      "epoch": 0.29958677685950413,
      "grad_norm": 0.3397315740585327,
      "learning_rate": 2.979381443298969e-05,
      "loss": 0.1201,
      "step": 290
    },
    {
      "epoch": 0.30991735537190085,
      "grad_norm": 2.7068402767181396,
      "learning_rate": 2.9908151549942597e-05,
      "loss": 0.1899,
      "step": 300
    },
    {
      "epoch": 0.3202479338842975,
      "grad_norm": 0.582635223865509,
      "learning_rate": 2.979334098737084e-05,
      "loss": 0.1217,
      "step": 310
    },
    {
      "epoch": 0.3305785123966942,
      "grad_norm": 5.252079486846924,
      "learning_rate": 2.9678530424799084e-05,
      "loss": 0.1351,
      "step": 320
    },
    {
      "epoch": 0.3409090909090909,
      "grad_norm": 1.9796040058135986,
      "learning_rate": 2.9563719862227327e-05,
      "loss": 0.1961,
      "step": 330
    },
    {
      "epoch": 0.3512396694214876,
      "grad_norm": 2.5909059047698975,
      "learning_rate": 2.944890929965557e-05,
      "loss": 0.1115,
      "step": 340
    },
    {
      "epoch": 0.3615702479338843,
      "grad_norm": 0.28774669766426086,
      "learning_rate": 2.9334098737083814e-05,
      "loss": 0.108,
      "step": 350
    },
    {
      "epoch": 0.371900826446281,
      "grad_norm": 0.676539421081543,
      "learning_rate": 2.9219288174512057e-05,
      "loss": 0.1044,
      "step": 360
    },
    {
      "epoch": 0.3822314049586777,
      "grad_norm": 5.058534622192383,
      "learning_rate": 2.91044776119403e-05,
      "loss": 0.1317,
      "step": 370
    },
    {
      "epoch": 0.3925619834710744,
      "grad_norm": 0.7016995549201965,
      "learning_rate": 2.8989667049368544e-05,
      "loss": 0.2024,
      "step": 380
    },
    {
      "epoch": 0.40289256198347106,
      "grad_norm": 2.7278494834899902,
      "learning_rate": 2.8874856486796787e-05,
      "loss": 0.1843,
      "step": 390
    },
    {
      "epoch": 0.4132231404958678,
      "grad_norm": 2.4777848720550537,
      "learning_rate": 2.876004592422503e-05,
      "loss": 0.1648,
      "step": 400
    },
    {
      "epoch": 0.42355371900826444,
      "grad_norm": 0.18564623594284058,
      "learning_rate": 2.8645235361653274e-05,
      "loss": 0.1628,
      "step": 410
    },
    {
      "epoch": 0.43388429752066116,
      "grad_norm": 0.4515726864337921,
      "learning_rate": 2.8530424799081517e-05,
      "loss": 0.1217,
      "step": 420
    },
    {
      "epoch": 0.44421487603305787,
      "grad_norm": 1.633537769317627,
      "learning_rate": 2.841561423650976e-05,
      "loss": 0.1168,
      "step": 430
    },
    {
      "epoch": 0.45454545454545453,
      "grad_norm": 0.11996642500162125,
      "learning_rate": 2.8300803673938004e-05,
      "loss": 0.0461,
      "step": 440
    },
    {
      "epoch": 0.46487603305785125,
      "grad_norm": 0.15292418003082275,
      "learning_rate": 2.8185993111366247e-05,
      "loss": 0.1679,
      "step": 450
    },
    {
      "epoch": 0.47520661157024796,
      "grad_norm": Infinity,
      "learning_rate": 2.807118254879449e-05,
      "loss": 0.0594,
      "step": 460
    },
    {
      "epoch": 0.4855371900826446,
      "grad_norm": 0.16092683374881744,
      "learning_rate": 2.7956371986222734e-05,
      "loss": 0.127,
      "step": 470
    },
    {
      "epoch": 0.49586776859504134,
      "grad_norm": 1.3988409042358398,
      "learning_rate": 2.7841561423650977e-05,
      "loss": 0.2205,
      "step": 480
    },
    {
      "epoch": 0.506198347107438,
      "grad_norm": 1.8357728719711304,
      "learning_rate": 2.772675086107922e-05,
      "loss": 0.1636,
      "step": 490
    },
    {
      "epoch": 0.5165289256198347,
      "grad_norm": 0.2015804499387741,
      "learning_rate": 2.7611940298507464e-05,
      "loss": 0.0379,
      "step": 500
    },
    {
      "epoch": 0.5268595041322314,
      "grad_norm": 2.8220150470733643,
      "learning_rate": 2.7497129735935707e-05,
      "loss": 0.3552,
      "step": 510
    },
    {
      "epoch": 0.5371900826446281,
      "grad_norm": 0.30692365765571594,
      "learning_rate": 2.738231917336395e-05,
      "loss": 0.0553,
      "step": 520
    },
    {
      "epoch": 0.5475206611570248,
      "grad_norm": 0.34080296754837036,
      "learning_rate": 2.7267508610792193e-05,
      "loss": 0.1087,
      "step": 530
    },
    {
      "epoch": 0.5578512396694215,
      "grad_norm": 0.5580190420150757,
      "learning_rate": 2.7152698048220437e-05,
      "loss": 0.0958,
      "step": 540
    },
    {
      "epoch": 0.5681818181818182,
      "grad_norm": 12.085930824279785,
      "learning_rate": 2.703788748564868e-05,
      "loss": 0.0611,
      "step": 550
    },
    {
      "epoch": 0.5785123966942148,
      "grad_norm": 0.10968444496393204,
      "learning_rate": 2.6923076923076923e-05,
      "loss": 0.0743,
      "step": 560
    },
    {
      "epoch": 0.5888429752066116,
      "grad_norm": 0.10683634132146835,
      "learning_rate": 2.6808266360505167e-05,
      "loss": 0.0253,
      "step": 570
    },
    {
      "epoch": 0.5991735537190083,
      "grad_norm": 2.8327040672302246,
      "learning_rate": 2.669345579793341e-05,
      "loss": 0.2562,
      "step": 580
    },
    {
      "epoch": 0.609504132231405,
      "grad_norm": 1.318297266960144,
      "learning_rate": 2.6578645235361653e-05,
      "loss": 0.1764,
      "step": 590
    },
    {
      "epoch": 0.6198347107438017,
      "grad_norm": 0.5438181757926941,
      "learning_rate": 2.64638346727899e-05,
      "loss": 0.0759,
      "step": 600
    },
    {
      "epoch": 0.6301652892561983,
      "grad_norm": 3.033223867416382,
      "learning_rate": 2.6349024110218143e-05,
      "loss": 0.0877,
      "step": 610
    },
    {
      "epoch": 0.640495867768595,
      "grad_norm": 1.8688043355941772,
      "learning_rate": 2.6234213547646387e-05,
      "loss": 0.1401,
      "step": 620
    },
    {
      "epoch": 0.6508264462809917,
      "grad_norm": 7.3099236488342285,
      "learning_rate": 2.611940298507463e-05,
      "loss": 0.1106,
      "step": 630
    },
    {
      "epoch": 0.6611570247933884,
      "grad_norm": 0.09869071841239929,
      "learning_rate": 2.6004592422502873e-05,
      "loss": 0.1311,
      "step": 640
    },
    {
      "epoch": 0.6714876033057852,
      "grad_norm": 0.11366278678178787,
      "learning_rate": 2.5889781859931116e-05,
      "loss": 0.1056,
      "step": 650
    },
    {
      "epoch": 0.6818181818181818,
      "grad_norm": 0.34495019912719727,
      "learning_rate": 2.577497129735936e-05,
      "loss": 0.1723,
      "step": 660
    },
    {
      "epoch": 0.6921487603305785,
      "grad_norm": 1.4882593154907227,
      "learning_rate": 2.5660160734787603e-05,
      "loss": 0.1289,
      "step": 670
    },
    {
      "epoch": 0.7024793388429752,
      "grad_norm": 0.1294734925031662,
      "learning_rate": 2.5545350172215846e-05,
      "loss": 0.0459,
      "step": 680
    },
    {
      "epoch": 0.7128099173553719,
      "grad_norm": 2.3632402420043945,
      "learning_rate": 2.543053960964409e-05,
      "loss": 0.0991,
      "step": 690
    },
    {
      "epoch": 0.7231404958677686,
      "grad_norm": 0.6482803821563721,
      "learning_rate": 2.5315729047072333e-05,
      "loss": 0.0951,
      "step": 700
    },
    {
      "epoch": 0.7334710743801653,
      "grad_norm": 10.988450050354004,
      "learning_rate": 2.5200918484500576e-05,
      "loss": 0.1382,
      "step": 710
    },
    {
      "epoch": 0.743801652892562,
      "grad_norm": 6.502532482147217,
      "learning_rate": 2.508610792192882e-05,
      "loss": 0.1248,
      "step": 720
    },
    {
      "epoch": 0.7541322314049587,
      "grad_norm": 1.6212464570999146,
      "learning_rate": 2.4971297359357063e-05,
      "loss": 0.1312,
      "step": 730
    },
    {
      "epoch": 0.7644628099173554,
      "grad_norm": 0.1698964685201645,
      "learning_rate": 2.4856486796785306e-05,
      "loss": 0.0426,
      "step": 740
    },
    {
      "epoch": 0.7747933884297521,
      "grad_norm": 0.9158139228820801,
      "learning_rate": 2.474167623421355e-05,
      "loss": 0.0804,
      "step": 750
    },
    {
      "epoch": 0.7851239669421488,
      "grad_norm": 0.331576943397522,
      "learning_rate": 2.4626865671641793e-05,
      "loss": 0.1417,
      "step": 760
    },
    {
      "epoch": 0.7954545454545454,
      "grad_norm": 1.113541841506958,
      "learning_rate": 2.4512055109070036e-05,
      "loss": 0.1026,
      "step": 770
    },
    {
      "epoch": 0.8057851239669421,
      "grad_norm": 0.2577393352985382,
      "learning_rate": 2.439724454649828e-05,
      "loss": 0.0726,
      "step": 780
    },
    {
      "epoch": 0.8161157024793388,
      "grad_norm": 0.1517639011144638,
      "learning_rate": 2.4282433983926523e-05,
      "loss": 0.0525,
      "step": 790
    },
    {
      "epoch": 0.8264462809917356,
      "grad_norm": 2.2239081859588623,
      "learning_rate": 2.4167623421354766e-05,
      "loss": 0.1137,
      "step": 800
    },
    {
      "epoch": 0.8367768595041323,
      "grad_norm": 3.3551881313323975,
      "learning_rate": 2.405281285878301e-05,
      "loss": 0.1175,
      "step": 810
    },
    {
      "epoch": 0.8471074380165289,
      "grad_norm": 6.345516681671143,
      "learning_rate": 2.3938002296211253e-05,
      "loss": 0.1228,
      "step": 820
    },
    {
      "epoch": 0.8574380165289256,
      "grad_norm": 0.5059385895729065,
      "learning_rate": 2.3823191733639496e-05,
      "loss": 0.1153,
      "step": 830
    },
    {
      "epoch": 0.8677685950413223,
      "grad_norm": 1.5861375331878662,
      "learning_rate": 2.370838117106774e-05,
      "loss": 0.082,
      "step": 840
    },
    {
      "epoch": 0.878099173553719,
      "grad_norm": 0.18188011646270752,
      "learning_rate": 2.3593570608495983e-05,
      "loss": 0.1176,
      "step": 850
    },
    {
      "epoch": 0.8884297520661157,
      "grad_norm": 0.838937520980835,
      "learning_rate": 2.3478760045924226e-05,
      "loss": 0.1271,
      "step": 860
    },
    {
      "epoch": 0.8987603305785123,
      "grad_norm": 0.20818538963794708,
      "learning_rate": 2.336394948335247e-05,
      "loss": 0.0957,
      "step": 870
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 0.15120859444141388,
      "learning_rate": 2.3249138920780712e-05,
      "loss": 0.0738,
      "step": 880
    },
    {
      "epoch": 0.9194214876033058,
      "grad_norm": 0.10466641187667847,
      "learning_rate": 2.3134328358208956e-05,
      "loss": 0.1121,
      "step": 890
    },
    {
      "epoch": 0.9297520661157025,
      "grad_norm": 3.2157866954803467,
      "learning_rate": 2.30195177956372e-05,
      "loss": 0.1101,
      "step": 900
    },
    {
      "epoch": 0.9400826446280992,
      "grad_norm": 0.13193802535533905,
      "learning_rate": 2.2904707233065442e-05,
      "loss": 0.0719,
      "step": 910
    },
    {
      "epoch": 0.9504132231404959,
      "grad_norm": 0.3981751799583435,
      "learning_rate": 2.2789896670493686e-05,
      "loss": 0.0862,
      "step": 920
    },
    {
      "epoch": 0.9607438016528925,
      "grad_norm": 0.1305660903453827,
      "learning_rate": 2.2675086107921932e-05,
      "loss": 0.1204,
      "step": 930
    },
    {
      "epoch": 0.9710743801652892,
      "grad_norm": 1.1762721538543701,
      "learning_rate": 2.2560275545350176e-05,
      "loss": 0.0717,
      "step": 940
    },
    {
      "epoch": 0.981404958677686,
      "grad_norm": 1.3196626901626587,
      "learning_rate": 2.244546498277842e-05,
      "loss": 0.1015,
      "step": 950
    },
    {
      "epoch": 0.9917355371900827,
      "grad_norm": 0.10447291284799576,
      "learning_rate": 2.2330654420206662e-05,
      "loss": 0.0817,
      "step": 960
    },
    {
      "epoch": 1.0,
      "eval_f1": 0.5596330275229358,
      "eval_loss": 0.10579660534858704,
      "eval_precision": 0.8840579710144928,
      "eval_recall": 0.40939597315436244,
      "eval_runtime": 2.2408,
      "eval_samples_per_second": 1480.723,
      "eval_steps_per_second": 92.824,
      "step": 968
    }
  ],
  "logging_steps": 10,
  "max_steps": 2904,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 512814417047040.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
