(.venv) ➜  spot-the-scam-project git:(David-Pu) ✗ PYTHONPATH=src python -m spot_scam.pipeline.train
2025-11-19 08:45:32.986907780 [W:onnxruntime:Default, device_discovery.cc:164 DiscoverDevicesForPlatform] GPU device discovery failed: device_discovery.cc:89 ReadFileContents Failed to open file: "/sys/class/drm/card0/device/vendor"
/home/snguyen/spot-the-scam-project/.venv/lib/python3.12/site-packages/mlflow/types/type_hints.py:394: UserWarning: Any type hint is inferred as AnyType, and MLflow doesn't validate the data for this type. Please use a more specific type hint to enable data validation.
  col_spec_type = _infer_colspec_type_from_type_hint(type_hint)
RUN FUNCTION ENTERED
2025-11-19 08:45:38 | INFO     | __main__ | Configuration hash: 40d153474518af98
2025-11-19 08:45:38 | INFO     | spot_scam.data.ingest | Loading raw dataset from data/fake_job_postings.csv
2025-11-19 08:45:38 | INFO     | spot_scam.data.ingest | Loading raw dataset from data/Fake_Real_Job_Posting.csv
2025-11-19 08:45:38 | INFO     | spot_scam.data.ingest | Dropped 10384 potential duplicate rows after merging sources.
2025-11-19 08:45:43 | INFO     | spot_scam.data.preprocess | Dropping 6 columns marked for removal: ['job_id', 'location', '_source_file', 'unnamed_0', 'department', 'salary_range']
2025-11-19 08:45:43 | INFO     | spot_scam.data.split | Creating stratified train/val/test splits (70/15/15)
2025-11-19 08:45:43 | WARNING  | spot_scam.data.split | Detected 3224 duplicate records based on text checksum; dropping duplicates.
2025-11-19 08:45:43 | INFO     | spot_scam.data.split | Persisted split indices to data/processed/split_indices.npz
2025-11-19 08:45:43 | INFO     | spot_scam.data.split | Train split size: 15506 | fraud ratio: 0.045
2025-11-19 08:45:43 | INFO     | spot_scam.data.split | Val split size: 3323 | fraud ratio: 0.045
2025-11-19 08:45:43 | INFO     | spot_scam.data.split | Test split size: 3323 | fraud ratio: 0.045
2025-11-19 08:45:55 | INFO     | spot_scam.models.classical | Training 3 Logistic Regression variants
2025-11-19 08:45:55 | INFO     | spot_scam.models.classical | Starting Logistic Regression fit (C=0.1)
2025-11-19 08:46:01 | INFO     | spot_scam.models.classical | Logistic Regression (C=0.1) F1=0.569 Precision=0.508 Recall=0.647
2025-11-19 08:46:01 | INFO     | spot_scam.models.classical | Starting Logistic Regression fit (C=1.0)
2025-11-19 08:46:08 | INFO     | spot_scam.models.classical | Logistic Regression (C=1.0) F1=0.782 Precision=0.876 Recall=0.707
2025-11-19 08:46:08 | INFO     | spot_scam.models.classical | Starting Logistic Regression fit (C=10.0)
2025-11-19 08:46:19 | INFO     | spot_scam.models.classical | Logistic Regression (C=10.0) F1=0.830 Precision=0.847 Recall=0.813
2025-11-19 08:46:19 | INFO     | spot_scam.models.classical | Training 3 Logistic Regression L1 variants
2025-11-19 08:46:19 | INFO     | spot_scam.models.classical | Starting Logistic Regression L1 fit (C=0.1)
/home/snguyen/spot-the-scam-project/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
2025-11-19 08:49:50 | INFO     | spot_scam.models.classical | Logistic Regression L1 (C=0.1) F1=0.331 Precision=0.317 Recall=0.347
2025-11-19 08:49:50 | INFO     | spot_scam.models.classical | Starting Logistic Regression L1 fit (C=1.0)
/home/snguyen/spot-the-scam-project/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
2025-11-19 09:02:41 | INFO     | spot_scam.models.classical | Logistic Regression L1 (C=1.0) F1=0.681 Precision=0.736 Recall=0.633
2025-11-19 09:02:41 | INFO     | spot_scam.models.classical | Starting Logistic Regression L1 fit (C=10.0)
/home/snguyen/spot-the-scam-project/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
2025-11-19 10:45:24 | INFO     | spot_scam.models.classical | Logistic Regression L1 (C=10.0) F1=0.744 Precision=0.785 Recall=0.707
2025-11-19 10:45:24 | INFO     | spot_scam.models.classical | Training 7 Linear SVM variants
2025-11-19 10:45:24 | INFO     | spot_scam.models.classical | Starting Linear SVM fit (C=0.1)
/home/snguyen/spot-the-scam-project/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
2025-11-19 10:45:36 | INFO     | spot_scam.models.classical | Linear SVM (C=0.1) F1=0.811 Precision=0.870 Recall=0.760
2025-11-19 10:45:36 | INFO     | spot_scam.models.classical | Starting Linear SVM fit (C=0.5)
/home/snguyen/spot-the-scam-project/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
2025-11-19 10:45:43 | INFO     | spot_scam.models.classical | Linear SVM (C=0.5) F1=0.835 Precision=0.906 Recall=0.773
2025-11-19 10:45:43 | INFO     | spot_scam.models.classical | Starting Linear SVM fit (C=1.0)
/home/snguyen/spot-the-scam-project/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
2025-11-19 10:45:51 | INFO     | spot_scam.models.classical | Linear SVM (C=1.0) F1=0.836 Precision=0.876 Recall=0.800
2025-11-19 10:45:51 | INFO     | spot_scam.models.classical | Starting Linear SVM fit (C=3.0)
/home/snguyen/spot-the-scam-project/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
2025-11-19 10:45:55 | INFO     | spot_scam.models.classical | Linear SVM (C=3.0) F1=0.855 Precision=0.910 Recall=0.807
2025-11-19 10:45:55 | INFO     | spot_scam.models.classical | Starting Linear SVM fit (C=5.0)
/home/snguyen/spot-the-scam-project/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
2025-11-19 10:46:00 | INFO     | spot_scam.models.classical | Linear SVM (C=5.0) F1=0.853 Precision=0.922 Recall=0.793
2025-11-19 10:46:00 | INFO     | spot_scam.models.classical | Starting Linear SVM fit (C=10.0)
/home/snguyen/spot-the-scam-project/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
2025-11-19 10:46:04 | INFO     | spot_scam.models.classical | Linear SVM (C=10.0) F1=0.835 Precision=0.844 Recall=0.827
2025-11-19 10:46:04 | INFO     | spot_scam.models.classical | Starting Linear SVM fit (C=30.0)
/home/snguyen/spot-the-scam-project/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
2025-11-19 10:46:09 | INFO     | spot_scam.models.classical | Linear SVM (C=30.0) F1=0.829 Precision=0.912 Recall=0.760
2025-11-19 10:46:09 | INFO     | spot_scam.models.classical | Training 1 LightGBM variants
2025-11-19 10:46:09 | INFO     | spot_scam.models.classical | Starting LightGBM fit with params: {'num_leaves': 64, 'max_depth': -1, 'learning_rate': 0.05, 'n_estimators': 800, 'subsample': 0.9, 'colsample_bytree': 0.9, 'class_weight': 'balanced'}
[LightGBM] [Info] Number of positive: 699, number of negative: 14807
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001269 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 606
[LightGBM] [Info] Number of data points in the train set: 15506, number of used features: 19
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
[LightGBM] [Info] Start training from score 0.000000
2025-11-19 10:46:09 | INFO     | spot_scam.models.classical | LightGBM {'num_leaves': 64, 'max_depth': -1, 'learning_rate': 0.05, 'n_estimators': 800, 'subsample': 0.9, 'colsample_bytree': 0.9, 'class_weight': 'balanced'} F1=0.289 Precision=0.400 Recall=0.227
2025-11-19 10:46:09 | INFO     | spot_scam.models.xgboost_model.xgb | Starting XGBoost fit: n=600 depth=4 lr=0.050
2025-11-19 10:46:09 | WARNING  | spot_scam.models.xgboost_model.xgb | Early stopping requested but this xgboost version does not expose callbacks or early_stopping_rounds; continuing without it.
/home/snguyen/spot-the-scam-project/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [10:46:11] WARNING: /workspace/src/learner.cc:790:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
2025-11-19 10:48:57 | INFO     | spot_scam.models.xgboost_model.xgb | Completed XGBoost fit
/home/snguyen/spot-the-scam-project/.venv/lib/python3.12/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.
  warnings.warn(
2025-11-19 10:48:57 | INFO     | __main__ | XGBOOST_d4_lr0.05_ne600_mcw1_a0.0_l1.0_spw14 trained (167.4s) F1=0.747 P=0.755 R=0.740 Thr=0.417
2025-11-19 10:48:57 | INFO     | spot_scam.models.xgboost_model.xgb | Starting XGBoost fit: n=1000 depth=4 lr=0.050
2025-11-19 10:48:57 | WARNING  | spot_scam.models.xgboost_model.xgb | Early stopping requested but this xgboost version does not expose callbacks or early_stopping_rounds; continuing without it.
/home/snguyen/spot-the-scam-project/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [10:48:57] WARNING: /workspace/src/learner.cc:790:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
2025-11-19 10:53:23 | INFO     | spot_scam.models.xgboost_model.xgb | Completed XGBoost fit
/home/snguyen/spot-the-scam-project/.venv/lib/python3.12/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.
  warnings.warn(
2025-11-19 10:53:23 | INFO     | __main__ | XGBOOST_d4_lr0.05_ne1000_mcw1_a0.3_l1.0_spw27 trained (266.0s) F1=0.738 P=0.798 R=0.687 Thr=0.500
2025-11-19 10:53:23 | INFO     | spot_scam.models.xgboost_model.xgb | Starting XGBoost fit: n=800 depth=4 lr=0.030
2025-11-19 10:53:23 | WARNING  | spot_scam.models.xgboost_model.xgb | Early stopping requested but this xgboost version does not expose callbacks or early_stopping_rounds; continuing without it.
/home/snguyen/spot-the-scam-project/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [10:53:23] WARNING: /workspace/src/learner.cc:790:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
2025-11-19 10:56:51 | INFO     | spot_scam.models.xgboost_model.xgb | Completed XGBoost fit
/home/snguyen/spot-the-scam-project/.venv/lib/python3.12/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.
  warnings.warn(
2025-11-19 10:56:51 | INFO     | __main__ | XGBOOST_d4_lr0.03_ne800_mcw5_a0.1_l2.0_spw21 trained (208.1s) F1=0.728 P=0.856 R=0.633 Thr=0.579
2025-11-19 10:56:51 | INFO     | spot_scam.models.xgboost_model.xgb | Starting XGBoost fit: n=600 depth=4 lr=0.020
2025-11-19 10:56:51 | WARNING  | spot_scam.models.xgboost_model.xgb | Early stopping requested but this xgboost version does not expose callbacks or early_stopping_rounds; continuing without it.
/home/snguyen/spot-the-scam-project/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [10:56:52] WARNING: /workspace/src/learner.cc:790:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
2025-11-19 10:59:35 | INFO     | spot_scam.models.xgboost_model.xgb | Completed XGBoost fit
/home/snguyen/spot-the-scam-project/.venv/lib/python3.12/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.
  warnings.warn(
2025-11-19 10:59:35 | INFO     | __main__ | XGBOOST_d4_lr0.02_ne600_mcw10_a0.0_l5.0_spw14 trained (164.2s) F1=0.719 P=0.821 R=0.640 Thr=0.500
2025-11-19 10:59:35 | INFO     | spot_scam.models.xgboost_model.xgb | Starting XGBoost fit: n=600 depth=6 lr=0.050
2025-11-19 10:59:35 | WARNING  | spot_scam.models.xgboost_model.xgb | Early stopping requested but this xgboost version does not expose callbacks or early_stopping_rounds; continuing without it.
/home/snguyen/spot-the-scam-project/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [10:59:36] WARNING: /workspace/src/learner.cc:790:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
2025-11-19 11:03:34 | INFO     | spot_scam.models.xgboost_model.xgb | Completed XGBoost fit
/home/snguyen/spot-the-scam-project/.venv/lib/python3.12/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.
  warnings.warn(
2025-11-19 11:03:34 | INFO     | __main__ | XGBOOST_d6_lr0.05_ne600_mcw1_a0.0_l1.0_spw14 trained (239.1s) F1=0.768 P=0.860 R=0.693 Thr=0.455
2025-11-19 11:03:34 | INFO     | spot_scam.models.xgboost_model.xgb | Starting XGBoost fit: n=1000 depth=6 lr=0.050
2025-11-19 11:03:34 | WARNING  | spot_scam.models.xgboost_model.xgb | Early stopping requested but this xgboost version does not expose callbacks or early_stopping_rounds; continuing without it.
/home/snguyen/spot-the-scam-project/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [11:03:35] WARNING: /workspace/src/learner.cc:790:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
2025-11-19 11:09:47 | INFO     | spot_scam.models.xgboost_model.xgb | Completed XGBoost fit
/home/snguyen/spot-the-scam-project/.venv/lib/python3.12/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.
  warnings.warn(
2025-11-19 11:09:48 | INFO     | __main__ | XGBOOST_d6_lr0.05_ne1000_mcw1_a0.3_l1.0_spw27 trained (373.3s) F1=0.753 P=0.766 R=0.740 Thr=0.379
2025-11-19 11:09:48 | INFO     | spot_scam.models.xgboost_model.xgb | Starting XGBoost fit: n=800 depth=6 lr=0.030
2025-11-19 11:09:48 | WARNING  | spot_scam.models.xgboost_model.xgb | Early stopping requested but this xgboost version does not expose callbacks or early_stopping_rounds; continuing without it.
/home/snguyen/spot-the-scam-project/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [11:09:48] WARNING: /workspace/src/learner.cc:790:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
2025-11-19 11:14:40 | INFO     | spot_scam.models.xgboost_model.xgb | Completed XGBoost fit
/home/snguyen/spot-the-scam-project/.venv/lib/python3.12/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.
  warnings.warn(
2025-11-19 11:14:40 | INFO     | __main__ | XGBOOST_d6_lr0.03_ne800_mcw5_a0.1_l2.0_spw21 trained (292.4s) F1=0.756 P=0.832 R=0.693 Thr=0.500
2025-11-19 11:14:40 | INFO     | spot_scam.models.xgboost_model.xgb | Starting XGBoost fit: n=600 depth=6 lr=0.020
2025-11-19 11:14:40 | WARNING  | spot_scam.models.xgboost_model.xgb | Early stopping requested but this xgboost version does not expose callbacks or early_stopping_rounds; continuing without it.
/home/snguyen/spot-the-scam-project/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [11:14:41] WARNING: /workspace/src/learner.cc:790:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
2025-11-19 11:18:32 | INFO     | spot_scam.models.xgboost_model.xgb | Completed XGBoost fit
/home/snguyen/spot-the-scam-project/.venv/lib/python3.12/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.
  warnings.warn(
2025-11-19 11:18:32 | INFO     | __main__ | XGBOOST_d6_lr0.02_ne600_mcw10_a0.0_l5.0_spw14 trained (231.8s) F1=0.754 P=0.891 R=0.653 Thr=0.737
2025-11-19 11:18:32 | INFO     | spot_scam.models.xgboost_model.xgb | Starting XGBoost fit: n=600 depth=8 lr=0.050
2025-11-19 11:18:32 | WARNING  | spot_scam.models.xgboost_model.xgb | Early stopping requested but this xgboost version does not expose callbacks or early_stopping_rounds; continuing without it.
/home/snguyen/spot-the-scam-project/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [11:18:33] WARNING: /workspace/src/learner.cc:790:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
2025-11-19 11:23:48 | INFO     | spot_scam.models.xgboost_model.xgb | Completed XGBoost fit
/home/snguyen/spot-the-scam-project/.venv/lib/python3.12/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.
  warnings.warn(
2025-11-19 11:23:48 | INFO     | __main__ | XGBOOST_d8_lr0.05_ne600_mcw1_a0.0_l1.0_spw14 trained (316.5s) F1=0.773 P=0.826 R=0.727 Thr=0.500
2025-11-19 11:23:48 | INFO     | spot_scam.models.xgboost_model.xgb | Starting XGBoost fit: n=1000 depth=8 lr=0.050
2025-11-19 11:23:48 | WARNING  | spot_scam.models.xgboost_model.xgb | Early stopping requested but this xgboost version does not expose callbacks or early_stopping_rounds; continuing without it.
/home/snguyen/spot-the-scam-project/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [11:23:49] WARNING: /workspace/src/learner.cc:790:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
2025-11-19 11:31:57 | INFO     | spot_scam.models.xgboost_model.xgb | Completed XGBoost fit
/home/snguyen/spot-the-scam-project/.venv/lib/python3.12/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.
  warnings.warn(
2025-11-19 11:31:57 | INFO     | __main__ | XGBOOST_d8_lr0.05_ne1000_mcw1_a0.3_l1.0_spw27 trained (488.7s) F1=0.774 P=0.810 R=0.740 Thr=0.500
2025-11-19 11:31:57 | INFO     | spot_scam.models.xgboost_model.xgb | Starting XGBoost fit: n=800 depth=8 lr=0.030
2025-11-19 11:31:57 | WARNING  | spot_scam.models.xgboost_model.xgb | Early stopping requested but this xgboost version does not expose callbacks or early_stopping_rounds; continuing without it.
/home/snguyen/spot-the-scam-project/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [11:31:58] WARNING: /workspace/src/learner.cc:790:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
2025-11-19 11:38:10 | INFO     | spot_scam.models.xgboost_model.xgb | Completed XGBoost fit
/home/snguyen/spot-the-scam-project/.venv/lib/python3.12/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.
  warnings.warn(
2025-11-19 11:38:11 | INFO     | __main__ | XGBOOST_d8_lr0.03_ne800_mcw5_a0.1_l2.0_spw21 trained (373.8s) F1=0.758 P=0.857 R=0.680 Thr=0.500
2025-11-19 11:38:11 | INFO     | spot_scam.models.xgboost_model.xgb | Starting XGBoost fit: n=600 depth=8 lr=0.020
2025-11-19 11:38:11 | WARNING  | spot_scam.models.xgboost_model.xgb | Early stopping requested but this xgboost version does not expose callbacks or early_stopping_rounds; continuing without it.
/home/snguyen/spot-the-scam-project/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [11:38:11] WARNING: /workspace/src/learner.cc:790:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
2025-11-19 11:43:13 | INFO     | spot_scam.models.xgboost_model.xgb | Completed XGBoost fit
/home/snguyen/spot-the-scam-project/.venv/lib/python3.12/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.
  warnings.warn(
2025-11-19 11:43:13 | INFO     | __main__ | XGBOOST_d8_lr0.02_ne600_mcw10_a0.0_l5.0_spw14 trained (302.3s) F1=0.754 P=0.825 R=0.693 Thr=0.400
Map: 100%|█████████████████████████████████████████████| 15506/15506 [00:12<00:00, 1273.69 examples/s]
Map: 100%|███████████████████████████████████████████████| 3323/3323 [00:02<00:00, 1563.48 examples/s]
Map: 100%|███████████████████████████████████████████████| 3323/3323 [00:02<00:00, 1561.53 examples/s]
Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/snguyen/spot-the-scam-project/.venv/lib/python3.12/site-packages/accelerate/accelerator.py:479: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self.scaler = torch.cuda.amp.GradScaler(**kwargs)
2025-11-19 11:43:35 | INFO     | spot_scam.models.transformer | Starting transformer fine-tuning for 3 epochs (max).
{'loss': 0.6838, 'grad_norm': 4.317173480987549, 'learning_rate': 1.0309278350515464e-06, 'epoch': 0.01}
{'loss': 0.6513, 'grad_norm': 3.7843096256256104, 'learning_rate': 2.061855670103093e-06, 'epoch': 0.02}
{'loss': 0.6005, 'grad_norm': 4.014454364776611, 'learning_rate': 3.092783505154639e-06, 'epoch': 0.03}
{'loss': 0.5166, 'grad_norm': 3.813436985015869, 'learning_rate': 4.123711340206186e-06, 'epoch': 0.04}
{'loss': 0.4146, 'grad_norm': 3.2399587631225586, 'learning_rate': 5.154639175257732e-06, 'epoch': 0.05}
{'loss': 0.2646, 'grad_norm': 2.0524892807006836, 'learning_rate': 6.185567010309278e-06, 'epoch': 0.06}
{'loss': 0.211, 'grad_norm': 1.1096937656402588, 'learning_rate': 7.216494845360825e-06, 'epoch': 0.07}
{'loss': 0.2271, 'grad_norm': 1.2972776889801025, 'learning_rate': 8.247422680412371e-06, 'epoch': 0.08}
{'loss': 0.1704, 'grad_norm': 0.9677532911300659, 'learning_rate': 9.278350515463918e-06, 'epoch': 0.09}
{'loss': 0.1418, 'grad_norm': 0.6862984299659729, 'learning_rate': 1.0309278350515464e-05, 'epoch': 0.1}
{'loss': 0.2207, 'grad_norm': 2.193655014038086, 'learning_rate': 1.134020618556701e-05, 'epoch': 0.11}
{'loss': 0.0881, 'grad_norm': 1.1636004447937012, 'learning_rate': 1.2371134020618556e-05, 'epoch': 0.12}
{'loss': 0.1181, 'grad_norm': 0.3661237359046936, 'learning_rate': 1.3402061855670105e-05, 'epoch': 0.13}
{'loss': 0.1557, 'grad_norm': 1.9541175365447998, 'learning_rate': 1.443298969072165e-05, 'epoch': 0.14}
{'loss': 0.1943, 'grad_norm': 1.551915168762207, 'learning_rate': 1.5463917525773194e-05, 'epoch': 0.15}
{'loss': 0.1791, 'grad_norm': 1.1274645328521729, 'learning_rate': 1.6494845360824743e-05, 'epoch': 0.16}
{'loss': 0.176, 'grad_norm': 1.3621965646743774, 'learning_rate': 1.752577319587629e-05, 'epoch': 0.18}
{'loss': 0.1249, 'grad_norm': 0.5910958051681519, 'learning_rate': 1.8556701030927837e-05, 'epoch': 0.19}
{'loss': 0.1509, 'grad_norm': 1.926119089126587, 'learning_rate': 1.9587628865979382e-05, 'epoch': 0.2}
{'loss': 0.199, 'grad_norm': 3.208749532699585, 'learning_rate': 2.0618556701030927e-05, 'epoch': 0.21}
{'loss': 0.0668, 'grad_norm': 0.1765502393245697, 'learning_rate': 2.1649484536082473e-05, 'epoch': 0.22}
{'loss': 0.0665, 'grad_norm': 0.15736441314220428, 'learning_rate': 2.268041237113402e-05, 'epoch': 0.23}
{'loss': 0.2029, 'grad_norm': 1.3699356317520142, 'learning_rate': 2.3711340206185567e-05, 'epoch': 0.24}
{'loss': 0.104, 'grad_norm': 1.521803379058838, 'learning_rate': 2.4742268041237112e-05, 'epoch': 0.25}
{'loss': 0.3135, 'grad_norm': 2.3980531692504883, 'learning_rate': 2.5773195876288658e-05, 'epoch': 0.26}
{'loss': 0.1475, 'grad_norm': 0.8085442781448364, 'learning_rate': 2.680412371134021e-05, 'epoch': 0.27}
{'loss': 0.2079, 'grad_norm': 2.1041088104248047, 'learning_rate': 2.7835051546391755e-05, 'epoch': 0.28}
{'loss': 0.2849, 'grad_norm': 1.9802327156066895, 'learning_rate': 2.88659793814433e-05, 'epoch': 0.29}
{'loss': 0.1952, 'grad_norm': 2.7279770374298096, 'learning_rate': 2.9896907216494846e-05, 'epoch': 0.3}
{'loss': 0.2699, 'grad_norm': 0.7825284600257874, 'learning_rate': 2.9896907216494846e-05, 'epoch': 0.31}
{'loss': 0.1429, 'grad_norm': 0.5694960355758667, 'learning_rate': 2.9782359679266894e-05, 'epoch': 0.32}
{'loss': 0.1397, 'grad_norm': 0.19804762303829193, 'learning_rate': 2.966781214203895e-05, 'epoch': 0.33}
{'loss': 0.191, 'grad_norm': 0.2788718640804291, 'learning_rate': 2.9553264604811e-05, 'epoch': 0.34}
{'loss': 0.1709, 'grad_norm': 1.182224988937378, 'learning_rate': 2.9438717067583048e-05, 'epoch': 0.35}
{'loss': 0.109, 'grad_norm': 0.3944391906261444, 'learning_rate': 2.93241695303551e-05, 'epoch': 0.36}
{'loss': 0.0765, 'grad_norm': 1.25361168384552, 'learning_rate': 2.9209621993127147e-05, 'epoch': 0.37}
{'loss': 0.0899, 'grad_norm': 1.7102159261703491, 'learning_rate': 2.90950744558992e-05, 'epoch': 0.38}
{'loss': 0.1681, 'grad_norm': 3.245516538619995, 'learning_rate': 2.898052691867125e-05, 'epoch': 0.39}
{'loss': 0.1652, 'grad_norm': 1.45280921459198, 'learning_rate': 2.88659793814433e-05, 'epoch': 0.4}
{'loss': 0.0914, 'grad_norm': 2.6472182273864746, 'learning_rate': 2.875143184421535e-05, 'epoch': 0.41}
{'loss': 0.1529, 'grad_norm': 0.5660482048988342, 'learning_rate': 2.86368843069874e-05, 'epoch': 0.42}
{'loss': 0.1111, 'grad_norm': 0.3490018844604492, 'learning_rate': 2.852233676975945e-05, 'epoch': 0.43}
{'loss': 0.1256, 'grad_norm': 4.462515830993652, 'learning_rate': 2.8407789232531502e-05, 'epoch': 0.44}
{'loss': 0.1268, 'grad_norm': 0.2722024619579315, 'learning_rate': 2.8293241695303553e-05, 'epoch': 0.45}
{'loss': 0.1872, 'grad_norm': 3.0581185817718506, 'learning_rate': 2.81786941580756e-05, 'epoch': 0.46}
{'loss': 0.1119, 'grad_norm': 0.4485691785812378, 'learning_rate': 2.8064146620847653e-05, 'epoch': 0.47}
{'loss': 0.0952, 'grad_norm': 0.3479576110839844, 'learning_rate': 2.7949599083619704e-05, 'epoch': 0.48}
{'loss': 0.0544, 'grad_norm': 2.625110149383545, 'learning_rate': 2.7835051546391755e-05, 'epoch': 0.49}
{'loss': 0.0533, 'grad_norm': 0.13807691633701324, 'learning_rate': 2.7720504009163803e-05, 'epoch': 0.51}
{'loss': 0.0719, 'grad_norm': 2.3253605365753174, 'learning_rate': 2.7605956471935854e-05, 'epoch': 0.52}
{'loss': 0.0838, 'grad_norm': 0.10762935131788254, 'learning_rate': 2.7491408934707902e-05, 'epoch': 0.53}
{'loss': 0.1732, 'grad_norm': 0.3613987863063812, 'learning_rate': 2.7376861397479957e-05, 'epoch': 0.54}
{'loss': 0.1647, 'grad_norm': 2.2884011268615723, 'learning_rate': 2.7262313860252005e-05, 'epoch': 0.55}
{'loss': 0.1559, 'grad_norm': 1.7993592023849487, 'learning_rate': 2.7147766323024056e-05, 'epoch': 0.56}
{'loss': 0.086, 'grad_norm': 1.7095249891281128, 'learning_rate': 2.70446735395189e-05, 'epoch': 0.57}
{'loss': 0.09, 'grad_norm': 0.1881275624036789, 'learning_rate': 2.693012600229095e-05, 'epoch': 0.58}
{'loss': 0.0859, 'grad_norm': 0.5030262470245361, 'learning_rate': 2.6815578465063004e-05, 'epoch': 0.59}
{'loss': 0.1249, 'grad_norm': 0.2941288650035858, 'learning_rate': 2.670103092783505e-05, 'epoch': 0.6}
{'loss': 0.1213, 'grad_norm': 0.36757808923721313, 'learning_rate': 2.6586483390607103e-05, 'epoch': 0.61}
{'loss': 0.0731, 'grad_norm': 1.9992733001708984, 'learning_rate': 2.6471935853379154e-05, 'epoch': 0.62}
{'loss': 0.0834, 'grad_norm': 2.4748663902282715, 'learning_rate': 2.6357388316151202e-05, 'epoch': 0.63}
{'loss': 0.0945, 'grad_norm': 2.408506155014038, 'learning_rate': 2.6242840778923257e-05, 'epoch': 0.64}
{'loss': 0.1055, 'grad_norm': 0.10369842499494553, 'learning_rate': 2.6128293241695305e-05, 'epoch': 0.65}
{'loss': 0.1831, 'grad_norm': 3.6266393661499023, 'learning_rate': 2.6013745704467356e-05, 'epoch': 0.66}
{'loss': 0.1231, 'grad_norm': 0.7044646143913269, 'learning_rate': 2.5899198167239404e-05, 'epoch': 0.67}
{'loss': 0.1026, 'grad_norm': 0.21254697442054749, 'learning_rate': 2.5784650630011455e-05, 'epoch': 0.68}
{'loss': 0.07, 'grad_norm': 0.1241818368434906, 'learning_rate': 2.5670103092783506e-05, 'epoch': 0.69}
{'loss': 0.1851, 'grad_norm': 2.380262613296509, 'learning_rate': 2.5555555555555557e-05, 'epoch': 0.7}
{'loss': 0.1245, 'grad_norm': 0.19160880148410797, 'learning_rate': 2.5441008018327605e-05, 'epoch': 0.71}
{'loss': 0.0731, 'grad_norm': 0.16937170922756195, 'learning_rate': 2.5326460481099657e-05, 'epoch': 0.72}
{'loss': 0.1335, 'grad_norm': 3.7826178073883057, 'learning_rate': 2.5211912943871708e-05, 'epoch': 0.73}
{'loss': 0.1095, 'grad_norm': 1.6277021169662476, 'learning_rate': 2.5097365406643756e-05, 'epoch': 0.74}
{'loss': 0.1416, 'grad_norm': 1.4571443796157837, 'learning_rate': 2.498281786941581e-05, 'epoch': 0.75}
{'loss': 0.1035, 'grad_norm': 0.1162184551358223, 'learning_rate': 2.4868270332187858e-05, 'epoch': 0.76}
{'loss': 0.0235, 'grad_norm': 0.05871587246656418, 'learning_rate': 2.475372279495991e-05, 'epoch': 0.77}
{'loss': 0.0821, 'grad_norm': 0.0951966866850853, 'learning_rate': 2.4639175257731957e-05, 'epoch': 0.78}
{'loss': 0.0907, 'grad_norm': 0.13699640333652496, 'learning_rate': 2.452462772050401e-05, 'epoch': 0.79}
{'loss': 0.1042, 'grad_norm': 1.293277382850647, 'learning_rate': 2.441008018327606e-05, 'epoch': 0.8}
{'loss': 0.0678, 'grad_norm': 3.166578769683838, 'learning_rate': 2.429553264604811e-05, 'epoch': 0.81}
{'loss': 0.1292, 'grad_norm': 0.08600921183824539, 'learning_rate': 2.418098510882016e-05, 'epoch': 0.82}
{'loss': 0.1491, 'grad_norm': 6.330578804016113, 'learning_rate': 2.406643757159221e-05, 'epoch': 0.84}
{'loss': 0.1794, 'grad_norm': 3.1759073734283447, 'learning_rate': 2.395189003436426e-05, 'epoch': 0.85}
{'loss': 0.0911, 'grad_norm': 0.2446589320898056, 'learning_rate': 2.3837342497136313e-05, 'epoch': 0.86}
{'loss': 0.1548, 'grad_norm': 1.6263593435287476, 'learning_rate': 2.3722794959908364e-05, 'epoch': 0.87}
{'loss': 0.0655, 'grad_norm': 1.4983681440353394, 'learning_rate': 2.3608247422680412e-05, 'epoch': 0.88}
{'loss': 0.0869, 'grad_norm': 1.4722660779953003, 'learning_rate': 2.3493699885452463e-05, 'epoch': 0.89}
{'loss': 0.154, 'grad_norm': 3.211874485015869, 'learning_rate': 2.337915234822451e-05, 'epoch': 0.9}
{'loss': 0.1052, 'grad_norm': 4.197707653045654, 'learning_rate': 2.3264604810996566e-05, 'epoch': 0.91}
{'loss': 0.094, 'grad_norm': 0.16066524386405945, 'learning_rate': 2.3150057273768614e-05, 'epoch': 0.92}
{'loss': 0.1809, 'grad_norm': 1.7180278301239014, 'learning_rate': 2.3035509736540665e-05, 'epoch': 0.93}
{'loss': 0.168, 'grad_norm': 3.2047743797302246, 'learning_rate': 2.2920962199312713e-05, 'epoch': 0.94}
{'loss': 0.1405, 'grad_norm': 1.868985891342163, 'learning_rate': 2.2806414662084764e-05, 'epoch': 0.95}
{'loss': 0.1149, 'grad_norm': 0.24455225467681885, 'learning_rate': 2.269186712485682e-05, 'epoch': 0.96}
{'loss': 0.0966, 'grad_norm': 1.8327713012695312, 'learning_rate': 2.2577319587628867e-05, 'epoch': 0.97}
{'loss': 0.1444, 'grad_norm': 0.27689123153686523, 'learning_rate': 2.2462772050400918e-05, 'epoch': 0.98}
{'loss': 0.0403, 'grad_norm': 0.1984609067440033, 'learning_rate': 2.2348224513172966e-05, 'epoch': 0.99}
{'loss': 0.0805, 'grad_norm': 0.10088545083999634, 'learning_rate': 2.2233676975945017e-05, 'epoch': 1.0}
{'eval_loss': 0.10410524159669876, 'eval_precision': 0.8588235294117647, 'eval_recall': 0.4866666666666667, 'eval_f1': 0.6212765957446809, 'eval_runtime': 1.6897, 'eval_samples_per_second': 1966.629, 'eval_steps_per_second': 123.099, 'epoch': 1.0}
{'loss': 0.1132, 'grad_norm': 1.5825376510620117, 'learning_rate': 2.211912943871707e-05, 'epoch': 1.01}
{'loss': 0.0931, 'grad_norm': 0.2509423494338989, 'learning_rate': 2.200458190148912e-05, 'epoch': 1.02}
{'loss': 0.0659, 'grad_norm': 0.4168960154056549, 'learning_rate': 2.1890034364261168e-05, 'epoch': 1.03}
{'loss': 0.0814, 'grad_norm': 0.1522691547870636, 'learning_rate': 2.177548682703322e-05, 'epoch': 1.04}
{'loss': 0.0323, 'grad_norm': 0.07962822914123535, 'learning_rate': 2.1660939289805267e-05, 'epoch': 1.05}
{'loss': 0.058, 'grad_norm': 6.0692949295043945, 'learning_rate': 2.154639175257732e-05, 'epoch': 1.06}
{'loss': 0.0195, 'grad_norm': 0.44531315565109253, 'learning_rate': 2.1431844215349373e-05, 'epoch': 1.07}
{'loss': 0.0836, 'grad_norm': 0.07671056687831879, 'learning_rate': 2.131729667812142e-05, 'epoch': 1.08}
{'loss': 0.0839, 'grad_norm': 0.3776167035102844, 'learning_rate': 2.1202749140893472e-05, 'epoch': 1.09}
{'loss': 0.0114, 'grad_norm': 0.6264195442199707, 'learning_rate': 2.108820160366552e-05, 'epoch': 1.1}
{'loss': 0.0588, 'grad_norm': 1.631669282913208, 'learning_rate': 2.0973654066437574e-05, 'epoch': 1.11}
{'loss': 0.017, 'grad_norm': 0.050690095871686935, 'learning_rate': 2.0859106529209622e-05, 'epoch': 1.12}
{'loss': 0.1172, 'grad_norm': 0.05047135055065155, 'learning_rate': 2.0756013745704467e-05, 'epoch': 1.13}
{'loss': 0.0277, 'grad_norm': 0.07051543891429901, 'learning_rate': 2.064146620847652e-05, 'epoch': 1.14}
{'loss': 0.0078, 'grad_norm': 0.1723417043685913, 'learning_rate': 2.0526918671248566e-05, 'epoch': 1.15}
{'loss': 0.0937, 'grad_norm': 0.6613743901252747, 'learning_rate': 2.041237113402062e-05, 'epoch': 1.16}
{'loss': 0.1054, 'grad_norm': 0.27278047800064087, 'learning_rate': 2.029782359679267e-05, 'epoch': 1.18}
{'loss': 0.0677, 'grad_norm': 0.49154219031333923, 'learning_rate': 2.018327605956472e-05, 'epoch': 1.19}
{'loss': 0.1039, 'grad_norm': 0.04639893397688866, 'learning_rate': 2.0068728522336768e-05, 'epoch': 1.2}
{'loss': 0.1311, 'grad_norm': 3.035609006881714, 'learning_rate': 1.995418098510882e-05, 'epoch': 1.21}
{'loss': 0.0286, 'grad_norm': 0.11584543436765671, 'learning_rate': 1.983963344788087e-05, 'epoch': 1.22}
{'loss': 0.0499, 'grad_norm': 0.19672565162181854, 'learning_rate': 1.9725085910652922e-05, 'epoch': 1.23}
{'loss': 0.0343, 'grad_norm': 0.11552894115447998, 'learning_rate': 1.9610538373424973e-05, 'epoch': 1.24}
{'loss': 0.1056, 'grad_norm': 0.35241463780403137, 'learning_rate': 1.949599083619702e-05, 'epoch': 1.25}
{'loss': 0.0285, 'grad_norm': 0.16526514291763306, 'learning_rate': 1.9381443298969072e-05, 'epoch': 1.26}
{'loss': 0.055, 'grad_norm': 5.826353549957275, 'learning_rate': 1.9266895761741124e-05, 'epoch': 1.27}
{'loss': 0.0085, 'grad_norm': 0.49273091554641724, 'learning_rate': 1.9152348224513175e-05, 'epoch': 1.28}
{'loss': 0.0332, 'grad_norm': 0.026848260313272476, 'learning_rate': 1.9037800687285223e-05, 'epoch': 1.29}
{'loss': 0.0735, 'grad_norm': 0.31606560945510864, 'learning_rate': 1.8923253150057274e-05, 'epoch': 1.3}
{'loss': 0.1373, 'grad_norm': 0.11708291620016098, 'learning_rate': 1.8808705612829322e-05, 'epoch': 1.31}
{'loss': 0.1284, 'grad_norm': 5.989693641662598, 'learning_rate': 1.8694158075601377e-05, 'epoch': 1.32}
{'loss': 0.025, 'grad_norm': 0.26877957582473755, 'learning_rate': 1.8579610538373424e-05, 'epoch': 1.33}
{'loss': 0.0557, 'grad_norm': 4.572633743286133, 'learning_rate': 1.8465063001145476e-05, 'epoch': 1.34}
{'loss': 0.027, 'grad_norm': 0.19360578060150146, 'learning_rate': 1.8350515463917527e-05, 'epoch': 1.35}
{'loss': 0.0761, 'grad_norm': 0.027447201311588287, 'learning_rate': 1.8235967926689575e-05, 'epoch': 1.36}
{'loss': 0.1701, 'grad_norm': 3.470348358154297, 'learning_rate': 1.812142038946163e-05, 'epoch': 1.37}
{'loss': 0.0281, 'grad_norm': 0.09934183955192566, 'learning_rate': 1.8006872852233677e-05, 'epoch': 1.38}
{'loss': 0.1144, 'grad_norm': 11.088688850402832, 'learning_rate': 1.789232531500573e-05, 'epoch': 1.39}
{'loss': 0.0465, 'grad_norm': 2.447697401046753, 'learning_rate': 1.7777777777777777e-05, 'epoch': 1.4}
{'loss': 0.1549, 'grad_norm': 3.262481451034546, 'learning_rate': 1.7663230240549828e-05, 'epoch': 1.41}
{'loss': 0.112, 'grad_norm': 11.21426010131836, 'learning_rate': 1.754868270332188e-05, 'epoch': 1.42}
{'loss': 0.073, 'grad_norm': 2.0972723960876465, 'learning_rate': 1.743413516609393e-05, 'epoch': 1.43}
{'loss': 0.1117, 'grad_norm': 9.263619422912598, 'learning_rate': 1.7319587628865978e-05, 'epoch': 1.44}
{'loss': 0.0293, 'grad_norm': 0.32472851872444153, 'learning_rate': 1.720504009163803e-05, 'epoch': 1.45}
{'loss': 0.0928, 'grad_norm': 11.957159042358398, 'learning_rate': 1.709049255441008e-05, 'epoch': 1.46}
{'loss': 0.0588, 'grad_norm': 3.5665836334228516, 'learning_rate': 1.6975945017182132e-05, 'epoch': 1.47}
{'loss': 0.0976, 'grad_norm': 0.20149274170398712, 'learning_rate': 1.6861397479954183e-05, 'epoch': 1.48}
{'loss': 0.1458, 'grad_norm': 0.08038213104009628, 'learning_rate': 1.674684994272623e-05, 'epoch': 1.49}
{'loss': 0.0847, 'grad_norm': 4.051845550537109, 'learning_rate': 1.6632302405498283e-05, 'epoch': 1.51}
{'loss': 0.0406, 'grad_norm': 0.12762843072414398, 'learning_rate': 1.651775486827033e-05, 'epoch': 1.52}
{'loss': 0.0253, 'grad_norm': 0.1741316169500351, 'learning_rate': 1.6403207331042385e-05, 'epoch': 1.53}
{'loss': 0.0296, 'grad_norm': 0.050555936992168427, 'learning_rate': 1.6288659793814433e-05, 'epoch': 1.54}
{'loss': 0.0142, 'grad_norm': 0.03147748485207558, 'learning_rate': 1.6174112256586484e-05, 'epoch': 1.55}
{'loss': 0.0608, 'grad_norm': 1.022942066192627, 'learning_rate': 1.6059564719358532e-05, 'epoch': 1.56}
{'loss': 0.0464, 'grad_norm': 0.06452157348394394, 'learning_rate': 1.5945017182130583e-05, 'epoch': 1.57}
{'loss': 0.0457, 'grad_norm': 0.2197786569595337, 'learning_rate': 1.5830469644902638e-05, 'epoch': 1.58}
{'loss': 0.1198, 'grad_norm': 8.29436206817627, 'learning_rate': 1.5715922107674686e-05, 'epoch': 1.59}
{'loss': 0.0337, 'grad_norm': 0.12264234572649002, 'learning_rate': 1.5601374570446737e-05, 'epoch': 1.6}
{'loss': 0.0605, 'grad_norm': 0.029949283227324486, 'learning_rate': 1.5486827033218785e-05, 'epoch': 1.61}
{'loss': 0.0338, 'grad_norm': 0.16410726308822632, 'learning_rate': 1.5372279495990836e-05, 'epoch': 1.62}
{'loss': 0.0355, 'grad_norm': 2.2676210403442383, 'learning_rate': 1.5257731958762886e-05, 'epoch': 1.63}
{'loss': 0.0543, 'grad_norm': 0.18357457220554352, 'learning_rate': 1.5143184421534937e-05, 'epoch': 1.64}
{'loss': 0.0717, 'grad_norm': 8.963653564453125, 'learning_rate': 1.5028636884306987e-05, 'epoch': 1.65}
{'loss': 0.0807, 'grad_norm': 0.11624784022569656, 'learning_rate': 1.4914089347079038e-05, 'epoch': 1.66}
{'loss': 0.0354, 'grad_norm': 0.06013496592640877, 'learning_rate': 1.479954180985109e-05, 'epoch': 1.67}
{'loss': 0.1149, 'grad_norm': 0.17156679928302765, 'learning_rate': 1.4684994272623139e-05, 'epoch': 1.68}
{'loss': 0.0651, 'grad_norm': 0.2744223475456238, 'learning_rate': 1.4570446735395188e-05, 'epoch': 1.69}
{'loss': 0.0123, 'grad_norm': 0.07620652765035629, 'learning_rate': 1.445589919816724e-05, 'epoch': 1.7}
{'loss': 0.0293, 'grad_norm': 0.22384363412857056, 'learning_rate': 1.434135166093929e-05, 'epoch': 1.71}
{'loss': 0.0645, 'grad_norm': 3.401942491531372, 'learning_rate': 1.422680412371134e-05, 'epoch': 1.72}
{'loss': 0.0727, 'grad_norm': 4.862588882446289, 'learning_rate': 1.411225658648339e-05, 'epoch': 1.73}
{'loss': 0.0477, 'grad_norm': 0.33115583658218384, 'learning_rate': 1.3997709049255441e-05, 'epoch': 1.74}
{'loss': 0.0747, 'grad_norm': 0.31604743003845215, 'learning_rate': 1.3883161512027493e-05, 'epoch': 1.75}
{'loss': 0.1053, 'grad_norm': 0.03809346258640289, 'learning_rate': 1.3768613974799542e-05, 'epoch': 1.76}
{'loss': 0.0688, 'grad_norm': 0.08946692943572998, 'learning_rate': 1.3654066437571593e-05, 'epoch': 1.77}
{'loss': 0.0188, 'grad_norm': 0.206621453166008, 'learning_rate': 1.3539518900343643e-05, 'epoch': 1.78}
{'loss': 0.0091, 'grad_norm': 1.1095622777938843, 'learning_rate': 1.3424971363115693e-05, 'epoch': 1.79}
{'loss': 0.0383, 'grad_norm': 0.09467820078134537, 'learning_rate': 1.3310423825887744e-05, 'epoch': 1.8}
{'loss': 0.0129, 'grad_norm': 0.19485613703727722, 'learning_rate': 1.3195876288659793e-05, 'epoch': 1.81}
{'loss': 0.0475, 'grad_norm': 0.03243769332766533, 'learning_rate': 1.3081328751431845e-05, 'epoch': 1.82}
{'loss': 0.0223, 'grad_norm': 0.13236543536186218, 'learning_rate': 1.2966781214203894e-05, 'epoch': 1.84}
{'loss': 0.0712, 'grad_norm': 0.026740094646811485, 'learning_rate': 1.2852233676975944e-05, 'epoch': 1.85}
{'loss': 0.0832, 'grad_norm': 0.0959073156118393, 'learning_rate': 1.2737686139747997e-05, 'epoch': 1.86}
{'loss': 0.0712, 'grad_norm': 7.6800007820129395, 'learning_rate': 1.2623138602520046e-05, 'epoch': 1.87}
{'loss': 0.0814, 'grad_norm': 8.711745262145996, 'learning_rate': 1.2508591065292098e-05, 'epoch': 1.88}
{'loss': 0.003, 'grad_norm': 0.5978940725326538, 'learning_rate': 1.2394043528064147e-05, 'epoch': 1.89}
{'loss': 0.0214, 'grad_norm': 0.018499305471777916, 'learning_rate': 1.2279495990836197e-05, 'epoch': 1.9}
{'loss': 0.0166, 'grad_norm': 0.08009520918130875, 'learning_rate': 1.2164948453608248e-05, 'epoch': 1.91}
{'loss': 0.1056, 'grad_norm': 0.262083500623703, 'learning_rate': 1.2050400916380298e-05, 'epoch': 1.92}
{'loss': 0.0591, 'grad_norm': 0.683948814868927, 'learning_rate': 1.1935853379152349e-05, 'epoch': 1.93}
{'loss': 0.0467, 'grad_norm': 0.02761785313487053, 'learning_rate': 1.1821305841924399e-05, 'epoch': 1.94}
{'loss': 0.0509, 'grad_norm': 0.05655491724610329, 'learning_rate': 1.1706758304696448e-05, 'epoch': 1.95}
{'loss': 0.1094, 'grad_norm': 0.0532994344830513, 'learning_rate': 1.15922107674685e-05, 'epoch': 1.96}
{'loss': 0.0926, 'grad_norm': 0.0637044832110405, 'learning_rate': 1.1477663230240549e-05, 'epoch': 1.97}
{'loss': 0.0591, 'grad_norm': 0.11572844535112381, 'learning_rate': 1.1363115693012602e-05, 'epoch': 1.98}
{'loss': 0.0939, 'grad_norm': 7.361093521118164, 'learning_rate': 1.1248568155784651e-05, 'epoch': 1.99}
{'loss': 0.027, 'grad_norm': 0.012472599744796753, 'learning_rate': 1.1134020618556701e-05, 'epoch': 2.0}
{'eval_loss': 0.08000223338603973, 'eval_precision': 0.8828828828828829, 'eval_recall': 0.6533333333333333, 'eval_f1': 0.7509578544061303, 'eval_runtime': 1.6836, 'eval_samples_per_second': 1973.792, 'eval_steps_per_second': 123.548, 'epoch': 2.0}
{'loss': 0.0016, 'grad_norm': 0.04373371601104736, 'learning_rate': 1.1019473081328752e-05, 'epoch': 2.01}
{'loss': 0.0271, 'grad_norm': 0.02940940484404564, 'learning_rate': 1.0904925544100802e-05, 'epoch': 2.02}
{'loss': 0.043, 'grad_norm': 0.22533771395683289, 'learning_rate': 1.0790378006872853e-05, 'epoch': 2.03}
{'loss': 0.0131, 'grad_norm': 0.3112419545650482, 'learning_rate': 1.0675830469644903e-05, 'epoch': 2.04}
{'loss': 0.0531, 'grad_norm': 6.360775947570801, 'learning_rate': 1.0561282932416952e-05, 'epoch': 2.05}
{'loss': 0.0485, 'grad_norm': 3.6381478309631348, 'learning_rate': 1.0446735395189004e-05, 'epoch': 2.06}
{'loss': 0.019, 'grad_norm': 0.07350518554449081, 'learning_rate': 1.0332187857961053e-05, 'epoch': 2.07}
{'loss': 0.0317, 'grad_norm': 7.305514812469482, 'learning_rate': 1.0217640320733104e-05, 'epoch': 2.08}
{'loss': 0.0158, 'grad_norm': 0.022926969453692436, 'learning_rate': 1.0103092783505156e-05, 'epoch': 2.09}
{'loss': 0.0136, 'grad_norm': 0.15228112041950226, 'learning_rate': 9.988545246277205e-06, 'epoch': 2.1}
{'loss': 0.0283, 'grad_norm': 0.04139455407857895, 'learning_rate': 9.873997709049257e-06, 'epoch': 2.11}
{'loss': 0.0566, 'grad_norm': 17.485000610351562, 'learning_rate': 9.759450171821306e-06, 'epoch': 2.12}
{'loss': 0.0237, 'grad_norm': 0.029681317508220673, 'learning_rate': 9.644902634593357e-06, 'epoch': 2.13}
{'loss': 0.0023, 'grad_norm': 0.3352223038673401, 'learning_rate': 9.530355097365407e-06, 'epoch': 2.14}
{'loss': 0.0036, 'grad_norm': 0.13560333847999573, 'learning_rate': 9.415807560137457e-06, 'epoch': 2.15}
{'loss': 0.0436, 'grad_norm': 0.023198924958705902, 'learning_rate': 9.301260022909508e-06, 'epoch': 2.16}
{'loss': 0.043, 'grad_norm': 0.04926251247525215, 'learning_rate': 9.186712485681557e-06, 'epoch': 2.18}
{'loss': 0.0319, 'grad_norm': 0.027114320546388626, 'learning_rate': 9.072164948453609e-06, 'epoch': 2.19}
{'loss': 0.0989, 'grad_norm': 0.07645676285028458, 'learning_rate': 8.957617411225658e-06, 'epoch': 2.2}
{'loss': 0.0027, 'grad_norm': 0.045519378036260605, 'learning_rate': 8.84306987399771e-06, 'epoch': 2.21}
{'loss': 0.0366, 'grad_norm': 3.6571874618530273, 'learning_rate': 8.72852233676976e-06, 'epoch': 2.22}
{'loss': 0.0054, 'grad_norm': 0.021279428154230118, 'learning_rate': 8.61397479954181e-06, 'epoch': 2.23}
{'loss': 0.0728, 'grad_norm': 4.965035915374756, 'learning_rate': 8.499427262313862e-06, 'epoch': 2.24}
{'loss': 0.0035, 'grad_norm': 0.04071386903524399, 'learning_rate': 8.384879725085911e-06, 'epoch': 2.25}
{'loss': 0.0168, 'grad_norm': 0.2861349284648895, 'learning_rate': 8.27033218785796e-06, 'epoch': 2.26}
{'loss': 0.0226, 'grad_norm': 0.08274807780981064, 'learning_rate': 8.155784650630012e-06, 'epoch': 2.27}
{'loss': 0.0236, 'grad_norm': 0.045776911079883575, 'learning_rate': 8.041237113402062e-06, 'epoch': 2.28}
{'loss': 0.0238, 'grad_norm': 0.018478892743587494, 'learning_rate': 7.926689576174113e-06, 'epoch': 2.29}
{'loss': 0.0029, 'grad_norm': 2.7552602291107178, 'learning_rate': 7.812142038946162e-06, 'epoch': 2.3}
{'loss': 0.0789, 'grad_norm': 0.07262483984231949, 'learning_rate': 7.697594501718212e-06, 'epoch': 2.31}
{'loss': 0.019, 'grad_norm': 0.04016147181391716, 'learning_rate': 7.583046964490264e-06, 'epoch': 2.32}
{'loss': 0.015, 'grad_norm': 0.28085756301879883, 'learning_rate': 7.468499427262314e-06, 'epoch': 2.33}
{'loss': 0.0062, 'grad_norm': 0.03595329448580742, 'learning_rate': 7.353951890034364e-06, 'epoch': 2.34}
{'loss': 0.0261, 'grad_norm': 0.012629996985197067, 'learning_rate': 7.239404352806415e-06, 'epoch': 2.35}
{'loss': 0.0473, 'grad_norm': 0.013781826943159103, 'learning_rate': 7.124856815578466e-06, 'epoch': 2.36}
{'loss': 0.0475, 'grad_norm': 0.14271730184555054, 'learning_rate': 7.010309278350515e-06, 'epoch': 2.37}
{'loss': 0.0436, 'grad_norm': 0.03822716325521469, 'learning_rate': 6.895761741122566e-06, 'epoch': 2.38}
{'loss': 0.0207, 'grad_norm': 0.02220831997692585, 'learning_rate': 6.781214203894616e-06, 'epoch': 2.39}
{'loss': 0.0231, 'grad_norm': 0.08852267265319824, 'learning_rate': 6.666666666666667e-06, 'epoch': 2.4}
{'loss': 0.0009, 'grad_norm': 0.029937349259853363, 'learning_rate': 6.552119129438718e-06, 'epoch': 2.41}
{'loss': 0.0667, 'grad_norm': 4.011668682098389, 'learning_rate': 6.4375715922107675e-06, 'epoch': 2.42}
{'loss': 0.048, 'grad_norm': 2.4068682193756104, 'learning_rate': 6.323024054982818e-06, 'epoch': 2.43}
{'loss': 0.0496, 'grad_norm': 0.030706986784934998, 'learning_rate': 6.208476517754868e-06, 'epoch': 2.44}
{'loss': 0.0373, 'grad_norm': 0.038077812641859055, 'learning_rate': 6.093928980526919e-06, 'epoch': 2.45}
{'loss': 0.0757, 'grad_norm': 7.874398231506348, 'learning_rate': 5.97938144329897e-06, 'epoch': 2.46}
{'loss': 0.0387, 'grad_norm': 0.25020262598991394, 'learning_rate': 5.86483390607102e-06, 'epoch': 2.47}
{'loss': 0.0032, 'grad_norm': 0.02750178799033165, 'learning_rate': 5.75028636884307e-06, 'epoch': 2.48}
{'loss': 0.0104, 'grad_norm': 0.1140226349234581, 'learning_rate': 5.6357388316151204e-06, 'epoch': 2.49}
{'loss': 0.0511, 'grad_norm': 8.699901580810547, 'learning_rate': 5.521191294387171e-06, 'epoch': 2.51}
{'loss': 0.0009, 'grad_norm': 0.02392842248082161, 'learning_rate': 5.406643757159221e-06, 'epoch': 2.52}
{'loss': 0.0617, 'grad_norm': 1.887519359588623, 'learning_rate': 5.292096219931272e-06, 'epoch': 2.53}
{'loss': 0.0422, 'grad_norm': 12.935230255126953, 'learning_rate': 5.177548682703322e-06, 'epoch': 2.54}
{'loss': 0.0152, 'grad_norm': 0.04965393245220184, 'learning_rate': 5.0630011454753726e-06, 'epoch': 2.55}
{'loss': 0.0131, 'grad_norm': 0.01342835184186697, 'learning_rate': 4.948453608247423e-06, 'epoch': 2.56}
{'loss': 0.0347, 'grad_norm': 0.05648103356361389, 'learning_rate': 4.8339060710194725e-06, 'epoch': 2.57}
{'loss': 0.0188, 'grad_norm': 0.015596347860991955, 'learning_rate': 4.719358533791523e-06, 'epoch': 2.58}
{'loss': 0.0013, 'grad_norm': 0.3773278594017029, 'learning_rate': 4.604810996563574e-06, 'epoch': 2.59}
{'loss': 0.0239, 'grad_norm': 3.465897798538208, 'learning_rate': 4.490263459335625e-06, 'epoch': 2.6}
{'loss': 0.0097, 'grad_norm': 0.06416498869657516, 'learning_rate': 4.375715922107675e-06, 'epoch': 2.61}
{'loss': 0.0482, 'grad_norm': 2.0794966220855713, 'learning_rate': 4.261168384879725e-06, 'epoch': 2.62}
{'loss': 0.0399, 'grad_norm': 0.040504276752471924, 'learning_rate': 4.146620847651775e-06, 'epoch': 2.63}
{'loss': 0.0742, 'grad_norm': 2.9593887329101562, 'learning_rate': 4.032073310423826e-06, 'epoch': 2.64}
{'loss': 0.0052, 'grad_norm': 0.03548374027013779, 'learning_rate': 3.917525773195877e-06, 'epoch': 2.65}
{'loss': 0.0011, 'grad_norm': 0.013827776536345482, 'learning_rate': 3.8029782359679268e-06, 'epoch': 2.66}
{'loss': 0.0028, 'grad_norm': 0.056386999785900116, 'learning_rate': 3.688430698739977e-06, 'epoch': 2.67}
{'loss': 0.0316, 'grad_norm': 0.03353402391076088, 'learning_rate': 3.573883161512027e-06, 'epoch': 2.68}
{'loss': 0.0664, 'grad_norm': 0.34432166814804077, 'learning_rate': 3.459335624284078e-06, 'epoch': 2.69}
{'loss': 0.038, 'grad_norm': 0.03327024728059769, 'learning_rate': 3.3447880870561285e-06, 'epoch': 2.7}
{'loss': 0.0196, 'grad_norm': 0.033090684562921524, 'learning_rate': 3.230240549828179e-06, 'epoch': 2.71}
{'loss': 0.0275, 'grad_norm': 0.020472681149840355, 'learning_rate': 3.1156930126002293e-06, 'epoch': 2.72}
{'loss': 0.0268, 'grad_norm': 0.02251368574798107, 'learning_rate': 3.0011454753722793e-06, 'epoch': 2.73}
{'loss': 0.0013, 'grad_norm': 0.15708185732364655, 'learning_rate': 2.88659793814433e-06, 'epoch': 2.74}
{'loss': 0.0133, 'grad_norm': 0.01716494746506214, 'learning_rate': 2.7720504009163806e-06, 'epoch': 2.75}
{'loss': 0.0245, 'grad_norm': 0.00948026031255722, 'learning_rate': 2.6575028636884306e-06, 'epoch': 2.76}
{'loss': 0.0349, 'grad_norm': 0.015581762418150902, 'learning_rate': 2.5429553264604814e-06, 'epoch': 2.77}
{'loss': 0.0012, 'grad_norm': 0.038813721388578415, 'learning_rate': 2.4284077892325314e-06, 'epoch': 2.78}
{'loss': 0.041, 'grad_norm': 0.03504427149891853, 'learning_rate': 2.313860252004582e-06, 'epoch': 2.79}
{'loss': 0.0446, 'grad_norm': 0.031080882996320724, 'learning_rate': 2.1993127147766322e-06, 'epoch': 2.8}
{'loss': 0.0026, 'grad_norm': 0.05173027142882347, 'learning_rate': 2.0847651775486827e-06, 'epoch': 2.81}
{'loss': 0.0472, 'grad_norm': 0.04636136442422867, 'learning_rate': 1.970217640320733e-06, 'epoch': 2.82}
{'loss': 0.0012, 'grad_norm': 0.015198017470538616, 'learning_rate': 1.8556701030927837e-06, 'epoch': 2.84}
{'loss': 0.0188, 'grad_norm': 0.046647634357213974, 'learning_rate': 1.741122565864834e-06, 'epoch': 2.85}
{'loss': 0.0016, 'grad_norm': 0.024301692843437195, 'learning_rate': 1.6265750286368844e-06, 'epoch': 2.86}
{'loss': 0.0133, 'grad_norm': 0.016709104180336, 'learning_rate': 1.5120274914089348e-06, 'epoch': 2.87}
{'loss': 0.0019, 'grad_norm': 0.027338460087776184, 'learning_rate': 1.3974799541809852e-06, 'epoch': 2.88}
{'loss': 0.0026, 'grad_norm': 0.3419231176376343, 'learning_rate': 1.2829324169530354e-06, 'epoch': 2.89}
{'loss': 0.0435, 'grad_norm': 0.0684218779206276, 'learning_rate': 1.168384879725086e-06, 'epoch': 2.9}
{'loss': 0.0448, 'grad_norm': 0.2091173380613327, 'learning_rate': 1.0538373424971365e-06, 'epoch': 2.91}
{'loss': 0.0381, 'grad_norm': 0.04728148132562637, 'learning_rate': 9.392898052691867e-07, 'epoch': 2.92}
{'loss': 0.003, 'grad_norm': 0.02549094147980213, 'learning_rate': 8.247422680412371e-07, 'epoch': 2.93}
{'loss': 0.0013, 'grad_norm': 1.3702152967453003, 'learning_rate': 7.101947308132876e-07, 'epoch': 2.94}
{'loss': 0.0034, 'grad_norm': 0.0775376707315445, 'learning_rate': 5.956471935853379e-07, 'epoch': 2.95}
{'loss': 0.0125, 'grad_norm': 3.670414447784424, 'learning_rate': 4.810996563573883e-07, 'epoch': 2.96}
{'loss': 0.0644, 'grad_norm': 0.020632313564419746, 'learning_rate': 3.665521191294387e-07, 'epoch': 2.97}
{'loss': 0.0493, 'grad_norm': 0.09777373820543289, 'learning_rate': 2.5200458190148915e-07, 'epoch': 2.98}
{'loss': 0.0012, 'grad_norm': 0.04038876295089722, 'learning_rate': 1.3745704467353952e-07, 'epoch': 2.99}
{'loss': 0.051, 'grad_norm': 0.021561112254858017, 'learning_rate': 2.290950744558992e-08, 'epoch': 3.0}
{'eval_loss': 0.0821208655834198, 'eval_precision': 0.8833333333333333, 'eval_recall': 0.7066666666666667, 'eval_f1': 0.7851851851851852, 'eval_runtime': 1.9261, 'eval_samples_per_second': 1725.272, 'eval_steps_per_second': 107.992, 'epoch': 3.0}
{'train_runtime': 117.7747, 'train_samples_per_second': 394.975, 'train_steps_per_second': 24.708, 'train_loss': 0.08228314644129006, 'epoch': 3.0}
100%|█████████████████████████████████████████████████████████████| 2910/2910 [01:57<00:00, 24.71it/s]
100%|██████████████████████████████████████████████████████████████| 208/208 [00:01<00:00, 129.64it/s]
100%|██████████████████████████████████████████████████████████████| 208/208 [00:01<00:00, 128.37it/s]
2025-11-19 11:45:37 | INFO     | spot_scam.models.transformer | Transformer validation F1=0.783 Precision=0.840 Recall=0.733
2025-11-19 11:45:37 | INFO     | __main__ | Ensemble (top 3) F1=0.856 Precision=0.930 Recall=0.793
2025-11-19 11:45:37 | WARNING  | __main__ | Failed to build ensemble: y_prob contains values less than 0: -3.6281798190364594e-19
2025-11-19 11:45:37 | INFO     | __main__ | Selected best model (classical): ensemble_top3 (val F1=0.856)
2025-11-19 11:45:38 | INFO     | spot_scam.evaluation.curves | Saved PR curve to /home/snguyen/spot-the-scam-project/experiments/figs/pr_curve_test.png
2025-11-19 11:45:38 | INFO     | spot_scam.evaluation.curves | Saved calibration curve to /home/snguyen/spot-the-scam-project/experiments/figs/calibration_curve_test.png
2025-11-19 11:45:38 | INFO     | spot_scam.evaluation.curves | Saved confusion matrix plot to /home/snguyen/spot-the-scam-project/experiments/figs/confusion_matrix_test.png
2025-11-19 11:45:38 | INFO     | spot_scam.evaluation.curves | Saved score distribution plot to /home/snguyen/spot-the-scam-project/experiments/figs/score_distribution_test.png
2025-11-19 11:45:38 | INFO     | spot_scam.evaluation.curves | Saved threshold sweep plot to /home/snguyen/spot-the-scam-project/experiments/figs/threshold_sweep_val.png
2025-11-19 11:45:39 | INFO     | spot_scam.evaluation.curves | Saved probability regression plot to /home/snguyen/spot-the-scam-project/experiments/figs/probability_vs_length.png
2025-11-19 11:45:42 | INFO     | spot_scam.evaluation.curves | Saved inference benchmark plot to /home/snguyen/spot-the-scam-project/experiments/figs/latency_throughput.png
2025-11-19 11:45:42 | INFO     | spot_scam.evaluation.reporting | Wrote evaluation report to /home/snguyen/spot-the-scam-project/experiments/report.md
2025-11-19 11:45:42 | INFO     | spot_scam.export.mlflow_logger | Exporting model artifacts to temporary directory: /tmp/spot_scam_onnx_n3ngsfz4
2025-11-19 11:45:42 | WARNING  | spot_scam.export.mlflow_logger | MLflow export skipped: ensemble_top3 is an ensemble model (ONNX export not supported).
Training complete. Best model: ensemble_top3